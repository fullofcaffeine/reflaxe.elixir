This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: AGENTS.md, docs/prds/HAXE_ELIXIR_1_0_COMPILER_TODOAPP_PRD.md, docs/05-architecture/FILE_NAMING_ARCHITECTURE.md, src/reflaxe/elixir/ElixirCompiler.hx, src/reflaxe/elixir/ast/builders/ModuleBuilder.hx, src/reflaxe/elixir/ast/transformers/AnnotationTransforms.hx, src/reflaxe/elixir/ElixirOutputIterator.hx, src/reflaxe/elixir/PhoenixMapper.hx, src/reflaxe/elixir/ast/ElixirAST.hx, examples/todo-app/src_haxe/TodoApp.hx, examples/todo-app/build-server-passE.hxml, examples/todo-app/build-server-multipass.hxml, examples/todo-app/build-server.hxml, examples/todo-app/mix.exs, examples/todo-app/lib/_GeneratedFiles.json, scripts/qa-sentinel.sh, examples/todo-app/assets/postcss.config.js, examples/todo-app/assets/package.json, examples/todo-app/build-client.hxml, haxe_libraries/genes.hxml, haxe_libraries/helder.set.hxml, lib/haxe_compiler.ex
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
docs/
  05-architecture/
    FILE_NAMING_ARCHITECTURE.md
  prds/
    HAXE_ELIXIR_1_0_COMPILER_TODOAPP_PRD.md
examples/
  todo-app/
    assets/
      package.json
      postcss.config.js
    src_haxe/
      TodoApp.hx
    build-client.hxml
    build-server-multipass.hxml
    build-server-passE.hxml
    build-server.hxml
    mix.exs
lib/
  haxe_compiler.ex
scripts/
  qa-sentinel.sh
src/
  reflaxe/
    elixir/
      ast/
        builders/
          ModuleBuilder.hx
        transformers/
          AnnotationTransforms.hx
        ElixirAST.hx
      ElixirCompiler.hx
      ElixirOutputIterator.hx
      PhoenixMapper.hx
AGENTS.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="docs/05-architecture/FILE_NAMING_ARCHITECTURE.md">
# File Naming Architecture for Reflaxe.Elixir

## Overview

This document describes the comprehensive file naming system that transforms Haxe PascalCase class names and package structures into Elixir snake_case file paths. The system ensures **100% consistency** across all generated files while respecting Phoenix framework conventions.

## Core Principles

1. **Universal snake_case conversion** - Every file gets proper Elixir naming
2. **Package-to-directory mapping** - Haxe packages become snake_case directories
3. **Framework-aware placement** - Phoenix annotations override default paths
4. **DRY implementation** - Single source of truth for all naming logic

## Architecture Components

### 1. Central Naming Function: `getComprehensiveNamingRule()`

Located in `ElixirCompiler.hx`, this function handles ALL naming scenarios:

```haxe
private function getComprehensiveNamingRule(classType: ClassType): {fileName: String, dirPath: String}
```

**Inputs:**
- `classType`: Complete Haxe class information including name, package, and metadata

**Outputs:**
- `fileName`: Snake_case file name (without extension)
- `dirPath`: Directory path relative to lib/

### 2. Naming Pipeline

```
Haxe Class → Extract Components → Apply Rules → Generate Path
```

#### Step 1: Extract Components
- Class name: `TodoApp`
- Package: `["server", "infrastructure"]`
- Annotations: `@:application`, `@:router`, etc.

#### Step 2: Apply Base Rules
- Convert class name to snake_case: `TodoApp` → `todo_app`
- Convert package parts to snake_case: `["server", "infrastructure"]` → `["server", "infrastructure"]`
- Create default path: `server/infrastructure/todo_app.ex`

#### Step 3: Apply Framework Overrides
If framework annotations are present, override the default path:
- `@:application` → `todo_app/application.ex`
- `@:router` → `todo_app_web/router.ex`
- `@:endpoint` → `todo_app_web/endpoint.ex`

## Comprehensive Naming Rules

### Default Rule (No Annotations)
```
Class: MyComplexClassName
Package: com.example.models
Result: lib/com/example/models/my_complex_class_name.ex
```

### Framework Annotation Rules

#### @:application
```
Class: TodoApp
Annotation: @:application
Result: lib/todo_app/application.ex
```
**Note**: The file is named `application.ex` but placed in the app's directory for better organization.

#### @:router
```
Class: TodoAppRouter
Annotation: @:router
Result: lib/todo_app_web/router.ex
```
**Special**: Always named `router.ex` regardless of class name.

#### @:liveview
```
Class: UserLive
Annotation: @:liveview
Result: lib/todo_app_web/live/user_live.ex
```
**Pattern**: Preserves the `_live` suffix for clarity.

#### @:controller
```
Class: UserController
Annotation: @:controller
Result: lib/todo_app_web/controllers/user_controller.ex
```

#### @:schema
```
Class: Todo
Annotation: @:schema
Result: lib/todo_app/schemas/todo.ex
```

#### @:endpoint
```
Class: Endpoint
Annotation: @:endpoint
Result: lib/todo_app_web/endpoint.ex
```

### Package Transformation Examples

#### Simple Package
```
Package: models
Class: User
Result: lib/models/user.ex
```

#### Nested Package
```
Package: server.contexts
Class: Users
Result: lib/server/contexts/users.ex
```

#### CamelCase Package
```
Package: MyCompany.DataModels
Class: CustomerOrder
Result: lib/my_company/data_models/customer_order.ex
```

## Implementation Details

### The DRY Naming System

```haxe
private function getComprehensiveNamingRule(classType: ClassType): {fileName: String, dirPath: String} {
    var className = classType.name;
    var packageParts = classType.pack;
    var annotationInfo = reflaxe.elixir.helpers.AnnotationSystem.detectAnnotations(classType);
    
    // 1. Start with base snake_case conversion
    var baseFileName = NamingHelper.toSnakeCase(className);
    
    // 2. Convert package parts to snake_case directories
    var snakePackageParts = packageParts.map(part -> NamingHelper.toSnakeCase(part));
    var packagePath = snakePackageParts.length > 0 ? snakePackageParts.join("/") : "";
    
    // 3. Create default rule
    var rule = {
        fileName: baseFileName,
        dirPath: packagePath
    };
    
    // 4. Apply framework-specific overrides
    if (annotationInfo.primaryAnnotation != null) {
        // ... annotation-specific logic
    }
    
    return rule;
}
```

### Integration with Reflaxe

The naming system integrates with Reflaxe's file output system:

```haxe
private function setFrameworkAwareOutputPath(classType: ClassType): Void {
    var namingRule = getComprehensiveNamingRule(classType);
    
    // Tell Reflaxe where to put the file
    setOutputFileName(namingRule.fileName);
    setOutputFileDir(namingRule.dirPath);
}
```

## Edge Cases and Special Handling

### 1. @:native Annotations
Classes with `@:native("Module.Name")` keep their native module name in the generated code but still follow file naming conventions:
```
@:native("TodoApp.Application")
class TodoApp
Result: lib/todo_app/application.ex with module TodoApp.Application
```

### 2. Acronyms and Special Cases
```
HTTPClient → http_client.ex
XMLParser → xml_parser.ex
IOManager → io_manager.ex
```

### 3. Numbers in Names
```
User2FASettings → user2fa_settings.ex
Table3Column → table3_column.ex
```

### 4. Already Snake_Case
If a class is already in snake_case (unusual but possible):
```
already_snake → already_snake.ex (no change)
```

## Benefits of This Architecture

1. **Consistency** - All files follow Elixir conventions
2. **Predictability** - Developers can easily find generated files
3. **Framework Integration** - Phoenix apps work out-of-the-box
4. **Maintainability** - Single source of truth for naming logic
5. **Extensibility** - Easy to add new annotation types

## Testing the Naming System

### Unit Test Examples
```haxe
// Test basic conversion
assert(getName("MyClass") == "my_class");

// Test package conversion
assert(getPath(["com", "example"], "User") == "com/example/user.ex");

// Test annotation override
assert(getPath([], "TodoAppRouter", "@:router") == "todo_app_web/router.ex");
```

### Integration Test
```bash
# Compile todo-app
npx haxe build-server.hxml

# Verify file structure
find lib -name "*.ex" | head -20

# Should see:
# lib/todo_app/application.ex
# lib/todo_app_web/router.ex
# lib/todo_app_web/endpoint.ex
# lib/todo_app_web/live/todo_live.ex
# lib/todo_app/schemas/todo.ex
```

## Migration Guide

### For Existing Projects
1. Delete all generated .ex files
2. Update to latest compiler with comprehensive naming
3. Regenerate all files
4. Update any manual references to old file paths

### Common Issues and Solutions

**Issue**: File not found after naming update
**Solution**: Check for framework annotations that change output location

**Issue**: Module name doesn't match file path
**Solution**: This is normal for @:native annotations - module name can differ from file name

**Issue**: Package directories not created
**Solution**: Ensure package declaration in Haxe source matches intended structure

## Bug Fixes and Historical Issues

### The Double Colon Bug
**Issue**: Supervisor options were being compiled as `::one_for_one` instead of `:one_for_one`
**Root Cause**: The compileSupervisorOptions function was adding an extra colon to enum values that already had one
**Fix**: Added detection to remove leading colon from enum values before formatting (ElixirCompiler.hx lines 5060-5067)
**Related**: This was part of a pattern of enum compilation issues where the compiler wasn't handling Elixir atoms correctly

### The TodoApp.ex Naming Bug
**Issue**: Application classes like TodoApp were generating `TodoApp.ex` instead of `todo_app.ex`
**Discovery**: User observation that file names weren't following Elixir conventions
**Root Cause**: The @:application annotation case wasn't being handled in file naming logic
**Initial Attempt**: Added @:application case but had early return bug preventing snake_case conversion
**Final Fix**: Comprehensive DRY naming system that handles all cases without early returns

### Pattern of Naming Issues
These bugs revealed a systemic issue:
1. Multiple code paths for file naming (violating DRY)
2. Early returns preventing proper snake_case conversion
3. Missing annotation cases (@:application, @:supervisor, etc.)
4. Inconsistent handling between different compiler helpers

### The DRY Solution
Created getComprehensiveNamingRule() function that:
- Centralizes ALL naming logic in one place
- Handles package-to-directory conversion
- Supports all framework annotations
- Always applies snake_case transformation (no early returns)
- Follows idiomatic Elixir/Phoenix conventions

This eliminated an entire class of bugs by having a single source of truth for file naming.

## Future Enhancements

1. **Configurable naming strategies** - Allow projects to customize naming rules
2. **Namespace prefixing** - Support vendor prefixes for libraries
3. **Multi-app support** - Handle umbrella applications with multiple apps
4. **Backward compatibility mode** - Option to use old naming for migration

## Related Documentation

- [`/documentation/COMPILER_BEST_PRACTICES.md`](COMPILER_BEST_PRACTICES.md) - Compiler development practices
- [`/documentation/FILE_GENERATION.md`](FILE_GENERATION.md) - File generation process
- [`/documentation/ANNOTATION_SYSTEM.md`](ANNOTATION_SYSTEM.md) - Framework annotation system
- [`/documentation/PHOENIX_INTEGRATION.md`](PHOENIX_INTEGRATION.md) - Phoenix framework patterns

## Summary

The comprehensive naming system ensures that every Haxe class becomes a properly named Elixir file, following BEAM conventions while supporting Phoenix framework patterns. The DRY implementation makes it easy to maintain and extend, providing a solid foundation for cross-language compilation.
</file>

<file path="docs/prds/HAXE_ELIXIR_1_0_COMPILER_TODOAPP_PRD.md">
Reflaxe.Elixir 1.0 – Compiler + Todo-App PRD
============================================

Vision
------

Deliver a production‑quality Haxe→Elixir compiler that:

- Uses a **pure AST pipeline** (TypedExpr → ElixirAST → transforms → printer).
- Generates **idiomatic Elixir/Phoenix/Ecto/OTP** code that looks hand‑written.
- Builds and runs the **todo-app** as a first‑class end‑to‑end test with:
  - Zero Haxe compiler warnings.
  - Zero Mix compile warnings (warnings‑as‑errors clean).
  - Zero runtime warnings/errors in Phoenix logs under LiveView + Playwright smoke.
- Compiles within **bounded time** – no apparent hangs, no unbounded passes.

This document ties together the existing 1.0 PRD (docs/08-roadmap/1.0-PRD.md) and the active todo‑app PRD (docs/08-roadmap/ACTIVE_PRD.md) with the latest findings about transformer performance and the regression at commit `76abdeb3`.

Non‑Negotiable Constraints
--------------------------

- **AST pipeline only**
  - All compilation must go through ElixirAST; no string concatenation emitters.
  - No alternative backdoors that bypass builders/transformers/printer.

- **No band‑aids**
  - Fix root causes instead of masking symptoms.
  - No TODOs left in production code as “temporary” workarounds.
  - No arbitrary limits added just to break infinite loops.
  - No string post‑processing to patch bad output.
  - No `-D analyzer-optimize` in server builds.

- **No app‑specific heuristics**
  - Transformers must not key behavior on todo‑app names, atoms, routes or variable names.
  - Allowed decisions are based on shape (AST, annotations, types) and documented APIs, never on domain words like “todo”, “updated_todo”, “toggle_todo”.

- **Runtime artifact rule**
  - Do not edit generated `.ex` files to fix behavior.
  - All fixes must be made in compiler `.hx` sources or std/_std Haxe sources and validated via snapshots and QA sentinel.

- **Module size constraint**
  - Any compiler `.hx` module (builders, transformers, helpers) must remain **< 2000 LOC**.
  - If approaching the limit, extract into domain modules (e.g. CaseBinderTransforms, AssignHygieneTransforms).

- **No Dynamic expansion**
  - Avoid introducing `Dynamic` in public compiler APIs or std externs.
  - Only use `Dynamic` at unavoidable boundary points; prefer precise types everywhere else.

Architectural Invariants
------------------------

The following invariants extend the 1.0 PRD (docs/08-roadmap/1.0-PRD.md) with concrete expectations for the transformer stack and performance:

- **ElixirASTTransformer is a registry, not a brain**
  - It wires passes in a clear order and forwards to domain modules.
  - It does not embed complex logic that belongs in dedicated transformers.

- **Transformers are grouped by responsibility**
  - Core semantic transforms (loops, pattern matching, Phoenix/Ecto behaviors).
  - Cosmetic/hygiene transforms (underscore/alias cleanup, unused assign removal).
  - Late, narrow sweeps (minimal final repairs only when needed).

- **Single‑pass bias**
  - Prefer single AST traversals that compose analyses rather than separate passes that re‑walk the entire tree.
  - Where multiple passes are required, each must be bounded and avoid O(N²) patterns on large modules such as `server.live.TodoLive`.

- **Target‑conditional stdlib gating**
  - Elixir specific std/_std and `__elixir__()` helpers are only placed on the classpath when the target is Elixir.
  - Macro context and non‑Elixir targets see stock Haxe stdlib.

Regression Context: 76abdeb3
----------------------------

Bisect results show that:

- The first commit where the Haxe server build for the todo‑app “hangs” (exceeds strict timeouts) is **`76abdeb3`**.
- That commit introduced a large batch of **LHS/binder/assign hygiene transformers** and rewired **ElixirASTPassRegistry** to run them.
- `server.live.TodoLive.hx` is unchanged between the known‑good baseline and HEAD; the regression is entirely in the compiler transforms and registry, not in app code.

This PRD encodes a requirement: **1.0 must ship with these transformer families architecturally sound and bounded**, and with a clear partition between semantic and cosmetic passes.

Milestones and Success Criteria
-------------------------------

### M1 – Compiler Core Stable and Snapshot Suites Green

- All snapshot categories are green:
  - Core, stdlib, regression, phoenix, ecto, otp and any cross‑migration suites.
- The AST pipeline is the only compilation path and is fully documented.
- ElixirASTPassRegistry is clearly partitioned into:
  - Core semantic passes.
  - Cosmetic hygiene passes.
  - Minimal late repair passes.
- No snapshot indicates unbounded or pathological transform behavior (no timeouts in snapshot runners under documented caps).

### M2 – Bounded Haxe Server Build for Todo-App

- Cold Haxe server build for todo‑app:
  - `cd examples/todo-app && HAXE_USE_SERVER=0 haxe build-server.hxml`
  - Completes within **< 30 seconds cold** on reference hardware.
- LiveView only pass (build-server-passF.hxml) for `server.live.TodoLive`:
  - `HAXE_USE_SERVER=0 haxe build-server-passF.hxml`
  - Completes within **< 15 seconds cold** on reference hardware.
- No Haxe step (including multi‑pass A1..F) is treated as “hanging” by our time‑bounded wrappers.

### M3 – Todo-App QA Sentinel: Zero Warnings, No Runtime Errors

- QA sentinel run for todo‑app (non‑blocking, bounded):

  - `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --async --deadline <CAP> -v`

- Guarantees:
  - Haxe build step(s) pass under caps with **zero Haxe warnings**.
  - `mix compile` (with `--warnings-as-errors` where configured) succeeds with **zero warnings**.
  - Phoenix server boots and readiness probes succeed.
  - Runtime logs show **no warnings or errors** for LiveView lifecycle, Ecto calls, or PubSub.

### M4 – Playwright Smoke and Regression Specs Within Caps

- Playwright E2E specs in `examples/todo-app/e2e/` (at least basic and search, possibly additional high‑value flows):
  - Run against the QA sentinel controlled server (or equivalent bounded server lifecycle).
  - All specs pass with total runtime **≤ 120 seconds**, ideally **≤ 60 seconds**.
  - Individual specs remain **≤ 30 seconds**.
- Selectors and flows are resilient (no flakiness due to brittle selectors).

### M5 – CI Running Bounded Sentinel + Playwright on Main

- CI pipeline runs:
  - Haxe snapshot suites.
  - QA sentinel for todo‑app with configured caps.
  - Playwright smoke/regression against the same server.
- All CI steps:
  - Complete within documented time budgets.
  - Produce **zero warnings** and **zero runtime errors**.
- Main branch reflects this configuration; legacy branches or modes that allowed hangs or unbounded passes are retired.

Transformers and Performance Requirements
-----------------------------------------

To satisfy M1–M3 for the regression case at `76abdeb3`, the following are explicit requirements:

- **Transformer profiling**
  - ElixirASTTransformer must support a `-D hxx_instrument_sys` mode that logs per‑pass timings (`[PassTiming] name=<pass> ms=<time>`).
  - We must profile `server.live.TodoLive` to identify the passes that dominate runtime, especially in the Case*/LocalAssign*/DropUnused*/SanitizeAssignLhsIdentifier/RefDeclAlignment/FinalLocalReferenceAlign/ZeroAssignCallToBareCall families.

- **Partitioning semantic vs cosmetic passes**
  - Cosmetic hygiene passes are gated behind `fast_boot` and `disable_hygiene_final` so they do not run for example/dev builds.
  - Semantic passes (required for correct code generation) remain active in all profiles but must be refactored to bounded algorithms.

- **Bounded algorithms**
  - Essential transformer passes must not perform repeated full‑AST scans that scale poorly on large modules like TodoLive.
  - Passes must:
    - Build reusable indices (maps from IDs to binders, from clause indices to metadata).
    - Avoid nested loops over all clauses or statements where possible.
    - Include explicit complexity guards and fallbacks for unusually large functions or modules.

fast_boot vs full_prepasses Profiles
------------------------------------

We distinguish two main compilation profiles:

- **fast_boot (example/dev/todo-app profile)**
  - Minimal macro loader and macro scope.
  - Core semantic transformers only.
  - Cosmetic hygiene and late heavy passes disabled or significantly reduced.
  - Used by:
    - `examples/todo-app/build-server-fast.hxml`
    - `build-server-passA1..F.hxml`
    - QA sentinel Haxe builds.

- **full_prepasses / full_hygiene (compiler/CI profile)**
  - Full macro set (HXX/HXXMacro/RouterBuildMacro/ModuleMacro) with carefully scoped triggers.
  - Full transformer stack, including hygiene passes, for maximum safety and cleanliness.
  - Used by:
    - Compiler snapshot and integration tests.
    - Specialized validation builds (e.g., gating checks or stress tests).

Todo-App as 1.0 Quality Bar
---------------------------

The existing ACTIVE_PRD (docs/08-roadmap/ACTIVE_PRD.md) defines the todo‑app as the primary quality benchmark. This PRD refines that:

- Todo‑app must:
  - Compile from Haxe to Elixir via the AST pipeline under the fast_boot profile.
  - Compile Elixir via Mix with warnings as errors.
  - Run under Phoenix with LiveView and PubSub features fully functional.
  - Pass Playwright smoke/regression specs under caps.
  - Produce no warnings or errors in logs throughout that flow.

Verification Layers
-------------------

1. **Compiler/unit layer**
   - Snapshot suites for AST → Elixir printer output.
   - Haxe‑authored ExUnit tests for key Phoenix/Ecto/OTP integration points.

2. **Integration layer**
   - QA sentinel (Haxe build + mix compile + Phoenix boot + readiness) with strict timeouts and log scanning.

3. **Application/E2E layer**
   - Playwright specs checking key todo‑app flows (home, list, search, create, toggle, edit).

All new work toward 1.0 must declare which layer(s) it verifies via and must use QA sentinel for runtime verification whenever the compiler or std changes could affect the example app.

Non‑Goals for This PRD
----------------------

- Supporting new language features or frameworks beyond what Phoenix/Ecto/OTP integration requires for 1.0.
- Introducing experimental backends or printers.
- Micro‑optimizing the generated Elixir at the expense of clarity.

Links
-----

- docs/08-roadmap/1.0-PRD.md – high‑level Reflaxe.Elixir 1.0 PRD and roadmap.
- docs/08-roadmap/ACTIVE_PRD.md – todo‑app focused 1.0 readiness PRD.
- docs/05-architecture/AST_PIPELINE_MIGRATION.md – AST pipeline migration details.
- docs/03-compiler-development/TESTING_INFRASTRUCTURE.md – snapshot and test architecture.
- docs/05-architecture/COMPILER_REFACTORING_PRD.md – refactoring goals and file size constraints.
</file>

<file path="examples/todo-app/assets/package.json">
{
  "name": "todo_app_assets",
  "version": "1.0.0",
  "description": "Assets for TodoApp Phoenix LiveView application with Haxe dual-target compilation",
  "private": true,
  "engines": {
    "node": ">=14.0.0",
    "npm": ">=6.0.0"
  },
  "scripts": {
    "build": "npm run build:haxe && npm run build:esbuild",
    "build:haxe": "cd .. && haxe build-client.hxml",
    "build:esbuild": "esbuild js/phoenix_app.js --bundle --outdir=../priv/static/assets --target=es2017",
    "build:production": "npm run build:haxe && npm run build:esbuild:production",
    "build:esbuild:production": "esbuild js/phoenix_app.js --bundle --outdir=../priv/static/assets --target=es2017 --minify --tree-shaking=true --drop:console --drop:debugger",
    "watch": "concurrently \"npm run watch:haxe\" \"npm run watch:esbuild\"",
    "watch:haxe": "cd .. && haxe build-client.hxml --wait 6001",
    "watch:esbuild": "esbuild js/phoenix_app.js --bundle --outdir=../priv/static/assets --target=es2017 --sourcemap=external --watch",
    "analyze": "esbuild js/phoenix_app.js --bundle --metafile=meta.json --analyze",
    "clean": "rm -rf ../priv/static/assets/*.js ../priv/static/assets/*.css ../priv/static/assets/*.map",
    "lint": "eslint js/**/*.js",
    "format": "prettier --write js/**/*.js css/**/*.css"
  },
  "dependencies": {
    "phoenix": "file:../deps/phoenix",
    "phoenix_html": "file:../deps/phoenix_html",
    "phoenix_live_view": "file:../deps/phoenix_live_view"
  },
  "devDependencies": {
    "@tailwindcss/forms": "^0.5.7",
    "@tailwindcss/typography": "^0.5.10",
    "autoprefixer": "^10.4.16",
    "concurrently": "^8.2.2",
    "esbuild": "^0.19.8",
    "eslint": "^8.55.0",
    "postcss": "^8.4.32",
    "postcss-import": "^15.1.0",
    "cssnano": "^6.0.1",
    "prettier": "^3.1.0",
    "tailwindcss": "^3.3.6"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/RobertBeckebans/reflaxe.elixir"
  },
  "keywords": [
    "haxe",
    "elixir",
    "phoenix",
    "liveview",
    "typescript",
    "frontend",
    "esbuild",
    "tailwind"
  ],
  "author": "Reflaxe.Elixir Contributors",
  "license": "MIT",
  "eslintConfig": {
    "env": {
      "browser": true,
      "es2017": true
    },
    "extends": [
      "eslint:recommended"
    ],
    "rules": {
      "no-unused-vars": "warn",
      "no-console": "off"
    }
  },
  "prettier": {
    "semi": true,
    "singleQuote": true,
    "tabWidth": 2,
    "trailingComma": "es5"
  },
  "browserslist": [
    "defaults",
    "not IE 11",
    "> 1%",
    "last 2 versions"
  ]
}
</file>

<file path="examples/todo-app/assets/postcss.config.js">
// PostCSS configuration for todo-app
module.exports = {
  plugins: {
    // Import CSS files
    'postcss-import': {},
    
    // Process Tailwind CSS
    tailwindcss: {},
    
    // Add vendor prefixes
    autoprefixer: {},
    
    // Minify CSS in production
    ...(process.env.NODE_ENV === 'production' ? {
      cssnano: {
        preset: 'default',
      }
    } : {})
  }
};
</file>

<file path="examples/todo-app/src_haxe/TodoApp.hx">
package;

import phoenix.Phoenix;
import elixir.otp.Application;
import elixir.otp.Supervisor.SupervisorExtern;
import elixir.otp.Supervisor.SupervisorStrategy;
import elixir.otp.Supervisor.SupervisorOptions;
import elixir.otp.TypeSafeChildSpec;
import elixir.otp.Supervisor.ChildSpecFormat;

/**
 * Main TodoApp application module
 * Defines the OTP application supervision tree
 */
@:application
@:appName("TodoApp")  
class TodoApp {
    /**
     * Start the application
     */
    @:keep
    public static function start(_type: ApplicationStartType, _args: ApplicationArgs): ApplicationResult {
        // Define children for the supervision tree using type-safe child specs
        var children: Array<ChildSpecFormat> = [
            // Database repository - Ecto.Repo handles Postgrex.TypeManager internally
            ModuleRef("TodoApp.Repo"),
            
            // PubSub system with proper child spec
            TypeSafeChildSpec.pubSub("TodoApp.PubSub"),
            
            // Presence tracker - starts Phoenix.Tracker backing ETS tables
            // Presence module defines child_spec via `use Phoenix.Presence`
            ModuleRef("TodoAppWeb.Presence"),
            
            // Telemetry supervisor
            TypeSafeChildSpec.telemetry("TodoAppWeb.Telemetry"),
            
            // Web endpoint
            TypeSafeChildSpec.endpoint("TodoAppWeb.Endpoint")
        ];

        final options: SupervisorOptions = {
            strategy: SupervisorStrategy.OneForOne,
            max_restarts: 3,
            max_seconds: 5
        };
        // Start supervisor with children using type-safe SupervisorExtern
        return SupervisorExtern.startLink(children, options);
    }

    /**
     * Called when application is preparing to shut down
     * State is whatever was returned from start/2
     */
    @:keep
    public static function prep_stop(state: Dynamic): Dynamic {
        // For now, keep Dynamic since this is rarely customized
        // and state type varies based on application needs
        return state;
    }
}
</file>

<file path="examples/todo-app/build-client.hxml">
# Haxe→JavaScript compilation for Phoenix LiveView client-side code
# Generates efficient ES6 modules compatible with esbuild

# Source directories (client only)
-cp src_haxe/client
-cp src_haxe
# Enable Genes ES6 generator (uses haxe_libraries/genes.hxml)
-lib genes

# JavaScript target output (separate from Phoenix bootstrap to avoid overwriting LiveView init)
-js assets/js/hx_app.js
-D js-unflatten               # Better module structure
# NOTE: -D analyzer-optimize removed - destroys functional patterns
--dce=full

# Haxe 4.3+ optimizations
-D real-position              # Better source maps
-D js-source-map              # Generate source maps

# Exclude server code from client compilation
--macro exclude('server')

# Main client entry point - minimal boot for Phoenix hooks
-main client.Boot
</file>

<file path="examples/todo-app/build-server-multipass.hxml">
-cp ../../std/_std
# Aggregated server build using micro-passes A..F
#
# This file exists to let tools like Mix.Tasks.Compile.Haxe run the same
# micro-pass partitioning strategy that QA sentinel uses, without hard-coding
# pass names in the compiler. It simply chains the existing pass hxml files.
#
# Passes:
#   - A1..A3: Repo and core infrastructure
#   - B..E:   additional server modules and infrastructure
#   - F:      LiveView main (TodoLive)

--next build-server-passA1.hxml
--next build-server-passA2.hxml
--next build-server-passA3.hxml
--next build-server-passB.hxml
--next build-server-passC.hxml
--next build-server-passD.hxml
--next build-server-passE.hxml
--next build-server-passF.hxml
</file>

<file path="examples/todo-app/build-server-passE.hxml">
# Pass E — application entrypoint
-lib reflaxe
-lib reflaxe.elixir
-cp ../../std/_std
-cp src_haxe
-cp src_haxe/server
-cp src_haxe/shared
-D elixir_output=lib
-D reflaxe_runtime
-D no-utf16
-D app_name=TodoApp
-dce full
--macro exclude('client')
--macro exclude('test')
-D reflaxe.elixir=0.1.0
-D hxx_string_to_sigil
-D no-traces
-D no_traces
-D fast_boot
TodoApp
</file>

<file path="examples/todo-app/build-server.hxml">
# Haxe→Elixir compilation for Phoenix LiveView server-side code
# Generates idiomatic Elixir code for the BEAM VM

# Use packaged libraries to avoid repo-level classpaths (faster, no shadowing)
-lib reflaxe
-lib reflaxe.elixir
-cp ../../std/_std

# Source directories
-cp src_haxe
-cp src_haxe/server
-cp src_haxe/shared

# Output directory for generated .ex files
-D elixir_output=lib

# Required for Reflaxe targets
-D reflaxe_runtime

# Elixir is not a UTF-16 platform
-D no-utf16

# Application-specific configuration
-D app_name=TodoApp

# Enable dead code elimination to remove unused functions
# 
# DCE (Dead Code Elimination) is CRITICAL for abstract types with operator overloads.
# Without DCE, ALL @:op annotated methods in abstracts (like Date's comparison operators)
# are compiled to helper functions in the _Impl_ module, even if never used.
# 
# Example: Date abstract defines lt, lte, gt, gte, eq, neq operators
# - Without DCE: All 6 functions generated in Date_Impl_, causing "unused function" warnings
# - With DCE full: Only used functions are kept, eliminating warnings
#
# DCE levels:
# - no: Disable DCE (causes unused function warnings)
# - std: Remove unused std library classes only
# - full: Remove all unreachable code (RECOMMENDED for production)
#
# Note: Reflaxe.Elixir correctly respects DCE - eliminated code is removed before
# transpilation, resulting in cleaner and smaller Elixir output.
-dce full

# (Optional) Debug traces for dynamic assignment fix
# Disabled by default to avoid noisy generation in some modules
# -D debug_dynamic_assignment

# Exclude client code from server compilation
--macro exclude('client')
--macro exclude('test')
--macro exclude('server.live.UserLive')
--macro exclude('server.services.UserGenServer')
## Include controllers and contexts in server build (needed for test WAE)
## (Removed earlier excludes for server.controllers.UserController and contexts.*)

# Keep Phoenix CoreComponents even if not referenced directly in Haxe
# WHY: Phoenix imports TodoAppWeb.CoreComponents via `use TodoAppWeb, :html`
# which Haxe DCE cannot see. Force-keep to ensure the module is emitted.
--macro keep('server.components.CoreComponents')
--macro keep('phoenix.DateFormat')
--macro keep('phoenix.Sorting')
# Skip problematic stdlib structures we don't use in the todo app

# Define library version and initialize compiler
-D reflaxe.elixir=0.1.0

# Debug flags are disabled by default to keep QA builds quiet and fast
# -D debug_success_unifier
# -D debug_presence

# Enable deterministic render string → ~H conversion
-D hxx_string_to_sigil

# Silence compiler debug traces for QA speed and signal clarity
# Provide both hyphenated and underscored defines for preprocessor gating compatibility
-D no-traces
-D no_traces

# Main server classes to compile
TodoApp
TodoAppRouter
server.live.TodoLive
server.schemas.Todo
server.migrations.CreateTodos
server.presence.TodoPresence
server.layouts.Layouts
server.infrastructure.Repo
server.infrastructure.Telemetry
server.infrastructure.Endpoint
server.infrastructure.TodoAppWeb
controllers.UserController
server.components.CoreComponents
server.i18n.Gettext
server.infrastructure.GettextErrorMessages
server.infrastructure.GettextUIMessages
# PostgrexTypes is now auto-generated from Repo, not a separate class
# Temporarily exclude problematic stdlib modules
# -D exclude-bytes  # Removed to test assignment extraction fix

# Force-keep controllers and contexts so WAE passes apply to their outputs
</file>

<file path="examples/todo-app/mix.exs">
defmodule TodoApp.MixProject do
  use Mix.Project

  def project do
    [
      app: :todo_app,
      version: "0.1.0",
      elixir: "~> 1.14",
      elixirc_paths: elixirc_paths(Mix.env()),
      # Ensure Haxe server-side code compiles as part of `mix compile`
      compilers: [:haxe] ++ Mix.compilers(),
      start_permanent: Mix.env() == :prod,
      aliases: aliases(),
      deps: deps(),
      haxe: [
        # Use the micro-pass server build so Mix.compilers align with QA sentinel
        # and keep Haxe server builds bounded and incremental.
        hxml_file: "build-server-multipass.hxml",
        source_dir: "src_haxe",
        target_dir: "lib",
        # Keep watcher disabled here; we start a watcher via Endpoint watchers (dev.exs)
        watch: false,
        verbose: false
      ]
    ]
  end

  # Configuration for the OTP application.
  def application do
    [
      mod: {TodoApp.Application, []},
      extra_applications: [:logger, :runtime_tools]
    ]
  end

  # Specifies which paths to compile per environment.
  defp elixirc_paths(:test), do: ["lib", "test/support"]
  defp elixirc_paths(:e2e), do: ["lib"]
  defp elixirc_paths(_), do: ["lib"]

  # Specifies your project dependencies.
  defp deps do
    [
      # Add parent project as dependency for Haxe compilation functionality
      {:reflaxe_elixir, path: "../..", only: [:dev, :test, :e2e]},
      {:phoenix, "~> 1.7.0"},
      {:phoenix_ecto, "~> 4.4"},
      {:ecto_sql, "~> 3.10"},
      {:postgrex, ">= 0.0.0"},
      {:phoenix_html, "~> 3.3"},
      {:phoenix_live_reload, "~> 1.2", only: :dev},
      {:phoenix_live_view, "~> 0.20.0"},
      {:floki, ">= 0.30.0", only: :test},
      {:phoenix_live_dashboard, "~> 0.8.0"},
      {:esbuild, "~> 0.8", runtime: Mix.env() == :dev},
      {:tailwind, "~> 0.2", runtime: Mix.env() == :dev},
      {:telemetry_metrics, "~> 0.6"},
      {:telemetry_poller, "~> 1.0"},
      {:telemetry_metrics_prometheus_core, "~> 1.0"},
      {:gettext, "~> 0.20"},
      {:jason, "~> 1.2"},
      # Webserver stack pinned for OTP 27 compatibility (see TODOAPP_COWBOY_TOOLCHAIN_ISSUE_REPORT.md)
      {:plug_cowboy, "~> 2.7.5", override: true},
      {:cowboy, "~> 2.14.2", override: true},
      {:cowlib, "~> 2.16.0", override: true},
      {:ranch, "~> 2.2", override: true},
      {:file_system, "~> 1.1", only: [:dev, :test]}
    ]
  end

  # Aliases are shortcuts or tasks specific to the current project.
  defp aliases do
    [
      setup: ["deps.get", "ecto.setup", "assets.setup", "assets.build"],
      "ecto.setup": ["ecto.create", "ecto.migrate", "run priv/repo/seeds.exs"],
      "ecto.reset": ["ecto.drop", "ecto.setup"],
      # Compile Haxe ExUnit tests before running mix test
      test: ["haxe.compile.tests", "ecto.create --quiet", "ecto.migrate --quiet", "test"],
      "assets.setup": ["tailwind.install --if-missing", "esbuild.install --if-missing"],
      "assets.build": ["haxe.compile.client", "tailwind todo_app", "esbuild todo_app"],
      "assets.deploy": ["haxe.compile.client", "tailwind todo_app --minify", "esbuild todo_app --minify --tree-shaking=true --drop:debugger --drop:console", "phx.digest"],
      "haxe.compile.client": ["cmd haxe build-client.hxml"],
      "haxe.compile.tests": ["cmd haxe build-tests.hxml"]
    ]
  end
end
</file>

<file path="lib/haxe_compiler.ex">
defmodule HaxeCompiler do
  @moduledoc """
  Core Haxe compilation functionality for Phoenix integration.
  
  Handles the execution of Haxe compilation, file watching, dependency tracking,
  and incremental compilation for optimal development workflow.
  """

  @doc """
  Compiles Haxe files using the specified build configuration.
  
  ## Options
  
    * `:hxml_file` - Path to the HXML build file (default: "build.hxml")
    * `:source_dir` - Source directory for Haxe files (default: "src_haxe")
    * `:target_dir` - Target directory for compiled files (default: "lib")
    * `:verbose` - Enable verbose output (default: false)
    * `:force` - Force full recompilation (default: false)
    
  ## Returns
  
    * `{:ok, files}` - Success with list of compiled files
    * `{:error, reason}` - Compilation failed with reason
  """
  @spec compile(keyword()) :: {:ok, [binary()]} | {:error, binary()}
  def compile(opts \\ []) do
    hxml_file = Keyword.get(opts, :hxml_file, "build.hxml")
    source_dir = Keyword.get(opts, :source_dir, "src_haxe")
    target_dir = Keyword.get(opts, :target_dir, "lib")
    verbose = Keyword.get(opts, :verbose, false)
    # Ensure HaxeServer is running in dev-like envs unless explicitly disabled
    if (Mix.env() in [:dev, :test, :e2e]) and System.get_env("HAXE_NO_SERVER") != "1" do
      try do
        unless HaxeServer.running?() do
          {:ok, _} = HaxeServer.start_link([])
        end
      rescue
        _ -> :ok
      end
    end
    
    cond do
      not File.exists?(hxml_file) ->
        {:error, "Build file not found: #{hxml_file}"}
      
      not File.exists?(source_dir) ->
        {:error, "Source directory not found: #{source_dir}"}
      
      true ->
        execute_haxe_compilation(hxml_file, source_dir, target_dir, verbose)
    end
  end

  @doc """
  Checks if any source files have been modified since the last compilation.
  
  ## Returns
  
    * `true` - Files need recompilation
    * `false` - No recompilation needed
  """
  @spec needs_recompilation?(keyword()) :: boolean()
  def needs_recompilation?(opts \\ []) do
    source_dir = Keyword.get(opts, :source_dir, "src_haxe")
    target_dir = Keyword.get(opts, :target_dir, "lib")
    force = Keyword.get(opts, :force, false)
    
    cond do
      force -> 
        true
      
      not File.exists?(target_dir) ->
        true
      
      true ->
        check_file_timestamps(source_dir, target_dir)
    end
  end

  @doc """
  Returns the list of source files that should be monitored for changes.
  """
  @spec source_files(keyword()) :: [binary()]
  def source_files(opts \\ []) do
    source_dir = Keyword.get(opts, :source_dir, "src_haxe")
    
    if File.exists?(source_dir) do
      find_haxe_files(source_dir)
    else
      []
    end
  end
  
  # Private helper functions
  
  defp execute_haxe_compilation(hxml_file, source_dir, target_dir, verbose) do
    if verbose do
      Mix.shell().info("Compiling Haxe files from #{source_dir} to #{target_dir}")
      Mix.shell().info("Using build file: #{hxml_file}")
    end
    
    # Find source files for tracking
    source_files = find_haxe_files(source_dir)
    
    if Enum.empty?(source_files) do
      {:ok, []}
    else
      # Use real Haxe compilation with Reflaxe.Elixir target
      case compile_with_real_haxe(hxml_file, source_dir, target_dir, verbose) do
        {:ok, compiled_files} ->
          if verbose do
            Mix.shell().info("Successfully compiled #{length(compiled_files)} file(s)")
          end
          {:ok, compiled_files}
        
        {:error, reason} ->
          {:error, reason}
      end
    end
  end
  
  defp check_file_timestamps(source_dir, target_dir) do
    source_files = find_haxe_files(source_dir)
    
    Enum.any?(source_files, fn source_file ->
      source_mtime = File.stat!(source_file).mtime
      
      # Convert .hx to .ex for target file check
      relative_path = Path.relative_to(source_file, source_dir)
      target_file = Path.join(target_dir, String.replace(relative_path, ".hx", ".ex"))
      
      if File.exists?(target_file) do
        target_mtime = File.stat!(target_file).mtime
        source_mtime > target_mtime
      else
        true  # Target file doesn't exist, needs compilation
      end
    end)
  end
  
  defp find_haxe_files(dir) do
    dir
    |> Path.join("**/*.hx")
    |> Path.wildcard()
    |> Enum.sort()
  end
  
  
  defp compile_with_real_haxe(hxml_file, _source_dir, target_dir, verbose) do
    # First, try to use HaxeServer for incremental compilation if available
    # Pass -D fast_boot in dev-like envs to minimize macro load during cold boots
    fast_boot? = Mix.env() in [:dev, :test, :e2e]
    common_args = (if fast_boot?, do: ["-D", "fast_boot"], else: [])
    
    compilation_result = case HaxeServer.running?() do
      true ->
        if verbose do
          Mix.shell().info("Using Haxe server for incremental compilation")
        end
        case HaxeServer.compile(common_args ++ [hxml_file]) do
          {:ok, _} = ok -> ok
          {:error, reason} ->
            # Fallback transparently to direct compile and refresh the server in background
            if verbose do
              Mix.shell().info("Haxe server compile failed; falling back to direct compile (#{reason})")
            end
            Task.start(fn ->
              # best effort restart without impacting current compile
              try do HaxeServer.stop() rescue _ -> :ok end
              try do HaxeServer.start_link([]) rescue _ -> :ok end
            end)
            compile_with_direct_haxe(hxml_file, verbose, common_args)
        end
      false ->
        if verbose do
          Mix.shell().info("Using direct Haxe compilation")
        end
        compile_with_direct_haxe(hxml_file, verbose, common_args)
    end
    
    case compilation_result do
      {:ok, _output} ->
        # Compilation succeeded, find generated .ex files
        compiled_files = find_generated_elixir_files(target_dir)
        {:ok, compiled_files}
        
      {:error, reason} ->
        {:error, reason}
    end
  rescue
    error ->
      {:error, "Haxe compilation failed: #{Exception.message(error)}"}
  end
  
  defp compile_with_direct_haxe(hxml_file, verbose, common_args \\ []) do
    {haxe_cmd, cmd_args} = get_haxe_command()
    args = cmd_args ++ common_args ++ [hxml_file]
    
    if verbose do
      Mix.shell().info("Running: #{haxe_cmd} #{Enum.join(args, " ")}")
    end
    
    # Build environment for Haxe command
    env = build_haxe_env()
    
    # Change to the directory containing the hxml file so relative paths work
    cmd_opts = case Path.dirname(hxml_file) do
      "." -> [stderr_to_stdout: true, env: env]
      dir -> [cd: dir, stderr_to_stdout: true, env: env]
    end
    
    # Use just the filename if we're changing directory
    final_hxml = if Keyword.has_key?(cmd_opts, :cd) do
      Path.basename(hxml_file)
    else
      hxml_file
    end
    
    args = cmd_args ++ common_args ++ [final_hxml]
    
    case System.cmd(haxe_cmd, args, cmd_opts) do
      {output, 0} ->
        {:ok, output}
      {output, exit_code} ->
        # Parse structured error information from Haxe output
        structured_errors = parse_haxe_errors(output)
        store_compilation_errors(structured_errors)
        
        {:error, "Haxe compilation failed (exit #{exit_code}): #{output}"}
    end
  rescue
    error ->
      {:error, "Failed to execute Haxe: #{Exception.message(error)}"}
  end
  
  defp find_generated_elixir_files(target_dir) do
    if File.exists?(target_dir) do
      target_dir
      |> Path.join("**/*.ex")
      |> Path.wildcard()
      |> Enum.sort()
    else
      []
    end
  end
  
  @doc """
  Parses Haxe compiler error output into structured format for LLM agents.
  
  Returns list of structured error maps with file, line, column, error type, 
  message, and stacktrace information.
  """
  def parse_haxe_errors(output) when is_binary(output) do
    errors = output
    |> String.split("\n")
    |> Enum.reduce([], fn line, acc ->
      case parse_error_line(line) do
        nil -> acc
        error -> [error | acc]
      end
    end)
    |> Enum.reverse()
    |> add_error_ids()
    
    # Automatically store errors for retrieval by Mix tasks
    store_compilation_errors(errors)
    
    errors
  end
  
  @doc """
  Returns stored compilation errors in structured format.
  """
  def get_compilation_errors(format \\ :map) do
    # Ensure ETS table exists
    case :ets.whereis(:haxe_errors) do
      :undefined ->
        # Table doesn't exist, return empty
        case format do
          :json -> "[]"
          :map -> []
        end
      
      _table ->
        # Table exists, try to get errors
        case :ets.lookup(:haxe_errors, :current_errors) do
          [{:current_errors, errors}] ->
            case format do
              :json -> 
                if Code.ensure_loaded?(Jason) do
                  Jason.encode!(errors)
                else
                  inspect(errors)
                end
              :map -> errors
            end
          [] -> 
            case format do
              :json -> "[]"
              :map -> []
            end
        end
    end
  end
  
  @doc """
  Clears stored compilation errors.
  """
  def clear_compilation_errors() do
    case :ets.whereis(:haxe_errors) do
      :undefined -> :ok  # Table doesn't exist, nothing to clear
      _ -> :ets.delete_all_objects(:haxe_errors)
    end
  end
  
  # Private error parsing functions
  
  defp parse_error_line(line) do
    cond do
      # Haxe error format: "src/Main.hx:10: characters 5-12 : Type not found : UnknownType"
      String.match?(line, ~r/\.hx:\d+:/) ->
        parse_standard_error(line)
      
      # Stack trace lines: "    at Main.main (src/Main.hx line 10)"  
      String.match?(line, ~r/\s+at\s+.*\.hx\s+line\s+\d+/) ->
        parse_stacktrace_line(line)
      
      # Warning format: "Warning : ..."
      String.starts_with?(line, "Warning :") ->
        parse_warning(line)
        
      true ->
        nil
    end
  end
  
  defp parse_standard_error(line) do
    # Try pattern with character positions first: "file.hx:line: characters start-end : message"
    case Regex.run(~r/(.+\.hx):(\d+):\s+characters\s+(\d+)-(\d+)\s*:\s*(.*)/, line) do
      [_, file, line_str, col_start, col_end, full_message] ->
        # For real Haxe errors, try to extract error type from the message
        {error_type, message} = extract_error_type_from_message(full_message)
        
        %{
          type: :compilation_error,
          level: :haxe,
          file: Path.relative_to_cwd(file),
          line: String.to_integer(line_str),
          column_start: parse_column(col_start),
          column_end: parse_column(col_end),
          error_type: error_type,
          message: message,
          raw_line: line,
          timestamp: DateTime.utc_now(),
          stacktrace: []
        }
      
      _ ->
        # Try simpler pattern without character positions: "file.hx:line: message"
        case Regex.run(~r/(.+\.hx):(\d+):\s*(.*)/, line) do
          [_, file, line_str, full_message] ->
            {error_type, message} = extract_error_type_from_message(full_message)
            
            %{
              type: :compilation_error,
              level: :haxe,
              file: Path.relative_to_cwd(file),
              line: String.to_integer(line_str),
              column_start: nil,
              column_end: nil,
              error_type: error_type,
              message: message,
              raw_line: line,
              timestamp: DateTime.utc_now(),
              stacktrace: []
            }
            
          _ -> nil
        end
    end
  end
  
  defp parse_stacktrace_line(line) do
    # Parse pattern: "    at Main.main (src/Main.hx line 10)"
    case Regex.run(~r/\s+at\s+(.*?)\s+\((.+\.hx)\s+line\s+(\d+)\)/, line) do
      [_, function_call, file, line_str] ->
        %{
          type: :stacktrace,
          level: :haxe,
          function_call: String.trim(function_call),
          file: Path.relative_to_cwd(file),
          line: String.to_integer(line_str),
          raw_line: line,
          timestamp: DateTime.utc_now()
        }
      
      _ -> nil
    end
  end
  
  defp parse_warning(line) do
    message = String.trim(String.replace_prefix(line, "Warning :", ""))
    
    # Try to extract file information from warning message
    {file, clean_message} = case Regex.run(~r/in\s+(.+\.hx)/, message) do
      [_, file_path] ->
        clean_msg = message |> String.replace(~r/\s+in\s+.+\.hx/, "")
        {Path.relative_to_cwd(file_path), clean_msg}
      _ ->
        {nil, message}
    end
    
    %{
      type: :warning,
      level: :haxe,
      file: file,
      message: String.trim(clean_message),
      raw_line: line,
      timestamp: DateTime.utc_now()
    }
  end
  
  defp parse_column(nil), do: nil
  defp parse_column(""), do: nil
  defp parse_column(col_str), do: String.to_integer(col_str)
  
  defp extract_error_type_from_message(full_message) do
    full_message = String.trim(full_message)
    
    cond do
      # "Type not found : SomeType"
      String.starts_with?(full_message, "Type not found") ->
        case String.split(full_message, ":", parts: 2) do
          [type_part, message_part] ->
            {String.trim(type_part), String.trim(message_part)}
          _ ->
            {"Type not found", full_message}
        end
      
      # "has no field fieldName"  
      String.contains?(full_message, "has no field") ->
        {"Field not found", full_message}
      
      # "Missing ;" or other syntax errors
      String.match?(full_message, ~r/Missing|Expected|Unexpected/) ->
        {"Syntax Error", full_message}
        
      # Default: try to split on first colon, otherwise use full message
      String.contains?(full_message, ":") ->
        case String.split(full_message, ":", parts: 2) do
          [type_part, message_part] when byte_size(type_part) < 50 ->
            {String.trim(type_part), String.trim(message_part)}
          _ ->
            {"Compilation Error", full_message}
        end
        
      true ->
        {"Compilation Error", full_message}
    end
  end
  
  defp add_error_ids(errors) do
    errors
    |> Enum.with_index()
    |> Enum.map(fn {error, index} ->
      Map.put(error, :error_id, "haxe_error_#{System.system_time(:microsecond)}_#{index}")
    end)
  end
  
  @doc """
  Stores compilation errors in ETS table for later retrieval by Mix tasks.
  """
  def store_compilation_errors(errors) do
    # Initialize ETS table if it doesn't exist
    case :ets.whereis(:haxe_errors) do
      :undefined ->
        :ets.new(:haxe_errors, [:named_table, :set, :public])
      _ -> :ok
    end
    
    # Enhance errors with source mapping information before storing
    enhanced_errors = SourceMapLookup.enhance_errors_with_source_mapping(errors)
    
    # Store enhanced errors
    :ets.insert(:haxe_errors, {:current_errors, enhanced_errors})
    
    # Also store with timestamp for history
    timestamp = System.system_time(:microsecond)
    :ets.insert(:haxe_errors, {{:errors_at, timestamp}, errors})
  end
  
  defp get_haxe_command() do
    # First check if HAXE_PATH environment variable is set (used in tests)
    # This allows tests to explicitly control which Haxe binary to use
    env_haxe = System.get_env("HAXE_PATH")
    
    # Try to find the project's lix-managed haxe binary
    # This ensures we use the correct version even when running from temp directories
    project_root = find_project_root()
    project_haxe = Path.join([project_root, "node_modules", ".bin", "haxe"])
    
    cond do
      # Respect HAXE_PATH environment variable if set (highest priority)
      env_haxe && File.exists?(env_haxe) ->
        {env_haxe, []}
      
      # Check for project's lix-managed haxe
      File.exists?(project_haxe) ->
        {project_haxe, []}
      
      # Check if npx is available (fallback)
      System.find_executable("npx") != nil ->
        {"npx", ["haxe"]}
      
      # Check if haxe is directly available
      System.find_executable("haxe") != nil ->
        {"haxe", []}
      
      # Try common installation paths
      File.exists?("/opt/homebrew/bin/haxe") ->
        {"/opt/homebrew/bin/haxe", []}
      
      File.exists?("/usr/local/bin/haxe") ->
        {"/usr/local/bin/haxe", []}
        
      true ->
        # Final fallback - will likely fail but provides clear error
        {"haxe", []}
    end
  end
  
  defp find_project_root() do
    # Try to find the project root by looking for mix.exs or package.json
    # Start from current directory and walk up
    find_project_root_from(File.cwd!())
  end
  
  defp find_project_root_from(dir) do
    cond do
      # Found project markers
      File.exists?(Path.join(dir, "mix.exs")) or 
      File.exists?(Path.join(dir, "package.json")) ->
        dir
      
      # Reached root directory
      dir == "/" or dir == Path.dirname(dir) ->
        # Default to current directory if we can't find project root
        File.cwd!()
      
      # Keep searching up
      true ->
        find_project_root_from(Path.dirname(dir))
    end
  end
  
  defp build_haxe_env() do
    # Start with current environment
    base_env = System.get_env() |> Enum.into([])
    
    # Add or override specific Haxe environment variables
    haxe_env = [
      # If HAXELIB_PATH is set (by tests), include it
      {"HAXELIB_PATH", System.get_env("HAXELIB_PATH")},
      # Include the project's haxe_libraries path as fallback
      {"HAXEPATH", Path.join(find_project_root(), "haxe_libraries")}
    ]
    |> Enum.filter(fn {_key, value} -> value != nil end)
    |> Enum.into(%{})
    
    # Merge with base environment
    Map.merge(base_env |> Enum.into(%{}), haxe_env)
    |> Enum.into([])
  end
  
end
</file>

<file path="scripts/qa-sentinel.sh">
#!/usr/bin/env bash
set -euo pipefail
# Disable job control notifications to avoid background job status lines like "Killed: 9"
set +m

# ============================================================================
# QA Sentinel: Non‑Blocking Phoenix App Validation (Haxe→Elixir→Runtime)
# ============================================================================
# WHAT
# - Builds the project (Haxe→Elixir), resolves Mix deps, compiles Elixir,
#   launches Phoenix in the background, probes readiness, curls endpoints, and
#   scans logs for errors — with strict non‑blocking behavior.
#
# WHY
# - Agents shouldn’t block on long compilation/runtime tasks. This script provides
#   robust timeouts, visible progress, and an async mode that returns immediately
#   while the full validation runs in the background with logs you can tail.
#
# USAGE
#   scripts/qa-sentinel.sh [--app PATH] [--port N] [--keep-alive] [--verbose] [--async] [--deadline SECS]
#
# FLAGS
#   --app PATH       Default: examples/todo-app
#   --port N         Default: 4001 (auto-detect Phoenix-reported port fallback)
#   --env NAME       Mix environment (dev|test|e2e|prod). Default: dev
#   --reuse-db       For non-dev envs, do not drop DB; ensure created + migrate only
#   --seeds PATH     Run a seeds script after migrations (e.g., priv/repo/seeds.e2e.exs)
#   --keep-alive     Do not kill Phoenix on exit; print PHX_PID and PORT
#   --verbose|-v     Print shell commands and tail logs during probes
#   --async          Dispatch pipeline to background and return immediately
#   --deadline SECS  Hard cap: watchdog kills background job after SECS
#   --playwright       After readiness, run Playwright tests (defaults to e2e under --app)
#   --e2e-spec ARG     Playwright spec selector (relative to --app), e.g. e2e or e2e/*.spec.ts
#                       NOTE: pass globs UNQUOTED so the shell expands them: --e2e-spec e2e/*.spec.ts
#   --e2e-workers NUM  Playwright workers to use (default: 1 for determinism in extended runs)
#
# QA LAYERS (Mapping)
#   Layer 1 – Compiler snapshot tests (Haxe)
#     - Outside this script; run: `make -C test summary` (and `summary-negative`)
#     - Validates AST→Elixir printer shapes and transforms deterministically.
#   Layer 2 – Integration (compiler→Phoenix runtime)
#     - This script Steps 1–6: Haxe build → deps → mix compile → boot → readiness → GET / + log scan
#     - Examples:
#         Quick: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001`
#         Async: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --async --deadline 300`
#         Keep:  `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --keep-alive -v`
#   Layer 3 – App E2E (browser)
#     - Optional Step 7 when `--playwright` is used
#     - Use a dedicated env `--env e2e` (separate DB, server=true, PORT honored)
#     - Run entire E2E via sentinel: `scripts/qa-sentinel.sh --app examples/todo-app --env e2e --port 4011 --playwright --e2e-spec "e2e/*.spec.ts" --deadline 600`
#     - Or standalone against a keep-alive server: `BASE_URL=http://localhost:$PORT npx -C examples/todo-app playwright test`
#   Testing Trophy Guidance
#     - Most coverage via Haxe-authored ExUnit (LiveView/ConnTest)
#     - Keep Playwright a thin smoke/regression layer (<1 minute total)
#
# TDD LOOP (Recommended)
#   1) Write/adjust a Playwright spec in examples/todo-app/e2e/ to describe the user-visible behavior.
#   2) Start server non-blocking: scripts/qa-sentinel.sh --app examples/todo-app --env e2e --port 4011 --keep-alive -v
#   3) Run: BASE_URL=http://localhost:4001 npx -C examples/todo-app playwright test e2e/<spec>.ts
#   4) Implement the fix generically (no app-coupling) and re-run with --playwright:
#      scripts/qa-sentinel.sh --app examples/todo-app --env e2e --port 4011 --playwright --e2e-spec "e2e/<spec>.ts" --deadline 600
#   --playwright     After readiness, run Playwright tests (examples/todo-app/e2e/*.spec.ts by default)
#   --e2e-spec GLOB  Playwright spec or glob (relative to --app); default: e2e/*.spec.ts
#
# ENV (timeouts/probes)
#   BUILD_TIMEOUT      Haxe build timeout (default: 300s)
#   DEPS_TIMEOUT       mix deps.get timeout (default: 300s)
#   COMPILE_TIMEOUT    mix compile timeout (default: 300s)
#   READY_PROBES       Readiness probes (default: 60) at 0.5s interval
#   PROGRESS_INTERVAL  Heartbeat interval in seconds (default: 10)
#
# OUTPUT / LOGS
#   /tmp/qa-haxe.log         Haxe build output
#   /tmp/qa-mix-deps.log     Mix deps.get output
#   /tmp/qa-mix-compile.log  Mix compile output
#   /tmp/qa-phx.log          Phoenix server output (background)
#   /tmp/qa-index.html       GET / response on success
#   Async mode main log: /tmp/qa-sentinel.<RUN_ID>.log
#
# NON‑BLOCKING DESIGN
#   - Per‑step timeouts guard against hangs.
#   - Heartbeat prints progress every PROGRESS_INTERVAL seconds.
#   - Async mode returns immediately with PIDs + log paths; optional watchdog.
#   - Background server is torn down unless --keep-alive is used.
#
# EXAMPLES
#   scripts/qa-sentinel.sh --verbose --async --deadline 120
#   BUILD_TIMEOUT=420s COMPILE_TIMEOUT=420s READY_PROBES=120 \
#     scripts/qa-sentinel.sh --verbose --async --deadline 300
#   PROGRESS_INTERVAL=5 scripts/qa-sentinel.sh --verbose
#
# TROUBLESHOOTING
#   - Haxe stalls:  tail -n 80 /tmp/qa-haxe.log
#   - Mix errors:   tail -n 80 /tmp/qa-mix-*.log
#   - Phoenix boot: tail -n 80 /tmp/qa-phx.log
#   - Kill async:   kill -TERM $QA_SENTINEL_PID
# ============================================================================

# Resolve script dir to reference repo-root tools regardless of cwd
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
APP_DIR="examples/todo-app"
PORT=4001
ENV_NAME="dev"
REUSE_DB=0
SEEDS_FILE=""
KEEP_ALIVE=0
VERBOSE=0
# Noise control
NO_HEARTBEAT=0
QUIET=0
# Non-blocking options
ASYNC=0
DEADLINE=""
# Optional E2E
RUN_PLAYWRIGHT=0
E2E_WORKERS=1
# Default to fast, stable smoke specs; override with --e2e-spec as needed
E2E_SPEC="e2e/basic.spec.ts e2e/search.spec.ts e2e/create_todo.spec.ts"
# Timeouts and probe counts (sane defaults; configurable via env)
BUILD_TIMEOUT=${BUILD_TIMEOUT:-300s}
# Optional prewarm to reduce first-build times using the Haxe compilation server
PREWARM_TIMEOUT=${PREWARM_TIMEOUT:-0}
DEPS_TIMEOUT=${DEPS_TIMEOUT:-300s}
COMPILE_TIMEOUT=${COMPILE_TIMEOUT:-300s}
READY_PROBES=${READY_PROBES:-60}
# Heartbeat interval while long steps run (seconds)
PROGRESS_INTERVAL=${PROGRESS_INTERVAL:-10}

while [[ $# -gt 0 ]]; do
  case "$1" in
    --app) APP_DIR="$2"; shift 2 ;;
    --port) PORT="$2"; shift 2 ;;
    --env) ENV_NAME="$2"; shift 2 ;;
    --reuse-db) REUSE_DB=1; shift 1 ;;
    --seeds) SEEDS_FILE="$2"; shift 2 ;;
    --keep-alive) KEEP_ALIVE=1; shift 1 ;;
    --verbose|-v) VERBOSE=1; shift 1 ;;
    --async) ASYNC=1; shift 1 ;;
    --playwright) RUN_PLAYWRIGHT=1; shift 1 ;;
    --e2e-spec) E2E_SPEC="$2"; shift 2 ;;
    --e2e-workers) E2E_WORKERS="$2"; shift 2 ;;
    --no-heartbeat) NO_HEARTBEAT=1; shift 1 ;;
    --quiet|-q) QUIET=1; VERBOSE=0; shift 1 ;;
    --deadline) DEADLINE="$2"; shift 2 ;;
    *) echo "Unknown arg: $1"; exit 2 ;;
  esac
done

# If Playwright is requested and no explicit env provided (still 'dev'),
# default to e2e for proper DB isolation and server settings
if [[ "$RUN_PLAYWRIGHT" -eq 1 && "$ENV_NAME" == "dev" ]]; then
  ENV_NAME="e2e"
fi

ts() { date "+%Y-%m-%d %H:%M:%S"; }
log() { if [[ "${QUIET:-0}" -eq 0 ]]; then echo "[$(ts)] $*"; fi }
run() { if [[ "$VERBOSE" -eq 1 ]]; then set -x; fi; "$@"; local rc=$?; if [[ "$VERBOSE" -eq 1 ]]; then set +x; fi; return $rc; }

# Wrapper to run a command with optional timeout and logging to a file.
# Usage: run_step_with_log "Desc" timeout_spec logfile "cmd …"
run_step_with_log() {
  local desc="$1"; shift
  local timeout_val="$1"; shift
  local logfile="$1"; shift
  local cmd="$*"

  local start_ts
  start_ts=$(date +%s)

  log "[QA] ${desc} (timeout=${timeout_val})"

  # Fresh logfile for this run
  : > "$logfile"

  # Heartbeat so callers see progress even for quiet commands
  local heartbeat_pid=""
  if [[ "${NO_HEARTBEAT:-0}" -eq 0 ]]; then
    (
      while true; do
        sleep "${PROGRESS_INTERVAL:-10}"
        log "[QA] .. ${desc} still running"
      done
    ) >/dev/null 2>&1 &
    heartbeat_pid=$!
    # Ensure heartbeat is always stopped when this function returns
    local __hb="$heartbeat_pid"
    trap 'if [[ -n "$__hb" ]] && kill -0 "$__hb" 2>/dev/null; then kill "$__hb" 2>/dev/null || true; wait "$__hb" 2>/dev/null || true; fi' RETURN
  fi

  local rc=0
  local WRAP_TIMEOUT="$SCRIPT_DIR/with-timeout.sh"

  # Normalise "300s" -> "300" for the wrapper/manual fallback
  local secs
  secs=$(echo "$timeout_val" | sed -E 's/[^0-9]//g')
  if [[ -z "$secs" ]]; then secs=300; fi

  if [[ -x "$WRAP_TIMEOUT" ]]; then
    # Preferred path: our PGID/session‑killer wrapper
    "$WRAP_TIMEOUT" --secs "$secs" --cwd "$(pwd)" -- bash -lc "$cmd" >>"$logfile" 2>&1
    rc=$?
  elif command -v timeout >/dev/null 2>&1; then
    timeout "$timeout_val" bash -lc "$cmd" >>"$logfile" 2>&1
    rc=$?
  elif command -v gtimeout >/dev/null 2>&1; then
    gtimeout "$timeout_val" bash -lc "$cmd" >>"$logfile" 2>&1
    rc=$?
  else
    # Last‑resort manual timeout: background + watchdog loop
    set +e
    bash -lc "$cmd" >>"$logfile" 2>&1 &
    local cmd_pid=$!
    local start
    start=$(date +%s)

    while true; do
      if ! kill -0 "$cmd_pid" 2>/dev/null; then
        wait "$cmd_pid"
        rc=$?
        break
      fi
      local now elapsed
      now=$(date +%s)
      elapsed=$(( now - start ))
      if (( elapsed > secs )); then
        echo "[$(ts)] [QA] ⏳ Timeout (${secs}s) reached for ${desc}. Terminating PID ${cmd_pid}" >>"$logfile"
        kill -TERM "$cmd_pid" >/dev/null 2>&1 || true
        sleep 1
        kill -KILL "$cmd_pid" >/dev/null 2>&1 || true
        rc=124
        break
      fi
    done
    set -e
  fi

  local end_ts
  end_ts=$(date +%s)
  local dur=$(( end_ts - start_ts ))

  # Stop heartbeat once step finishes (in addition to RETURN trap)
  if [[ -n "$heartbeat_pid" ]] && kill -0 "$heartbeat_pid" 2>/dev/null; then
    kill "$heartbeat_pid" >/dev/null 2>&1 || true
    wait "$heartbeat_pid" 2>/dev/null || true
  fi
  # Clear the RETURN trap for subsequent calls
  trap - RETURN || true

  # Mirror output to console on failure or when verbose
  if [[ "$VERBOSE" -eq 1 || ( "${QUIET:-0}" -eq 0 && "$rc" -ne 0 ) ]]; then
    tail -n +1 "$logfile" | tail -n 200 || true
  fi

  if [[ "$rc" -ne 0 ]]; then
    log "[QA] ❌ ${desc} failed (rc=$rc, ${dur}s). Last 100 lines:"
    tail -n 100 "$logfile" || true
    return "$rc"
  fi

  log "[QA] ✅ ${desc} OK (${dur}s)"
  return 0
}

# Best-effort variant: never fails the pipeline; logs informative status
run_step_best_effort() {
  local desc="$1"; shift
  local timeout_val="$1"; shift
  local logfile="$1"; shift
  local cmd="$*"
  # Run the normal step but in a subshell to capture rc without exiting callers
  run_step_with_log "$desc" "$timeout_val" "$logfile" "$cmd" || true
  return 0
}

# Async launcher: re-invoke this script in background and return immediately
if [[ "${ASYNC}" -eq 1 && "${ASYNC_CHILD:-0}" -eq 0 ]]; then
  RUN_ID=$(date +%s)
  LOG_MAIN="/tmp/qa-sentinel.${RUN_ID}.log"
  # Reconstruct flags (omit --async to avoid recursion)
  CHILD_FLAGS=("--app" "$APP_DIR" "--port" "$PORT" "--env" "$ENV_NAME")
  if [[ "$REUSE_DB" -eq 1 ]]; then CHILD_FLAGS+=("--reuse-db"); fi
  if [[ "$KEEP_ALIVE" -eq 1 ]]; then CHILD_FLAGS+=("--keep-alive"); fi
  if [[ "$VERBOSE" -eq 1 ]]; then CHILD_FLAGS+=("--verbose"); fi
  if [[ "$QUIET" -eq 1 ]]; then CHILD_FLAGS+=("--quiet"); fi
  if [[ "$NO_HEARTBEAT" -eq 1 ]]; then CHILD_FLAGS+=("--no-heartbeat"); fi
  if [[ "$RUN_PLAYWRIGHT" -eq 1 ]]; then
    CHILD_FLAGS+=("--playwright" "--e2e-spec" "$E2E_SPEC" "--e2e-workers" "$E2E_WORKERS")
  fi
  log "[QA] Async mode: dispatching background sentinel (RUN_ID=$RUN_ID)"
  # Launch background child fully detached; prefer setsid, fallback to nohup.
  # Avoid nested bash -lc quoting that previously caused "unexpected EOF" when
  # E2E_SPEC contained spaces. Invoke the script directly with an argv array.
  CHILD_CMD=( "$0" "${CHILD_FLAGS[@]}" )
  if command -v setsid >/dev/null 2>&1; then
    setsid env ASYNC_CHILD=1 E2E_SPEC="$E2E_SPEC" E2E_WORKERS="$E2E_WORKERS" QA_SKIP_HAXE="${QA_SKIP_HAXE:-}" QA_FORCE_FAST_BUILD="${QA_FORCE_FAST_BUILD:-}" BUILD_TIMEOUT="$BUILD_TIMEOUT" DEPS_TIMEOUT="$DEPS_TIMEOUT" COMPILE_TIMEOUT="$COMPILE_TIMEOUT" READY_PROBES="$READY_PROBES" PROGRESS_INTERVAL="$PROGRESS_INTERVAL" PORT="$PORT" APP_DIR="$APP_DIR" KEEP_ALIVE="$KEEP_ALIVE" VERBOSE="$VERBOSE" NO_HEARTBEAT="$NO_HEARTBEAT" QUIET="$QUIET" "${CHILD_CMD[@]}" </dev/null >"$LOG_MAIN" 2>&1 &
  else
    nohup env ASYNC_CHILD=1 E2E_SPEC="$E2E_SPEC" E2E_WORKERS="$E2E_WORKERS" QA_SKIP_HAXE="${QA_SKIP_HAXE:-}" QA_FORCE_FAST_BUILD="${QA_FORCE_FAST_BUILD:-}" BUILD_TIMEOUT="$BUILD_TIMEOUT" DEPS_TIMEOUT="$DEPS_TIMEOUT" COMPILE_TIMEOUT="$COMPILE_TIMEOUT" READY_PROBES="$READY_PROBES" PROGRESS_INTERVAL="$PROGRESS_INTERVAL" PORT="$PORT" APP_DIR="$APP_DIR" KEEP_ALIVE="$KEEP_ALIVE" VERBOSE="$VERBOSE" NO_HEARTBEAT="$NO_HEARTBEAT" QUIET="$QUIET" "${CHILD_CMD[@]}" </dev/null >"$LOG_MAIN" 2>&1 &
  fi
  SENTINEL_PID=$!
  # Disown the child so shells never warn/wait on background jobs
  { disown "$SENTINEL_PID" 2>/dev/null || true; } >/dev/null 2>&1
  if [[ -n "$DEADLINE" ]]; then
    ( sleep "$DEADLINE"; kill -TERM "$SENTINEL_PID" >/dev/null 2>&1 || true; sleep 1; kill -KILL "$SENTINEL_PID" >/dev/null 2>&1 || true ) </dev/null >/dev/null 2>&1 &
    WATCHDOG_PID=$!
    { disown "$WATCHDOG_PID" 2>/dev/null || true; } >/dev/null 2>&1
    log "[QA] Async watchdog enabled: DEADLINE=$DEADLINE (PID=$WATCHDOG_PID)"
  fi
  echo "QA_SENTINEL_PID=$SENTINEL_PID"
  echo "QA_SENTINEL_RUN_ID=$RUN_ID"
  echo "QA_SENTINEL_LOG=$LOG_MAIN"
  echo "TIP: View logs without blocking: scripts/qa-logpeek.sh --run-id $RUN_ID --last 200 --follow 30" >&2
  exit 0
fi

on_exit() {
  local rc=$?
  # Only report DONE for the actual runner (not the async launcher)
  # ASYNC_CHILD=1 is set for the background process; or ASYNC=0 for sync mode
  if [[ "${ASYNC_CHILD:-0}" -eq 1 || "${ASYNC}" -eq 0 ]]; then
    echo "[$(ts)] [QA] DONE status=${rc}"
  fi
}

trap on_exit EXIT

log "[QA] Starting QA Sentinel in $APP_DIR"
log "[QA] Plan:"
log "[QA]  1) Haxe build (BUILD_TIMEOUT=$BUILD_TIMEOUT)"
log "[QA]  2) mix deps.get (DEPS_TIMEOUT=$DEPS_TIMEOUT)"
log "[QA]  3) mix compile (COMPILE_TIMEOUT=$COMPILE_TIMEOUT)"
log "[QA]  4) Start Phoenix (background, non-blocking)"
log "[QA]  5) Readiness probe (READY_PROBES=$READY_PROBES, 0.5s interval)"
log "[QA]  6) GET /, scan logs, teardown (unless --keep-alive)"
if [[ "$RUN_PLAYWRIGHT" -eq 1 ]]; then
  log "[QA]  7) Run Playwright E2E (spec: ${E2E_SPEC:-e2e}, workers: ${E2E_WORKERS})"
fi
log "[QA] Config: PORT=$PORT ENV=$ENV_NAME KEEP_ALIVE=$KEEP_ALIVE VERBOSE=$VERBOSE"

# Optional overall deadline for synchronous mode too
if [[ -n "${DEADLINE}" && "${ASYNC}" -eq 0 ]]; then
  log "[QA] Overall deadline enabled: ${DEADLINE} (synchronous watchdog)"
  (
    # Use a subshell watchdog to terminate this script if deadline elapses
    sleep "${DEADLINE}" || true
    echo "[$(ts)] [QA] ⏳ Overall deadline reached (${DEADLINE}). Collecting logs and terminating."
    # Print last lines of known logs to aid debugging
    for f in /tmp/qa-haxe.log /tmp/qa-mix-deps.log /tmp/qa-mix-compile.log /tmp/qa-phx.log; do
      if [[ -s "$f" ]]; then
        echo "[$(ts)] [QA] --- Tail of ${f} ---"; tail -n 80 "$f"; echo
      fi
    done
    # Send TERM to the main shell to trigger cleanup trap
    kill -TERM $$ >/dev/null 2>&1 || true
  ) &
  OVERALL_WATCHDOG_PID=$!
  # Don’t keep a disowned child that shells may whine about
  { disown "$OVERALL_WATCHDOG_PID" 2>/dev/null || true; } >/dev/null 2>&1
fi
pushd "$APP_DIR" >/dev/null

# Use a unique build root to avoid lock contention with other shells/editors
RUN_TAG=${RUN_TAG:-$(date +%s)}
QA_BUILD_ROOT=${QA_BUILD_ROOT:-/tmp/qa-build.${RUN_TAG}}
mkdir -p "$QA_BUILD_ROOT" >/dev/null 2>&1 || true
# Ensure these are visible to all nested shells invoked via bash -lc
export QA_BUILD_ROOT
export ENV_NAME

# Prefer explicit override, else system haxe, else npx
if [[ -n "${HAXE_CMD:-}" ]]; then
  HAXE_CMD="$HAXE_CMD"
elif command -v haxe >/dev/null 2>&1; then
  HAXE_CMD="haxe"
else
  HAXE_CMD="npx -y haxe"
fi

# Optional: Haxe compilation server for faster repeated builds (warm cache)
HAXE_SERVER_PORT=${HAXE_SERVER_PORT:-6116}
# Default off to avoid hangs on systems without a running server
# Default ON to leverage incremental cache between passes; falls back to direct
# haxe if the server fails to start or connect.
HAXE_USE_SERVER=${HAXE_USE_SERVER:-1}
if [[ "$HAXE_USE_SERVER" -eq 1 ]] && command -v haxe >/dev/null 2>&1; then
  # Best-effort start of the Haxe compilation server; do not rely on nc
  ( nohup haxe --wait "$HAXE_SERVER_PORT" >/tmp/qa-haxe-server.log 2>&1 & echo $! > /tmp/qa-haxe-server.pid ) >/dev/null 2>&1 || true
  # Keep using plain HAXE_CMD unless caller explicitly set HAXE_USE_SERVER=1
  HAXE_CMD="$HAXE_CMD --connect $HAXE_SERVER_PORT"
  # Quick readiness probe (bounded). If the server is not reachable quickly,
  # fall back to direct haxe to avoid spending the entire BUILD_TIMEOUT on a failed handshake.
  # Try for up to ~5s, short polls, then fall back to direct haxe
  READY=0; for i in 1 2 3 4 5; do
    if bash -lc "$HAXE_CMD -version" >/dev/null 2>&1; then READY=1; break; fi
    sleep 0.2
  done
  if [[ "$READY" -ne 1 ]]; then HAXE_CMD="haxe"; fi
fi

# Optional: dependency prewarm to avoid first-time rebar/make latency for
# heavy Erlang deps (best-effort, bounded). Useful on macOS where erlang.mk
# projects like cowlib may trigger additional setup on the first run.
if [[ -n "$PREWARM_TIMEOUT" && "$PREWARM_TIMEOUT" != "0" ]]; then
  run_step_best_effort "Step 1.pre: deps prewarm (cowlib)" "$PREWARM_TIMEOUT" /tmp/qa-deps-prewarm.log "MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix deps.compile cowlib --force"
fi

# Generate .ex files. Prefer a fast hxml if available; else, if pass files
# exist, run in two bounded passes to respect strict per-step caps.
# Optionally skip Haxe generation entirely when sources are unchanged.
if [[ -n "${QA_SKIP_HAXE:-}" ]]; then
  log "[QA] Step 1: Skipping Haxe build (QA_SKIP_HAXE set)"
  : > /tmp/qa-haxe.log
elif [[ -n "${QA_FORCE_FAST_BUILD:-}" ]] && [[ -f "build-server-fast.hxml" ]]; then
  run_step_with_log "Step 1: Haxe build (fast) ($HAXE_CMD build-server-fast.hxml)" "$BUILD_TIMEOUT" /tmp/qa-haxe.log "$HAXE_CMD build-server-fast.hxml" || exit 1
elif ls build-server-pass*.hxml >/dev/null 2>&1; then
  i=0
  for h in $(ls -1 build-server-pass*.hxml | sort); do
    i=$((i+1))
    # Use the compilation server for all micro‑passes so later passes reuse cache
    run_step_with_log "Step 1.${i}: Haxe build pass ($HAXE_CMD $h)" "$BUILD_TIMEOUT" "/tmp/qa-haxe-pass${i}.log" "$HAXE_CMD $h" || exit 1
  done
  # Consolidated tail for convenience
  : > /tmp/qa-haxe.log; for h in /tmp/qa-haxe-pass*.log; do tail -n 60 "$h" >> /tmp/qa-haxe.log 2>/dev/null || true; echo >> /tmp/qa-haxe.log; done
elif [[ -f "build-server-fast.hxml" ]]; then
  run_step_with_log "Step 1: Haxe build (fast) ($HAXE_CMD build-server-fast.hxml)" "$BUILD_TIMEOUT" /tmp/qa-haxe.log "$HAXE_CMD build-server-fast.hxml" || exit 1
else
  run_step_with_log "Step 1: Haxe build ($HAXE_CMD build-server.hxml)" "$BUILD_TIMEOUT" /tmp/qa-haxe.log "$HAXE_CMD build-server.hxml" || exit 1
fi

# Remove unused std artifacts that are not needed for the app and may generate invalid code
run_step_with_log "Step 1.cleanup: prune unused Elixir helper outputs" 30s /tmp/qa-haxe-prune.log "bash -lc 'rm -rf lib/elixir/types'" || exit 1

if [[ -n "${QA_SKIP_DEPS:-}" ]]; then
  log "[QA] Step 2: Skipping deps (QA_SKIP_DEPS set)"
else
  run_step_with_log "Step 2: mix deps.get" "$DEPS_TIMEOUT" /tmp/qa-mix-deps.log "MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix deps.get" || exit 1

  # Workaround for cowlib hex packaging without rebar.config on some systems:
  # if deps/cowlib/rebar.config is missing, create a minimal one that includes
  # the local include/ dir so rebar3 passes -I include to erlc.
  if [[ -d "deps/cowlib" && ! -f "deps/cowlib/rebar.config" ]]; then
    echo "{erl_opts, [{i, \"include\"}]}."> "deps/cowlib/rebar.config"
  fi

  # Precompile critical Erlang deps to avoid include path races during main compile.
  # Use the default _build root to ensure rebar include_lib resolution works; best-effort so main compile can proceed.
  run_step_best_effort "Step 2.1: deps precompile (cowboy)" 180s /tmp/qa-deps-precompile.log "bash -lc 'unset MIX_BUILD_ROOT; MIX_ENV=$ENV_NAME mix deps.compile cowboy --force'"

  # Prepare database and runtime after compile. Robust deps compile to avoid
  # rebar include_lib issues under per-run MIX_BUILD_ROOT.
  # Always compile deps in the default root (unset MIX_BUILD_ROOT), then mirror to per-run root.
  run_step_with_log "Step 2.1: deps compile (default root)" 240s /tmp/qa-deps-compile-default.log "bash -lc 'unset MIX_BUILD_ROOT; MIX_ENV=$ENV_NAME mix deps.compile --force'" || exit 1
  # Mirror artifacts with symlink dereference so priv/include are real files in MIX_BUILD_ROOT
  run_step_with_log "Step 2.2: mirror deps to MIX_BUILD_ROOT" 60s /tmp/qa-deps-mirror.log "bash -lc 'mkdir -p \"$QA_BUILD_ROOT/$ENV_NAME/lib\" && rsync -aL --delete \"_build/$ENV_NAME/lib/\" \"$QA_BUILD_ROOT/$ENV_NAME/lib/\"'" || exit 1
fi

# Second prune in case codegen emitted unused std helpers during the build loop
run_step_with_log "Step 2.cleanup: prune unused Elixir helper outputs" 30s /tmp/qa-haxe-prune2.log "bash -lc 'rm -rf lib/elixir/types'" || exit 1

# Compile first so DB tasks do not incur compile cost repeatedly
# Compile application only (skip deps recompile inside per-run root to avoid rebar include_lib issues)
if ! run_step_with_log "Step 3: mix compile (no deps)" "$COMPILE_TIMEOUT" /tmp/qa-mix-compile.log "HAXE_NO_COMPILE=1 HAXE_NO_SERVER=1 MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix compile --no-deps-check"; then
  # As a bounded fallback, attempt normal compile once more
  run_step_with_log "Step 3 (retry): mix compile" "$COMPILE_TIMEOUT" /tmp/qa-mix-compile.log "HAXE_NO_COMPILE=1 HAXE_NO_SERVER=1 MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix compile" || exit 1
fi
if [[ "$ENV_NAME" != "dev" ]]; then
  if [[ "$REUSE_DB" -eq 1 ]]; then
    run_step_with_log "DB ensure ($ENV_NAME)" 120s /tmp/qa-mix-db-ensure.log "MIX_ENV=$ENV_NAME mix ecto.create --quiet" || true
    run_step_with_log "DB migrate ($ENV_NAME)" 300s /tmp/qa-mix-db-migrate.log "MIX_ENV=$ENV_NAME mix ecto.migrate" || exit 1
  else
    run_step_with_log "DB drop ($ENV_NAME)" 120s /tmp/qa-mix-db-drop.log "MIX_ENV=$ENV_NAME mix ecto.drop --quiet" || true
    run_step_with_log "DB create ($ENV_NAME)" 120s /tmp/qa-mix-db-create.log "MIX_ENV=$ENV_NAME mix ecto.create --quiet" || true
    run_step_with_log "DB migrate ($ENV_NAME)" 300s /tmp/qa-mix-db-migrate.log "MIX_ENV=$ENV_NAME mix ecto.migrate" || exit 1
  fi
  if [[ -n "$SEEDS_FILE" ]]; then
    run_step_with_log "DB seeds ($ENV_NAME)" 180s /tmp/qa-mix-db-seeds.log "MIX_ENV=$ENV_NAME mix run '$SEEDS_FILE'" || exit 1
  fi
fi

# Build static assets (JS/CSS) so LiveView client and UI interactions are available
if [[ -n "${QA_SKIP_ASSETS:-}" ]]; then
  log "[QA] Assets build: skipped (QA_SKIP_ASSETS set)"
else
  run_step_with_log "Assets build ($ENV_NAME)" 300s /tmp/qa-assets-build.log "MIX_ENV=$ENV_NAME mix assets.build" || true
fi

# Ensure no stale Phoenix server is occupying the target port (or default :4000)
for P in "$PORT" 4000; do
  if command -v lsof >/dev/null 2>&1; then
    PIDLIST=$(lsof -ti tcp:"$P" -sTCP:LISTEN || true)
    if [ -n "$PIDLIST" ]; then
      echo "[QA] Detected process on :$P → killing: $PIDLIST"
      kill -9 $PIDLIST >/dev/null 2>&1 || true
      sleep 0.5
    fi
  elif command -v ss >/dev/null 2>&1; then
    PIDS=$(ss -ltnp 2>/dev/null | awk -v p=":$P" '$4 ~ p {print $6}' | sed -E 's/.*pid=([0-9]+),.*/\1/' | sort -u)
    if [ -n "$PIDS" ]; then
      echo "[QA] Detected process on :$P → killing: $PIDS"
      kill -9 $PIDS >/dev/null 2>&1 || true
      sleep 0.5
    fi
  fi
done

log "[QA] Step 4: Starting Phoenix server on :$PORT (background, non-blocking)"
export PORT="$PORT"
# Start Phoenix in the background, detached when possible, and capture PID/PGID
# Prefer setsid; on macOS where `setsid` may not exist, fall back to perl POSIX::setsid;
# if neither available, start normally but ensure cleanup never targets our own PGID.
if command -v setsid >/dev/null 2>&1; then
  setsid sh -c "MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix phx.server" >/tmp/qa-phx.log 2>&1 &
elif command -v perl >/dev/null 2>&1; then
  # Create a new session via perl; then exec a shell to run the server
  nohup perl -MPOSIX -e 'POSIX::setsid() or die "setsid failed: $!"; exec @ARGV' \
    sh -c "MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix phx.server" >/tmp/qa-phx.log 2>&1 &
else
  # Fallback: still background, but guard cleanup to avoid killing our own process group
  nohup env MIX_ENV=$ENV_NAME MIX_BUILD_ROOT=$QA_BUILD_ROOT mix phx.server >/tmp/qa-phx.log 2>&1 &
fi
PHX_PID=$!
PGID=$(ps -o pgid= "$PHX_PID" 2>/dev/null | tr -d ' ' || true)
# Our own process group (for safety checks during cleanup)
MY_PGID=$(ps -o pgid= $$ 2>/dev/null | tr -d ' ' || true)
log "[QA] Phoenix started: PHX_PID=$PHX_PID PGID=$PGID (logs: /tmp/qa-phx.log)"

cleanup() {
  # Prefer killing the Phoenix process group when it is distinct from our own.
  # This prevents terminating the host CLI when the server wasn't started in a new session.
  if [[ -n "$PGID" && -n "$MY_PGID" && "$PGID" != "$MY_PGID" ]]; then
    kill -TERM -"$PGID" >/dev/null 2>&1 || true
    sleep 0.5
    kill -KILL -"$PGID" >/dev/null 2>&1 || true
  fi
  # Always try to terminate the server PID directly
  kill "$PHX_PID" >/dev/null 2>&1 || true
  # Extra safety: kill anything still listening on the port
  if command -v lsof >/dev/null 2>&1; then
    PIDS=$(lsof -ti tcp:"$PORT" -sTCP:LISTEN || true)
    if [[ -n "$PIDS" ]]; then kill -9 $PIDS >/dev/null 2>&1 || true; fi
  elif command -v ss >/dev/null 2>&1; then
    PIDS=$(ss -ltnp 2>/dev/null | awk -v p=":$PORT" '$4 ~ p {print $6}' | sed -E 's/.*pid=([0-9]+),.*/\1/' | sort -u)
    if [[ -n "$PIDS" ]]; then kill -9 $PIDS >/dev/null 2>&1 || true; fi
  fi
}

if [[ "$KEEP_ALIVE" -eq 0 ]]; then
  trap cleanup EXIT
fi

log "[QA] Step 5: Waiting for server readiness (probes=$READY_PROBES)"
READY=0
for i in $(seq 1 "$READY_PROBES"); do
  if curl -fsS "http://localhost:$PORT" >/dev/null 2>&1; then
    READY=1; break
  fi
  # If not ready, see if endpoint reported a different port
  DETECTED_PORT=$(grep -Eo 'http://localhost:[0-9]+' /tmp/qa-phx.log 2>/dev/null | tail -n1 | sed -E 's/.*:([0-9]+)/\1/' || true)
  if [[ -z "$DETECTED_PORT" ]]; then
    DETECTED_PORT=$(grep -Eo '127\.0\.0\.1:[0-9]+' /tmp/qa-phx.log 2>/dev/null | tail -n1 | sed -E 's/.*:([0-9]+)/\1/' || true)
  fi
  if [[ -n "$DETECTED_PORT" ]] && curl -fsS "http://localhost:$DETECTED_PORT" >/dev/null 2>&1; then
    PORT="$DETECTED_PORT"; READY=1; break
  fi
  log "[QA] Probe $i/$READY_PROBES: not ready yet (PORT=$PORT)."
  if [[ "$VERBOSE" -eq 1 ]]; then
    log "[QA] Last 20 phoenix log lines:"; tail -n 20 /tmp/qa-phx.log || true
  fi
  sleep 0.5
done

if [[ "$READY" -ne 1 ]]; then
  log "[QA] ❌ Server did not become ready. Last 200 log lines:"
  tail -n 200 /tmp/qa-phx.log || true
  cleanup || true
  exit 1
fi

log "[QA] Step 6: GET / (strict 2xx)"
if ! curl -fsS "http://localhost:$PORT/" >/tmp/qa-index.html 2>/dev/null; then
  log "[QA] ❌ GET / did not return 2xx. Last 200 log lines:"
  tail -n 200 /tmp/qa-phx.log || true
  cleanup || true
  exit 1
fi

# Optional: probe /todos if route exists
curl -fsS "http://localhost:$PORT/todos" >/dev/null 2>&1 || true

# Scan logs for runtime errors
if command -v rg >/dev/null 2>&1; then
  if rg -n "(CompileError|UndefinedFunctionError|ArgumentError|FunctionClauseError|KeyError|RuntimeError|\(EXIT\)|\bError\b)" /tmp/qa-phx.log >/dev/null 2>&1; then
    log "[QA] ❌ Runtime errors detected in logs"
    rg -n "(CompileError|UndefinedFunctionError|ArgumentError|FunctionClauseError|KeyError|RuntimeError|\(EXIT\)|\bError\b)" /tmp/qa-phx.log | tail -n 100
    cleanup || true
    exit 1
  fi
else
  if grep -E "CompileError|UndefinedFunctionError|ArgumentError|FunctionClauseError|KeyError|RuntimeError|\(EXIT\)|\bError\b" /tmp/qa-phx.log >/dev/null 2>&1; then
    log "[QA] ❌ Runtime errors detected in logs"
    tail -n 100 /tmp/qa-phx.log
    cleanup || true
    exit 1
  fi
fi

log "[QA] OK: build + runtime smoke passed with zero warnings (WAE)"

# Optional: run Playwright tests after readiness
if [[ "$RUN_PLAYWRIGHT" -eq 1 ]]; then
  log "[QA] Step 7: Running Playwright tests (${E2E_SPEC:-e2e}, workers: ${E2E_WORKERS})"
  # Install dependencies and browsers for Playwright in the app dir
  run_step_with_log "Playwright npm install" 180s /tmp/qa-playwright-install.log "npm -C . install --no-audit --no-fund" || { cleanup || true; exit 1; }
  run_step_with_log "Playwright browsers install" 600s /tmp/qa-playwright-browsers.log "npx -C . playwright install" || { cleanup || true; exit 1; }
  # Important: do NOT quote the spec so that shell globs expand (e.g., e2e/*.spec.ts)
  SPEC_ARG=${E2E_SPEC:-e2e}
  if ! BASE_URL="http://localhost:$PORT" bash -lc "npx -C . playwright test ${SPEC_ARG} --workers=${E2E_WORKERS}" >/tmp/qa-playwright-run.log 2>&1; then
    log "[QA] ❌ Playwright tests failed. Last 120 lines:"
    tail -n 120 /tmp/qa-playwright-run.log || true
    cleanup || true
    exit 1
  fi
  log "[QA] ✅ Playwright tests passed"
fi

if [[ "$KEEP_ALIVE" -eq 1 ]]; then
  log "[QA] KEEP-ALIVE enabled. Phoenix continues running."
  echo "PHX_PID=$PHX_PID"
  echo "PORT=$PORT"
fi
popd >/dev/null
</file>

<file path="src/reflaxe/elixir/ast/builders/ModuleBuilder.hx">
package reflaxe.elixir.ast.builders;

#if (macro || reflaxe_runtime)

import haxe.macro.Type;
import reflaxe.elixir.ast.ElixirAST;

/**
 * Bootstrap strategy for module loading
 */
enum BootstrapStrategy {
    None;                    // No bootstrap needed
    InlineDeterministic;     // Inline require statements
    External;                // External bootstrap file
}

/**
 * ModuleBuilder: Builds Elixir module structures
 *
 * WHY: Module generation is complex with many concerns: naming, imports,
 * attributes, functions, and bootstrap strategies. This builder centralizes
 * that logic.
 *
 * WHAT: Handles all aspects of Elixir module generation including defmodule
 * structure, use statements, imports, and bootstrap code generation.
 *
 * HOW: Provides a builder API for constructing modules piece by piece,
 * then generates the appropriate AST structure.
 *
 * ARCHITECTURE BENEFITS:
 * - Single responsibility for module generation
 * - Consistent module structure across all types
 * - Bootstrap strategy abstraction
 *
 * NOTE: This is a CONSERVATIVE stub implementation for Phase 2 integration.
 * Returns minimal, safe module structures. Full implementation in Phase 3.
 */
class ModuleBuilder {
    private static var bootstrapStrategy: BootstrapStrategy = None;

    /**
     * Get the current bootstrap strategy
     */
    public static function getBootstrapStrategy(): BootstrapStrategy {
        return bootstrapStrategy;
    }

    /**
     * Set the bootstrap strategy
     */
    public static function setBootstrapStrategy(strategy: BootstrapStrategy): Void {
        bootstrapStrategy = strategy;
    }

    /**
     * Extract module name from a ClassType
     *
     * @param classType The class to extract name from
     * @return The module name
     */
    public static function extractModuleName(classType: ClassType): String {
        // Check for @:native annotation first
        if (classType.meta.has(":native")) {
            var nativeMeta = classType.meta.extract(":native");
            if (nativeMeta.length > 0 && nativeMeta[0].params != null && nativeMeta[0].params.length > 0) {
                switch(nativeMeta[0].params[0].expr) {
                    case EConst(CString(s, _)):
                        return s;
                    default:
                }
            }
        }
        
        // For @:application classes without @:native, append ".Application" to module name
        // This follows Phoenix/OTP convention where applications are named AppName.Application
        if (classType.meta.has(":application") && !classType.meta.has(":native")) {
            return classType.name + ".Application";
        }

        // Default to class name
        return classType.name;
    }

    /**
     * Build a class module AST with support for exception classes
     *
     * @param classType The class type to compile
     * @param fields Module fields (functions, properties, etc.)
     * @param metadata Optional metadata containing inheritance info
     * @return Module AST with appropriate structure (regular module or exception)
     * 
     * @example Building a regular class:
     * ```haxe
     * var moduleAST = ModuleBuilder.buildClassModule(classType, fields, null);
     * ```
     * 
     * @example Building an exception class:
     * ```haxe
     * var metadata = { isException: true, parentModule: "Exception" };
     * var moduleAST = ModuleBuilder.buildClassModule(classType, fields, metadata);
     * ```
     */
    public static function buildClassModule(classType: ClassType, fields: Array<ElixirAST>, ?metadata: ElixirMetadata): ElixirAST {
        #if debug_compilation_hang
        Sys.println('[HANG DEBUG] 🏗️ ModuleBuilder.buildClassModule START - Class: ${classType.name}, Fields: ${fields.length}');
        var moduleStartTime = haxe.Timer.stamp() * 1000;
        #end

        var moduleName = extractModuleName(classType);
        // Register module globally for cross-file qualification
        try {
            reflaxe.elixir.ElixirCompiler.registerModule(moduleName);
            // Also register app-prefixed variant for Web-context qualification,
            // e.g., TodoApp + "." + Todo -> "TodoApp.Todo"
            var app = reflaxe.elixir.PhoenixMapper.getAppModuleName();
            if (app != null && app.length > 0 && moduleName.indexOf('.') == -1) {
                reflaxe.elixir.ElixirCompiler.registerModule(app + "." + moduleName);
            }
        } catch (e:Dynamic) {}
        var attributes: Array<EAttribute> = [];

        // Use provided metadata or create empty object
        var moduleMetadata = metadata != null ? metadata : {};

        // Check if this is an exception class
        if (moduleMetadata.isException == true) {
            #if debug_inheritance
            trace('[ModuleBuilder] Generating exception module for ${moduleName}');
            #end
            
            // Don't add defstruct for exceptions - defexception handles it automatically
            // The ElixirASTPrinter will handle the defexception macro when it sees isException metadata
            // Just keep the regular fields (methods like toString)
        }

        var result = {
            def: EModule(moduleName, attributes, fields),
            metadata: moduleMetadata,
            pos: classType.pos
        };

        #if debug_compilation_hang
        var elapsed = (haxe.Timer.stamp() * 1000) - moduleStartTime;
        Sys.println('[HANG DEBUG] ✅ ModuleBuilder.buildClassModule END - Took ${elapsed}ms');
        #end

        return result;
    }
    
    /**
     * Create the defstruct definition for exception classes
     * 
     * @return AST node representing defstruct with message field
     * 
     * Generates: `defstruct message: ""`
     */
    static function makeExceptionStructDefinition(): ElixirAST {
        // Create the struct definition with message field
        // This simulates defexception which creates a struct with message
        return makeAST(ECall(
            null,
            "defstruct",
            [makeAST(EKeywordList([
                {key: "message", value: makeAST(EString(""))}
            ]))]
        ));
    }
    
    /**
     * Helper function to create AST nodes
     * 
     * @param def The AST definition
     * @return ElixirAST node with empty metadata
     */
    static inline function makeAST(def: ElixirASTDef): ElixirAST {
        return {
            def: def,
            metadata: {},
            pos: null
        };
    }
}

#end
</file>

<file path="src/reflaxe/elixir/ast/transformers/AnnotationTransforms.hx">
package reflaxe.elixir.ast.transformers;

#if (macro || reflaxe_runtime)

import reflaxe.elixir.ast.ElixirAST;
import haxe.macro.Context;
import reflaxe.elixir.ast.ElixirAST.ElixirASTDef;
import reflaxe.elixir.ast.ElixirAST.makeAST;
import reflaxe.elixir.ast.ElixirAST.makeASTWithMeta;
import reflaxe.elixir.ast.ElixirAST.ElixirMetadata;
import reflaxe.elixir.ast.ElixirAST.EKeywordPair;
import reflaxe.elixir.ast.ElixirAST.EMapPair;
import reflaxe.elixir.ast.ElixirASTTransformer;
import reflaxe.elixir.ast.naming.ElixirAtom;

/**
 * AnnotationTransforms: AST transformation passes for annotation-based modules
 * 
 * WHY: Framework-specific modules (@:endpoint, @:liveview, @:schema) need specialized
 *      transformation from basic module structure to framework-compliant code.
 * 
 * WHAT: Contains transformation passes that detect metadata flags set by ModuleBuilder
 *       and transform the AST to generate proper Phoenix/Ecto/OTP structures.
 * 
 * HOW: Each pass checks for specific metadata flags and transforms the module body
 *      to include framework-specific directives, configurations, and callbacks.
 * 
 * ARCHITECTURE BENEFITS:
 * - Separation of Concerns: Building (ModuleBuilder) vs Transformation (this file)
 * - Single Responsibility: Each pass handles one annotation type
 * - Predictable Pipeline: Metadata-driven, no string manipulation
 * - Maintainable: Small focused functions instead of monolithic code
 * - Extensible: Easy to add new annotation types
 * 
 * SUPPORTED ANNOTATIONS:
 * - @:endpoint - Phoenix.Endpoint with plugs, sockets, and static configuration
 * - @:liveview - Phoenix.LiveView with mount/handle_event/render callbacks
 * - @:schema - Ecto.Schema with field definitions and changeset functions
 * - @:repo - Ecto.Repo with database access functions
 * - @:postgrexTypes - Postgrex precompiled types module (Types.define)
 * - @:application - OTP Application with supervision tree configuration
 * - @:phoenixWeb - Phoenix Web module with router/controller/live_view macros
 * - @:controller - Phoenix.Controller with action functions
 * - @:channel - Phoenix.Channel with join/handle_in/handle_out callbacks
 * - @:presence - Phoenix.Presence with tracking and listing callbacks
 * - @:exunit - ExUnit.Case test modules with test functions
 * 
 * TRANSFORMATION PASSES:
 * 1. phoenixWebTransformPass - Adds defmacro definitions for Phoenix DSL
 * 2. endpointTransformPass - Configures Phoenix.Endpoint module structure
 * 3. liveViewTransformPass - Sets up Phoenix.LiveView use statement
 * 4. schemaTransformPass - Adds Ecto.Schema use and schema block
 * 5. repoTransformPass - Adds Ecto.Repo use with otp_app and adapter
 * 6. applicationTransformPass - Configures OTP Application callbacks
 * 7. controllerTransformPass - Sets up Phoenix.Controller use statement
 * 8. routerTransformPass - Sets up Phoenix.Router with pipelines and routes
 * 9. presenceTransformPass - Sets up Phoenix.Presence use statement
 * 10. exunitTransformPass - Sets up ExUnit.Case with test functions
 * 
 * METADATA FLOW:
 * 1. ModuleBuilder detects annotations and sets metadata flags
 * 2. Each transformation pass checks its specific metadata flag
 * 3. If flag is set, module body is transformed with framework code
 * 4. Original module functions are preserved and integrated
 * 
 * EDGE CASES:
 * - Multiple annotations on same module: First match wins
 * - Missing required functions: Default implementations added
 * - Conflicting metadata: Logged and first annotation takes precedence
 */
@:nullSafety(Off)
class AnnotationTransforms {
    
    /**
     * Transform @:endpoint modules into Phoenix.Endpoint structure
     * 
     * WHY: Phoenix endpoints require specific structure with use statement, plugs, and sockets
     * WHAT: Replaces minimal module body with complete endpoint configuration
     * HOW: Detects isEndpoint metadata and builds proper Phoenix.Endpoint AST
     */
    public static function endpointTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        trace('[XRay Endpoint Transform] Checking AST node type: ${ast.def}');
        if (ast.metadata?.isEndpoint == true) {
            trace('[XRay Endpoint Transform] Found endpoint module with metadata');
        }
        #end
        
        // Check the top-level node first for Endpoint modules
        switch(ast.def) {
            case EModule(name, attrs, exprs) if (ast.metadata?.isEndpoint == true):
                #if debug_annotation_transforms
                trace('[XRay Endpoint Transform] Processing endpoint EModule: ${name}');
                #end
                
                var appName = (ast.metadata != null && ast.metadata.appName != null) ? ast.metadata.appName : extractAppName(name);
                var endpointBody = buildEndpointBody(name, appName);
                // EModule expects Array<ElixirAST> body; unwrap block to statements
                var stmts = switch (endpointBody.def) {
                    case EBlock(s): s;
                    default: [endpointBody];
                };
                return makeASTWithMeta(EModule(name, attrs, stmts), ast.metadata, ast.pos);
                
            case EDefmodule(name, body) if (ast.metadata?.isEndpoint == true):
                #if debug_annotation_transforms
                trace('[XRay Endpoint Transform] Processing endpoint EDefmodule: ${name}');
                #end
                
                var appName = (ast.metadata != null && ast.metadata.appName != null) ? ast.metadata.appName : extractAppName(name);
                var endpointBody = buildEndpointBody(name, appName);
                
                // Create new module with endpoint body, preserving metadata
                return makeASTWithMeta(
                    EDefmodule(name, endpointBody),
                    ast.metadata,
                    ast.pos
                );
                
            default:
                // Not an Endpoint module, just pass through
                return ast;
        }
    }
    
    /**
     * Build complete Phoenix.Endpoint module body as array of statements
     */
    static function buildEndpointBodyStatements(moduleName: String, appName: String): Array<ElixirAST> {
        var statements = [];
        
        // use Phoenix.Endpoint, otp_app: :app_name
        var useOptions = makeAST(EKeywordList([
            {key: "otp_app", value: makeAST(EAtom(appName))}
        ]));
        statements.push(makeAST(EUse("Phoenix.Endpoint", [useOptions])));
        
        // The rest of the endpoint configuration continues in buildEndpointBody
        // For now, just add the use statement which is most critical
        
        return statements;
    }
    
    /**
     * Build complete Phoenix.Endpoint module body
     */
    static function buildEndpointBody(moduleName: String, appName: String): ElixirAST {
        var statements = [];
        
        // use Phoenix.Endpoint, otp_app: :app_name
        var useOptions = makeAST(EKeywordList([
            {key: "otp_app", value: makeAST(EAtom(appName))}
        ]));
        statements.push(makeAST(EUse("Phoenix.Endpoint", [useOptions])));
        
        // @session_options configuration
        var sessionOptions = makeAST(EKeywordList([
            {key: "store", value: makeAST(EAtom(ElixirAtom.raw("cookie")))},
            {key: "key", value: makeAST(EString('_${appName}_key'))},
            {key: "signing_salt", value: makeAST(EString('generated_salt_${Std.int(Math.random() * 1000000)}'))},
            {key: "same_site", value: makeAST(EString("Lax"))}
        ]));
        // Module attribute for session options
        statements.push(makeAST(EModuleAttribute("session_options", sessionOptions)));
        
        // socket "/live", Phoenix.LiveView.Socket configuration
        var socketOptions = makeAST(EKeywordList([
            {key: "websocket", value: makeAST(EKeywordList([
                {key: "connect_info", value: makeAST(EKeywordList([
                    {key: "session", value: makeAST(EVar("@session_options"))}
                ]))}
            ]))}
        ]));
        statements.push(makeAST(ECall(null, "socket", [
            makeAST(EString("/live")),
            makeAST(EVar("Phoenix.LiveView.Socket")),
            socketOptions
        ])));
        
        // plug Plug.Static configuration
        // Use the sigil directly for the only option instead of calling a function
        var staticOptions = makeAST(EKeywordList([
            {key: "at", value: makeAST(EString("/"))},
            {key: "from", value: makeAST(EAtom(appName))},
            {key: "gzip", value: makeAST(EBoolean(false))},
            {key: "only", value: makeAST(ESigil(
                "w",
                "assets fonts images favicon.ico robots.txt",
                ""
            ))}
        ]));
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.Static")),
            staticOptions
        ])));
        
        // if code_reloading? do plug Phoenix.CodeReloader end
        // Note: code_reloading? is imported by use Phoenix.Endpoint but might need explicit reference
        var codeReloadingBlock = makeAST(EIf(
            makeAST(ECall(null, "Code.ensure_loaded?", [makeAST(EVar("Phoenix.CodeReloader"))])),
            makeAST(ECall(null, "plug", [
                makeAST(EVar("Phoenix.CodeReloader"))
            ])),
            null
        ));
        statements.push(codeReloadingBlock);
        
        // Request pipeline plugs
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.RequestId"))
        ])));
        
        var telemetryOptions = makeAST(EKeywordList([
            {key: "event_prefix", value: makeAST(EList([
                makeAST(EAtom(ElixirAtom.raw("phoenix"))),
                makeAST(EAtom(ElixirAtom.raw("endpoint")))
            ]))}
        ]));
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.Telemetry")),
            telemetryOptions
        ])));
        
        // plug Plug.Parsers
        var parsersOptions = makeAST(EKeywordList([
            {key: "parsers", value: makeAST(EList([
                makeAST(EAtom(ElixirAtom.raw("urlencoded"))),
                makeAST(EAtom(ElixirAtom.raw("multipart"))),
                makeAST(EAtom(ElixirAtom.raw("json")))
            ]))},
            {key: "pass", value: makeAST(EList([makeAST(EString("*/*"))]))},
            {key: "json_decoder", value: makeAST(ERemoteCall(
                makeAST(EVar("Phoenix")),
                "json_library",
                []
            ))}
        ]));
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.Parsers")),
            parsersOptions
        ])));
        
        // Other standard plugs
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.MethodOverride"))
        ])));
        
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.Head"))
        ])));
        
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar("Plug.Session")),
            makeAST(EVar("@session_options"))
        ])));
        
        // Router plug (assumes Web module pattern)
        var routerModule = StringTools.replace(moduleName, ".Endpoint", ".Router");
        statements.push(makeAST(ECall(null, "plug", [
            makeAST(EVar(routerModule))
        ])));
        
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:liveview modules into Phoenix.LiveView structure
     * 
     * WHY: LiveView modules need specific callbacks and use statement
     * WHAT: Adds use Phoenix.LiveView and ensures proper callback structure
     * HOW: Detects isLiveView metadata and transforms module body
     */
    public static function liveViewTransformPass(ast: ElixirAST): ElixirAST {
        // Check the top-level node first for LiveView modules
        switch(ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isLiveView == true):
                #if debug_annotation_transforms
                #end
                
                var liveViewBody = buildLiveViewBody(name, body);
                
                return makeASTWithMeta(
                    EDefmodule(name, liveViewBody),
                    ast.metadata,
                    ast.pos
                );
            case EModule(name, attrs, body) if (ast.metadata?.isLiveView == true):
                // Shape-matched LiveView module using direct Phoenix.LiveView use
                var webIndex = name.indexOf("Web");
                var appWebModule = if (webIndex > 0) name.substring(0, webIndex + "Web".length) else name;
                var liveViewOptions = makeAST(EKeywordList([
                    {
                        key: "layout",
                        value: makeAST(ETuple([
                            makeAST(EVar(appWebModule + ".Layouts")),
                            makeAST(EAtom(ElixirAtom.raw("app")))
                        ]))
                    }
                ]));
                var newBody: Array<ElixirAST> = [];
                newBody.push(makeAST(EUse("Phoenix.LiveView", [liveViewOptions])));
                // Ensure Ecto.Query macros are available for LiveViews
                newBody.push(makeAST(ERequire("Ecto.Query", null)));
                for (stmt in body) newBody.push(stmt);
                return makeASTWithMeta(EModule(name, attrs, newBody), ast.metadata, ast.pos);
            default:
                // Not a LiveView module, just pass through
                return ast;
        }
    }

    /**
     * Transform channel modules into Phoenix.Channel structure
     *
     * WHAT
     * - Adds `use <App>Web, :channel` to modules shaped like Phoenix channels.
     *
     * WHY
     * - Ensure idiomatic Phoenix channel setup without app-specific name heuristics.
     *   We rely on the framework naming convention "<App>Web.*Channel".
     *
     * HOW
     * - For EDefmodule/EModule whose name contains "Web." and "Channel",
     *   prepend use <App>Web, :channel and preserve existing body.
     */
    public static function channelTransformPass(ast: ElixirAST): ElixirAST {
        return ElixirASTTransformer.transformNode(ast, function(n: ElixirAST): ElixirAST {
            return switch (n.def) {
                case EDefmodule(name, body) if (name != null && name.indexOf("Web.") > 0 && name.indexOf("Channel") > 0):
                    var webIndex = name.indexOf("Web");
                    var appNamePart = if (webIndex > 0) name.substring(0, webIndex) else name;
                    var useStmt = makeAST(EUse(appNamePart + "Web", [ makeAST(EAtom(ElixirAtom.raw("channel"))) ]));
                    var newBody = switch (body.def) {
                        case EBlock(stmts): makeAST(EBlock([useStmt].concat(stmts)));
                        case EDo(stmts2): makeAST(EDo([useStmt].concat(stmts2)));
                        default: makeAST(EBlock([useStmt, body]));
                    };
                    makeASTWithMeta(EDefmodule(name, newBody), n.metadata, n.pos);
                case EModule(name, attrs, stmts) if (name != null && name.indexOf("Web.") > 0 && name.indexOf("Channel") > 0):
                    var webIndex2 = name.indexOf("Web");
                    var appNamePart2 = if (webIndex2 > 0) name.substring(0, webIndex2) else name;
                    var useStmt2 = makeAST(EUse(appNamePart2 + "Web", [ makeAST(EAtom(ElixirAtom.raw("channel"))) ]));
                    makeASTWithMeta(EModule(name, attrs, [useStmt2].concat(stmts)), n.metadata, n.pos);
                default:
                    n;
            }
        });
    }
    
    /**
     * Build LiveView module body
     *
     * WHAT
     * - Emits idiomatic LiveView modules that depend only on `Phoenix.LiveView`
     *   rather than `AppWeb` macros for core behavior.
     *
     * WHY
     * - `use AppWeb, :live_view` is the Phoenix generator default, but it
     *   introduces a compile‑time dependency on the web hub module being
     *   compiled and loaded first. In isolated build roots (e.g. QA sentinel
     *   using per‑run MIX_BUILD_ROOT), this can surface as
     *   “module <App>Web is not loaded and could not be found” even though the
     *   generated AppWeb module exists as a normal .ex file.
     *
     * - Using `Phoenix.LiveView` directly keeps the generated code fully
     *   idiomatic while avoiding fragile compile ordering between the web hub
     *   and individual LiveViews. The hub module (`<App>Web`) is still
     *   generated for controllers, HTML helpers, etc., but LiveViews no longer
     *   require it during compilation.
     *
     * HOW
     * - Derives the `<App>Web` prefix from the LiveView module name
     *   (e.g. `TodoAppWeb.TodoLive` → `TodoAppWeb`) and uses it only to build
     *   the layout module name for options.
     * - Emits:
     *
     *   use Phoenix.LiveView, layout: {AppWeb.Layouts, :app}
     *
     * - Then appends the existing function body so that HXX/HXX‑generated
     *   render functions are preserved unchanged.
     *
     * EXAMPLES
     * Haxe:
     *   @:liveview @:native("TodoAppWeb.TodoLive")
     *   class TodoLive { ... }
     *
     * Elixir (before):
     *   defmodule TodoAppWeb.TodoLive do
     *     use TodoAppWeb, :live_view
     *     ...
     *   end
     *
     * Elixir (after):
     *   defmodule TodoAppWeb.TodoLive do
     *     use Phoenix.LiveView, layout: {TodoAppWeb.Layouts, :app}
     *     ...
     *   end
     */
    static function buildLiveViewBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];

        // Extract AppWeb module name from module name (e.g., TodoAppWeb.TodoLive -> TodoAppWeb)
        var webIndex = moduleName.indexOf("Web");
        var appWebModule = if (webIndex > 0) moduleName.substring(0, webIndex + "Web".length) else moduleName;

        // use Phoenix.LiveView, layout: {AppWeb.Layouts, :app}
        var liveViewOptions = makeAST(EKeywordList([
            {
                key: "layout",
                value: makeAST(ETuple([
                    makeAST(EVar(appWebModule + ".Layouts")),
                    makeAST(EAtom(ElixirAtom.raw("app")))
                ]))
            }
        ]));
        statements.push(makeAST(EUse("Phoenix.LiveView", [liveViewOptions])));

        // Ensure Ecto.Query macros are available for LiveViews that use queries
        // Safe to include even if not used; avoids macro require errors
        statements.push(makeAST(ERequire("Ecto.Query", null)));
        
        // Add existing functions from the body
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    // Skip empty statements
                    switch(stmt.def) {
                        case ENil:
                            // Skip
                        default:
                            statements.push(stmt);
                    }
                }
            default:
                statements.push(existingBody);
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:presence modules into Phoenix.Presence structure
     * 
     * WHY: Phoenix Presence modules need use Phoenix.Presence with otp_app configuration
     * WHAT: Adds use statement to enable track/update/list functions
     * HOW: Detects isPresence metadata and adds Phoenix.Presence use statement
     */
    public static function presenceTransformPass(ast: ElixirAST): ElixirAST {
        // Use transformNode for recursive transformation
        return ElixirASTTransformer.transformNode(ast, function(node: ElixirAST): ElixirAST {
            switch(node.def) {
                case EDefmodule(name, body):
                    var looksLikePresence = node.metadata?.isPresence == true || (name != null && name.indexOf("Web.Presence") > 0);
                    if (looksLikePresence) {
                        var presenceBody = buildPresenceBody(name, body);
                        return makeASTWithMeta(EDefmodule(name, presenceBody), node.metadata, node.pos);
                    }
                    return node;
                case EModule(name, attrs, bodyExprs):
                    var looksLikePresence2 = node.metadata?.isPresence == true || (name != null && name.indexOf("Web.Presence") > 0);
                    if (looksLikePresence2) {
                        var presenceBody2 = buildPresenceBody(name, makeAST(EBlock(bodyExprs)));
                        return makeASTWithMeta(EDefmodule(name, presenceBody2), node.metadata, node.pos);
                    }
                    return node;
                default:
                    return node;
            }
        });
    }
    
    /**
     * Build Phoenix Presence module body with use statement
     */
    static function buildPresenceBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // Extract app name from module name (e.g., TodoAppWeb.Presence -> todo_app)
        var appName = extractAppName(moduleName);
        
        // use Phoenix.Presence, otp_app: :todo_app
        var useStatement = makeAST(EUse("Phoenix.Presence", [
            makeAST(EKeywordList([
                {key: "otp_app", value: makeAST(EAtom(appName))}
            ]))
        ]));
        statements.push(useStatement);
        
        // Add existing functions from the body
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    // Skip empty statements
                    switch(stmt.def) {
                        case ENil:
                            // Skip
                        default:
                            statements.push(stmt);
                    }
                }
            default:
                statements.push(existingBody);
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:router modules into Phoenix.Router structure
     * 
     * WHY: Phoenix routers require specific structure with use statement, pipelines, and scopes
     * WHAT: Replaces generated stub functions with complete Phoenix router setup
     * HOW: Detects isRouter metadata and builds proper Phoenix.Router AST
     */
    public static function routerTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        #end
        
        switch(ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isRouter == true):
                #if debug_annotation_transforms
                #end
                
                var routerBody = buildRouterBody(name, body);
                return makeASTWithMeta(EDefmodule(name, routerBody), ast.metadata, ast.pos);
            case EModule(name, attrs, body) if (ast.metadata?.isRouter == true):
                #if debug_annotation_transforms
                #end
                var routerBody2 = buildRouterBody(name, makeAST(EBlock(body)));
                return makeASTWithMeta(EDefmodule(name, routerBody2), ast.metadata, ast.pos);
                
            default:
                return ast;
        }
    }
    
    /**
     * Build Phoenix router body with pipelines and routes
     */
    static function buildRouterBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // Add use Phoenix.Router
        statements.push(makeAST(EUse("Phoenix.Router", [])));
        
        // Import LiveView router helpers
        statements.push(makeAST(EImport("Phoenix.LiveView.Router", null, null)));
        
        // For now, generate a simple working router structure using raw Elixir code
        // TODO: Create proper AST nodes for router DSL elements
        var routerCode = '
  pipeline :browser do
    plug :accepts, ["html"]
    plug :fetch_session
    plug :fetch_live_flash
    plug :put_root_layout, {${StringTools.replace(moduleName, ".Router", "")}.Layouts, :root}
    plug :protect_from_forgery
    plug :put_secure_browser_headers
  end

  pipeline :api do
    plug :accepts, ["json"]
  end

  scope "/", ${StringTools.replace(moduleName, ".Router", "")} do
    pipe_through :browser

    live "/", TodoLive, :index
    live "/todos", TodoLive, :index
    live "/todos/:id", TodoLive, :show
    live "/todos/:id/edit", TodoLive, :edit
  end

  scope "/api", ${StringTools.replace(moduleName, ".Router", "")} do
    pipe_through :api

    get "/users", UserController, :index
    post "/users", UserController, :create
    put "/users/:id", UserController, :update
    delete "/users/:id", UserController, :delete
  end

  if Mix.env() in [:dev, :test] do
    import Phoenix.LiveDashboard.Router

    scope "/dev" do
      pipe_through :browser

      live_dashboard "/dashboard", metrics: ${StringTools.replace(moduleName, ".Router", "")}.Telemetry
    end
  end';
        
        // Use raw Elixir code injection for now
        statements.push(makeAST(ERaw(routerCode)));
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:controller modules into Phoenix.Controller structure
     * 
     * WHY: Phoenix controllers need the use statement for controller functionality
     * WHAT: Adds use AppNameWeb, :controller at the beginning of the module
     * HOW: Detects isController metadata and adds the use statement
     */
    public static function controllerTransformPass(ast: ElixirAST): ElixirAST {
        // Check the top-level node first for Controller modules
        switch(ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isController == true || (name != null && name.indexOf("Web.") > 0 && name.indexOf("Controller") > 0)):
                #if debug_annotation_transforms
                #end
                
                var appName = ast.metadata.appName ?? "app";
                var controllerBody = buildControllerBody(name, appName, body);
                
                return makeASTWithMeta(
                    EDefmodule(name, controllerBody),
                    ast.metadata,
                    ast.pos
                );
            case EModule(name, attrs, exprs) if (ast.metadata?.isController == true || (name != null && name.indexOf("Web.") > 0 && name.indexOf("Controller") > 0)):
                var appName2 = ast.metadata.appName ?? "app";
                var controllerBody2 = buildControllerBody(name, appName2, makeAST(EBlock(exprs)));
                return makeASTWithMeta(EDefmodule(name, controllerBody2), ast.metadata, ast.pos);
            default:
                // Not a Controller module, just pass through
                return ast;
        }
    }
    
    /**
     * Build Phoenix Controller module body with use statement
     */
    static function buildControllerBody(moduleName: String, appName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // Extract app module name (e.g., "TodoApp" from "TodoAppWeb.UserController")
        var parts = moduleName.split(".");
        var webModuleName = parts.length > 0 ? parts[0] : '${capitalize(appName)}Web';
        
        // Add: use AppNameWeb, :controller
        statements.push(makeAST(EUse(
            webModuleName,
            [makeAST(EAtom(ElixirAtom.raw("controller")))]
        )));
        
        // Add the existing body
        switch(existingBody.def) {
            case EBlock(bodyStatements):
                statements = statements.concat(bodyStatements);
            default:
                statements.push(existingBody);
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Helper to capitalize first letter
     */
    static function capitalize(s: String): String {
        if (s.length == 0) return s;
        return s.charAt(0).toUpperCase() + s.substr(1);
    }
    
    /**
     * Transform @:schema modules into Ecto.Schema structure
     * 
     * WHY: Ecto schemas need specific structure with schema block and changeset
     * WHAT: Adds use Ecto.Schema, schema block with fields, and changeset function
     * HOW: Detects isSchema metadata and transforms module body
     */
    public static function schemaTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        if (ast.metadata != null && ast.metadata.isSchema == true) {
            trace('[XRay Schema Transform] Found schema module with isSchema metadata');
        }
        #end
        
        // Check the top-level node first for Schema modules
        switch(ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isSchema == true):
                #if debug_annotation_transforms
                trace('[XRay Schema Transform] Processing schema EDefmodule: ${name}');
                #end
                
                var tableName = ast.metadata.tableName ?? "items";
                var lookupName = ast.metadata?.haxeFqcn != null ? ast.metadata.haxeFqcn : name;
                var schemaBody = buildSchemaBody(name, tableName, body, lookupName, ast.metadata);
                
                return makeASTWithMeta(
                    EDefmodule(name, schemaBody),
                    ast.metadata,
                    ast.pos
                );
            
            case EModule(name, attrs, exprs) if (ast.metadata?.isSchema == true):
                #if debug_annotation_transforms
                trace('[XRay Schema Transform] Processing schema EModule: ${name}');
                #end
                
                var tableName = ast.metadata.tableName ?? "items";
                var lookupName = ast.metadata?.haxeFqcn != null ? ast.metadata.haxeFqcn : name;
                
                // Build the schema body with existing expressions
                var bodyStatements = [];
                
                // Add use Ecto.Schema and import Ecto.Changeset
                bodyStatements.push(makeAST(EUse("Ecto.Schema", [])));
                bodyStatements.push(makeAST(EImport("Ecto.Changeset", null, null)));
                
                // Build and add the schema block
                var schemaFieldStatements = [];
                if (ast.metadata != null && ast.metadata.schemaFields != null) {
                    for (f in ast.metadata.schemaFields) {
                        // Skip primary key id (Ecto adds by default)
                        if (f.name == "id") continue;
                        var elixirFieldName = reflaxe.elixir.ast.NameUtils.toSnakeCase(f.name);
                        var atomFieldName = makeAST(EAtom(elixirFieldName));
                        var fieldTypeAST = mapHaxeTypeToEctoFieldType(f.type);
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [
                            atomFieldName,
                            fieldTypeAST
                        ])));
                    }
                }
                
                // Add timestamps if specified
                if (ast.metadata?.hasTimestamps == true) {
                    schemaFieldStatements.push(makeAST(ECall(null, "timestamps", [])));
                }
                
                var schemaFields = makeAST(EBlock(schemaFieldStatements));
                var schemaBlock = makeAST(EMacroCall(
                    "schema",
                    [makeAST(EString(tableName))],
                    schemaFields
                ));
                bodyStatements.push(schemaBlock);
                
                // Add the existing functions
                for (expr in exprs) {
                    bodyStatements.push(expr);
                }
                
                // Return the transformed module
                return makeASTWithMeta(
                    EModule(name, attrs, bodyStatements),
                    ast.metadata,
                    ast.pos
                );
                
            default:
                // Not a Schema module, just pass through
                return ast;
        }
    }
    
    /**
     * Map Haxe types to Ecto field types
     * Returns an ElixirAST node for the field type (atom or tuple for complex types)
     */
    static function mapHaxeTypeToEctoFieldType(haxeType: String): ElixirAST {
        // Handle generic-like strings (e.g., "Array<String>") and aliases (e.g., "NaiveDateTime")
        if (haxeType == null) return makeAST(EAtom("string"));
        switch(haxeType) {
            case "String": return makeAST(EAtom("string"));
            case "Int": return makeAST(EAtom("integer"));
            case "Float": return makeAST(EAtom("float"));
            case "Bool": return makeAST(EAtom("boolean"));
            case "Date" | "NaiveDateTime": return makeAST(EAtom("naive_datetime"));
            case _:
                // Detect Array<...>
                if (StringTools.startsWith(haxeType, "Array<") && StringTools.endsWith(haxeType, ">")) {
                    var inner = haxeType.substr(6, haxeType.length - 7);
                    var innerAtom = switch (inner) {
                        case "String": "string";
                        case "Int": "integer";
                        case "Float": "float";
                        case "Bool": "boolean";
                        case "Date" | "NaiveDateTime": "naive_datetime";
                        case _: "string";
                    };
                    return makeAST(ETuple([
                        makeAST(EAtom("array")),
                        makeAST(EAtom(innerAtom))
                    ]));
                }
                // Fallback to string
                return makeAST(EAtom("string"));
        }
    }
    
    /**
     * Build Ecto.Schema module body
     */
    static function buildSchemaBody(moduleName: String, tableName: String, existingBody: ElixirAST, lookupName: String, meta: reflaxe.elixir.ast.ElixirMetadata): ElixirAST {
        var statements = [];
        
        // use Ecto.Schema
        statements.push(makeAST(EUse("Ecto.Schema", [])));
        
        // import Ecto.Changeset
        statements.push(makeAST(EImport("Ecto.Changeset", null, null)));
        
        // Extract schema fields from metadata (populated by ModuleBuilder)
        var schemaFieldStatements = [];
        var hasTimestamps: Bool = meta != null && meta.hasTimestamps == true;
        
        // Look for field metadata that might have been passed along
        // For now, we'll generate basic fields and rely on the functions being added below
        // The actual field extraction would require accessing the ClassType data
        // which would need to be passed through metadata
        
        // Use schemaFields provided in metadata. General, app-agnostic.
        if (meta != null && meta.schemaFields != null) {
            for (f in meta.schemaFields) {
                // Skip primary key id (Ecto adds by default)
                if (f.name == "id") continue;
                switch (f.type) {
                    case "Int":
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(EAtom(ElixirAtom.raw("integer"))) ])));
                    case "Bool":
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(EAtom(ElixirAtom.raw("boolean"))) ])));
                    case "NaiveDateTime":
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(EAtom(ElixirAtom.raw("naive_datetime"))) ])));
                    case "Float":
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(EAtom(ElixirAtom.raw("float"))) ])));
                    case "Array<String>":
                        // Use {:array, :string}
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(ETuple([makeAST(EAtom(ElixirAtom.raw("array"))), makeAST(EAtom(ElixirAtom.raw("string")))])) ])));
                    case _:
                        schemaFieldStatements.push(makeAST(ECall(null, "field", [ makeAST(EAtom(f.name)), makeAST(EAtom(ElixirAtom.raw("string"))) ])));
                }
            }
        }
        
        // Add timestamps only if class had @:timestamps
        if (hasTimestamps) schemaFieldStatements.push(makeAST(ECall(null, "timestamps", [])));
        
        var schemaFields = makeAST(EBlock(schemaFieldStatements));
        
        var schemaBlock = makeAST(EMacroCall(
            "schema",
            [makeAST(EString(tableName))],
            schemaFields
        ));
        statements.push(schemaBlock);
        
        // Add existing functions (including changeset functions)
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    switch(stmt.def) {
                        case ENil:
                            // Skip empty statements
                        default:
                            statements.push(stmt);
                    }
                }
            default:
                // Add the body if it's not empty
                if (existingBody.def != ENil) {
                    statements.push(existingBody);
                }
        }
        
        // Check if a changeset function exists in the body
        // If not, generate a basic one (this handles DCE issues)
        var hasChangeset = false;
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    switch(stmt.def) {
                        case EDef("changeset", _, _, _):
                            hasChangeset = true;
                        default:
                    }
                }
            default:
        }
        
        // If no changeset function was found, add a basic one
        // This ensures schemas always have a changeset function for Ecto compatibility
        if (!hasChangeset && meta?.schemaFields != null) {
            var castFields = [];
            var requiredFields = [];
            
            // Extract field names from metadata
            if (meta.schemaFields != null) {
                for (field in meta.schemaFields) {
                    if (field.name != "id" && field.name != "insertedAt" && field.name != "updatedAt") {
                        castFields.push(':${field.name}');
                        // Make some fields required based on type
                        if (field.type != null && field.type.indexOf("Null") == -1 && field.type.indexOf("array") == -1) {
                            requiredFields.push(field.name);
                        }
                    }
                }
            }
            
            // Generate a basic changeset function
            var castFieldsStr = castFields.join(", ");
            var requiredFieldsStr = requiredFields.map(f -> '"$f"').join(", ");
            var paramName = moduleName.toLowerCase();
            
            var changesetCode = '
  def changeset($paramName, attrs) do
    $paramName
    |> cast(attrs, [$castFieldsStr])' + 
    (requiredFields.length > 0 ? '\n    |> validate_required([$requiredFieldsStr])' : '') + '
  end';
            statements.push(makeAST(ERaw(changesetCode)));
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:repo modules into Ecto.Repo structure
     * 
     * WHY: Ecto repositories need use Ecto.Repo with otp_app and adapter configuration
     * WHAT: Adds use statement to enable database access functions (all/2, get/3, insert/2, etc.)
     * HOW: Detects isRepo metadata and adds Ecto.Repo use statement with configuration
     */
    public static function repoTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        trace("[XRay Repo Transform] PASS START");
        if (ast.metadata?.isRepo == true) {
            trace('[XRay Repo Transform] Found isRepo metadata on AST type: ${Type.enumConstructor(ast.def)}');
        }
        #end
        
        // Check the top-level node first for Repo modules
        switch(ast.def) {
            case EModule(name, attributes, body) if (ast.metadata?.isRepo == true):
                #if debug_annotation_transforms
                trace('[XRay Repo Transform] ✓ Processing @:repo EModule: $name');
                #end
                
                var appName = extractAppName(name);
                var repoBodyAST = buildRepoBody(name, appName);
                
                // EModule expects Array<ElixirAST> for body, so extract statements from EBlock
                var repoStatements = switch(repoBodyAST.def) {
                    case EBlock(stmts): stmts;
                    default: [repoBodyAST];
                };
                
                return makeASTWithMeta(
                    EModule(name, attributes, repoStatements),
                    ast.metadata,
                    ast.pos
                );
                
            case EDefmodule(name, body) if (ast.metadata?.isRepo == true):
                #if debug_annotation_transforms
                trace('[XRay Repo Transform] ✓ Processing @:repo module: $name');
                #end
                
                var appName = extractAppName(name);
                var repoBody = buildRepoBody(name, appName);
                
                return makeASTWithMeta(
                    EDefmodule(name, repoBody),
                    ast.metadata,
                    ast.pos
                );
                
            default:
                // Not a Repo module, just pass through
                return ast;
        }
    }

    /**
     * Transform @:postgrexTypes modules into a precompiled Postgrex types module
     *
     * WHY: Avoid runtime TypeManager races and allow custom JSON codecs
     * WHAT: Adds a module-level call to Postgrex.Types.define(__MODULE__, [], json: <jsonModule>)
     * HOW: Detects isPostgrexTypes metadata and builds a minimal module body
     */
    public static function postgrexTypesTransformPass(ast: ElixirAST): ElixirAST {
        switch (ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isPostgrexTypes == true):
                var jsonLib = ast.metadata.jsonModule != null ? ast.metadata.jsonModule : "Jason";
                var typesBody = buildDbTypesBody(name, "postgrex", jsonLib, []);
                return makeASTWithMeta(
                    EDefmodule(name, typesBody),
                    ast.metadata,
                    ast.pos
                );
            default:
                return ast;
        }
    }

    /** Generic DB types transformer */
    public static function dbTypesTransformPass(ast: ElixirAST): ElixirAST {
        switch (ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isDbTypes == true):
                var adapter = ast.metadata.dbAdapter != null ? ast.metadata.dbAdapter : "postgrex";
                var jsonLib = ast.metadata.jsonModule != null ? ast.metadata.jsonModule : "Jason";
                var exts = ast.metadata.extensions != null ? ast.metadata.extensions : [];
                
                // For Postgrex, the Types.define macro creates the module itself
                // So we return just the macro call without the defmodule wrapper
                switch(adapter.toLowerCase()) {
                    case "postgrex":
                        var opts = 'json: ' + jsonLib;
                        if (exts != null && exts.length > 0) {
                            var extList = '[' + exts.join(", ") + ']';
                            opts = opts + ', extensions: ' + extList;
                        }
                        // Generate the macro call with the module name directly
                        var line = 'Postgrex.Types.define(' + name + ', [], ' + opts + ')';
                        return makeAST(ERaw(line));
                    default:
                        // For other adapters, keep the module wrapper (they might need it)
                        var typesBody = buildDbTypesBody(name, adapter, jsonLib, exts);
                        return makeASTWithMeta(
                            EDefmodule(name, typesBody),
                            ast.metadata,
                            ast.pos
                        );
                }
            default:
                return ast;
        }
    }

    static function buildDbTypesBody(moduleName: String, adapter: String, jsonLib: String, extensions: Array<String>): ElixirAST {
        var statements = [];
        switch(adapter.toLowerCase()) {
            case "postgrex":
                // This case is now handled above, but keep for completeness
                var opts = 'json: ' + jsonLib;
                if (extensions != null && extensions.length > 0) {
                    var extList = '[' + extensions.join(", ") + ']';
                    opts = opts + ', extensions: ' + extList;
                }
                var line = 'Postgrex.Types.define(__MODULE__, [], ' + opts + ')';
                statements.push(makeAST(ERaw(line)));
            default:
                // Unknown adapter → emit a compile error as a clear message
                var err = 'raise("Unsupported DB adapter for @:dbTypes: ' + adapter + '")';
                statements.push(makeAST(ERaw(err)));
        }
        return makeAST(EBlock(statements));
    }
    
    /**
     * Build Ecto.Repo module body
     * 
     * WHY: Ecto repositories need use statement to inject database functions
     * WHAT: Creates minimal module with use Ecto.Repo and configuration
     * HOW: Generates use statement with otp_app and adapter options
     */
    static function buildRepoBody(moduleName: String, appName: String): ElixirAST {
        var statements = [];
        
        // use Ecto.Repo, otp_app: :app_name, adapter: Ecto.Adapters.Postgres
        var useOptions = makeAST(EKeywordList([
            {key: "otp_app", value: makeAST(EAtom(appName))},
            {key: "adapter", value: makeAST(EField(
                makeAST(EField(makeAST(EVar("Ecto")), "Adapters")),
                "Postgres"
            ))}
        ]));
        
        // EUse expects an array of options, with the keyword list as one element
        statements.push(makeAST(EUse("Ecto.Repo", [useOptions])));
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:application modules into OTP Application structure
     * 
     * WHY: OTP applications need specific callbacks and supervision tree
     * WHAT: Adds use Application and start/2 callback
     * HOW: Detects isApplication metadata and transforms module body
     */
    public static function applicationTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        if (ast.metadata != null && ast.metadata.isApplication == true) {
            trace('[XRay Application Transform] PASS START - Found Application module with metadata');
            trace('[XRay Application Transform] AST type: ${Type.enumConstructor(ast.def)}');
        }
        #end
        
        // Check the top-level node first for Application modules
        switch(ast.def) {
            case EModule(name, attributes, body) if (ast.metadata?.isApplication == true):
                #if debug_annotation_transforms
                trace('[XRay Application Transform] Processing EModule: $name');
                #end
                
                // For EModule, body is Array<ElixirAST>, need to handle differently
                var appBody = buildApplicationBodyFromArray(name, body);
                
                return makeASTWithMeta(
                    EModule(name, attributes, appBody),
                    ast.metadata,
                    ast.pos
                );
                
            case EDefmodule(name, body) if (ast.metadata?.isApplication == true):
                #if debug_annotation_transforms
                trace('[XRay Application Transform] Processing EDefmodule: $name');
                #end
                
                var appBody = buildApplicationBody(name, body);
                
                return makeASTWithMeta(
                    EDefmodule(name, appBody),
                    ast.metadata,
                    ast.pos
                );
                
            default:
                // Not an Application module, just pass through
                return ast;
        }
    }
    
    /**
     * Build OTP Application module body for Array<ElixirAST> (from EModule)
     */
    static function buildApplicationBodyFromArray(moduleName: String, existingBody: Array<ElixirAST>): Array<ElixirAST> {
        var result = [];
        
        #if debug_annotation_transforms
        trace('[XRay Application Transform] buildApplicationBodyFromArray - existing functions: ${existingBody.length}');
        #end
        
        // Add use Application
        result.push(makeAST(EUse("Application", [])));
        
        // Add existing functions
        for (func in existingBody) {
            #if debug_annotation_transforms
            if (func.def != null) {
                trace('[XRay Application Transform] Adding existing function: ${Type.enumConstructor(func.def)}');
            }
            #end
            result.push(func);
        }
        
        return result;
    }
    
    /**
     * Build OTP Application module body for ElixirAST (from EDefmodule)
     */
    static function buildApplicationBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // use Application
        statements.push(makeAST(EUse("Application", [])));
        
        // Add existing functions or create default start/2
        var hasStart = false;
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    switch(stmt.def) {
                        case EDef(name, _, _, _) if (name == "start"):
                            hasStart = true;
                            statements.push(stmt);
                        case ENil:
                            // Skip
                        default:
                            statements.push(stmt);
                    }
                }
            default:
                // Add the body if it's not empty
        }
        
        // Add default start/2 if not present
        if (!hasStart) {
            var startBody = makeAST(EBlock([
                // children = []
                makeAST(EMatch(
                    EPattern.PVar("children"),
                    makeAST(EList([]))
                )),
                // opts = [strategy: :one_for_one, name: Module.Supervisor]
                makeAST(EMatch(
                    EPattern.PVar("opts"),
                    makeAST(EKeywordList([
                        {key: "strategy", value: makeAST(EAtom(ElixirAtom.raw("one_for_one")))},
                        {key: "name", value: makeAST(EVar(moduleName + ".Supervisor"))}
                    ]))
                )),
                // Supervisor.start_link(children, opts)
                makeAST(ERemoteCall(
                    makeAST(EVar("Supervisor")),
                    "start_link",
                    [
                        makeAST(EVar("children")),
                        makeAST(EVar("opts"))
                    ]
                ))
            ]));
            
            statements.push(makeAST(EDef(
                "start",
                [EPattern.PVar("_type"), EPattern.PVar("_args")],
                null,
                startBody
            )));
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Transform @:phoenixWeb modules into Phoenix Web helper module
     * 
     * WHY: Phoenix Web modules need specific macro definitions for router, controller, etc.
     * WHAT: Adds defmacro definitions that Phoenix expects for 'use TodoAppWeb, :router'
     * HOW: Detects isPhoenixWeb metadata and transforms module body
     */
    public static function phoenixWebTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        #end
        
        // Check the top-level node first for PhoenixWeb modules
        switch(ast.def) {
            case EDefmodule(name, body) if (ast.metadata?.isPhoenixWeb == true || (name != null && (StringTools.endsWith(name, "Web") && name.indexOf(".") == -1))):
                var phoenixWebBody = buildPhoenixWebBody(name, body);
                // Extract statements from EBlock
                var stmts:Array<ElixirAST> = switch (phoenixWebBody.def) { case EBlock(es): es; default: [phoenixWebBody]; };
                // Inject @compile {:nowarn_unused_function, [html_helpers: 0]}
                var compileAttr:EAttribute = {
                    name: "compile",
                    value: makeAST(ETuple([
                        makeAST(EAtom("nowarn_unused_function")),
                        makeAST(EKeywordList([{key: "html_helpers", value: makeAST(EInteger(0))}]))
                    ]))
                };
                return makeASTWithMeta(EModule(name, [compileAttr], stmts), ast.metadata, ast.pos);
            case EModule(name, attrs, exprs) if (ast.metadata?.isPhoenixWeb == true || (name != null && (StringTools.endsWith(name, "Web") && name.indexOf(".") == -1))):
                var phoenixWebBody2 = buildPhoenixWebBody(name, makeAST(EBlock(exprs)));
                var stmts2:Array<ElixirAST> = switch (phoenixWebBody2.def) { case EBlock(es): es; default: [phoenixWebBody2]; };
                var compileAttr2:EAttribute = {
                    name: "compile",
                    value: makeAST(ETuple([
                        makeAST(EAtom("nowarn_unused_function")),
                        makeAST(EKeywordList([{key: "html_helpers", value: makeAST(EInteger(0))}]))
                    ]))
                };
                return makeASTWithMeta(EModule(name, [compileAttr2], stmts2), ast.metadata, ast.pos);
            default:
                // Not a PhoenixWeb module, just pass through
                return ast;
        }
    }
    
    /**
     * Build Phoenix Web module body with macro definitions
     */
    static function buildPhoenixWebBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // Add existing functions first (like static_paths)
        switch(existingBody.def) {
            case EBlock(stmts):
                for (stmt in stmts) {
                    switch(stmt.def) {
                        case ENil:
                            // Skip
                        default:
                            statements.push(stmt);
                    }
                }
            default:
                if (existingBody.def != ENil) {
                    statements.push(existingBody);
                }
        }
        
        // defmacro __using__(which) when is_atom(which) do
        var usingMacroBody = makeAST(ECall(null, "apply", [
            makeAST(EVar("__MODULE__")),
            makeAST(EVar("which")),
            makeAST(EList([]))
        ]));
        
        statements.push(makeAST(EDefmacro(
            "__using__",
            [EPattern.PVar("which")],
            makeAST(ECall(null, "is_atom", [makeAST(EVar("which"))])),
            usingMacroBody
        )));
        
        // Extract base app name from module name (e.g., "TodoAppWeb" -> "TodoApp")
        var appBaseName = StringTools.replace(moduleName, "Web", "");
        
        // def router do
        var routerBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.Router", [])),
            makeAST(EImport("Phoenix.LiveView.Router", null, null)),
            makeAST(EImport(moduleName, null, [
                {name: "controller", arity: 0},
                {name: "live_view", arity: 0}, 
                {name: "live_component", arity: 0}
            ])),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "verified_routes", []))]))
        ]))));
        
        statements.push(makeAST(EDef(
            "router",
            [],
            null,
            routerBody
        )));
        
        // def controller do
        var controllerBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.Controller", [
                makeAST(EKeywordList([
                    {key: "formats", value: makeAST(EList([makeAST(EAtom(ElixirAtom.raw("html"))), makeAST(EAtom(ElixirAtom.raw("json")))]))},
                    {key: "layouts", value: makeAST(EKeywordList([
                        {key: "html", value: makeAST(ETuple([
                            makeAST(EVar(moduleName + ".Layouts")),
                            makeAST(EAtom(ElixirAtom.raw("app")))
                        ]))}
                    ]))}
                ]))
            ])),
            makeAST(EImport("Plug.Conn", null, null)),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "verified_routes", []))]))
        ]))));
        
        statements.push(makeAST(EDef(
            "controller",
            [],
            null,
            controllerBody
        )));
        
        // def live_view do
        var liveViewBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.LiveView", [
                makeAST(EKeywordList([
                    {key: "layout", value: makeAST(ETuple([
                        makeAST(EVar(moduleName + ".Layouts")),
                        makeAST(EAtom(ElixirAtom.raw("app")))
                    ]))}
                ]))
            ])),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "html_helpers", []))]))
        ]))));
        
        statements.push(makeAST(EDef(
            "live_view",
            [],
            null,
            liveViewBody
        )));
        
        // def live_component do
        var liveComponentBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.LiveComponent", [])),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "html_helpers", []))]))
        ]))));
        
        statements.push(makeAST(EDef(
            "live_component",
            [],
            null,
            liveComponentBody
        )));
        
        // def html do
        var htmlBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.Component", [])),
            makeAST(EImport(moduleName + ".CoreComponents", null, null)),
            makeAST(EImport(moduleName + ".Gettext", null, null)),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "html_helpers", []))])),
            makeAST(ECall(null, "unquote", [makeAST(ECall(null, "verified_routes", []))]))
        ]))));
        
        statements.push(makeAST(EDef(
            "html",
            [],
            null,
            htmlBody
        )));
        
        // defp html_helpers do
        var htmlHelpersBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EImport("Phoenix.HTML", null, null)),
            makeAST(EImport("Phoenix.HTML.Form", null, null)),
            makeAST(EAlias("Phoenix.HTML.Form", "Form"))
        ]))));
        
        statements.push(makeAST(EDefp(
            "html_helpers",
            [],
            null,
            htmlHelpersBody
        )));
        
        // def verified_routes do
        var verifiedRoutesBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.VerifiedRoutes", [
                makeAST(EKeywordList([
                    {key: "endpoint", value: makeAST(EVar(moduleName + ".Endpoint"))},
                    {key: "router", value: makeAST(EVar(moduleName + ".Router"))},
                    {key: "statics", value: makeAST(ERemoteCall(
                        makeAST(EVar(moduleName)),
                        "static_paths",
                        []
                    ))}
                ]))
            ]))
        ]))));
        
        statements.push(makeAST(EDef(
            "verified_routes",
            [],
            null,
            verifiedRoutesBody
        )));
        
        // def channel do
        var channelBody = makeAST(EQuote([], makeAST(EBlock([
            makeAST(EUse("Phoenix.Channel", [])),
            makeAST(EImport(moduleName + ".Gettext", null, null))
        ]))));
        
        statements.push(makeAST(EDef(
            "channel",
            [],
            null,
            channelBody
        )));
        
        // def static_paths do
        // This function is expected by Phoenix.VerifiedRoutes
        statements.push(makeAST(EDef(
            "static_paths",
            [],
            null,
            makeAST(EList([
                makeAST(EString("assets")),
                makeAST(EString("fonts")),
                makeAST(EString("images")),
                makeAST(EString("favicon.ico")),
                makeAST(EString("robots.txt"))
            ]))
        )));
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * Extract app name from module name
     * 
     * Examples:
     * - TodoAppWeb.Presence -> todo_app
     * - MyApp.Presence -> my_app
     * - SomeModuleWeb.Presence -> some_module
     */
    static function extractAppName(moduleName: String): String {
        // Remove Web suffix if present
        var name = moduleName;
        var webIndex = name.indexOf("Web.");
        if (webIndex > 0) {
            name = name.substring(0, webIndex);
        }
        
        // Remove module path after last dot
        var lastDotIndex = name.lastIndexOf(".");
        if (lastDotIndex > 0) {
            name = name.substring(0, lastDotIndex);
        }
        
        // Convert CamelCase to snake_case
        var result = "";
        for (i in 0...name.length) {
            var char = name.charAt(i);
            if (i > 0 && char == char.toUpperCase() && char != char.toLowerCase()) {
                result += "_";
            }
            result += char.toLowerCase();
        }
        
        return result;
    }
    
    /**
     * Transform @:exunit modules into ExUnit.Case test modules
     * 
     * WHY: ExUnit tests require specific structure with use statement and test macros
     * WHAT: Transforms classes marked with @:exunit into proper ExUnit test modules
     * HOW: Detects isExunit metadata and transforms methods with @:test into test blocks
     */
    public static function exunitTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        trace("[XRay ExUnit Transform] PASS START");
        trace('[XRay ExUnit Transform] AST type: ${Type.enumConstructor(ast.def)}');
        if (ast.metadata != null) {
            trace('[XRay ExUnit Transform] AST has metadata: isExunit=${ast.metadata.isExunit}');
        } else {
            trace('[XRay ExUnit Transform] AST has NO metadata');
        }
        #end
        
        // Check the top-level node first for ExUnit modules
        switch(ast.def) {
            case EModule(name, attributes, bodyExprs):
                #if debug_annotation_transforms
                trace('[XRay ExUnit Transform] Found EModule: $name');
                if (ast.metadata != null) {
                    trace('[XRay ExUnit Transform] Module metadata exists, isExunit=${ast.metadata.isExunit}');
                } else {
                    trace('[XRay ExUnit Transform] Module has NO metadata!');
                }
                #end

                // Check if metadata indicates ExUnit module
                var isExunit = ast.metadata?.isExunit == true;

                if (isExunit) {
                    #if debug_annotation_transforms
                    trace('[XRay ExUnit Transform] ✓ Processing @:exunit module: $name');
                    #end

                    // Create a block from the body expressions
                    var bodyBlock = makeAST(EBlock(bodyExprs));
                    var exunitBody = buildExUnitBody(name, bodyBlock);

                    // Convert EModule to EDefmodule for ExUnit output
                    return makeASTWithMeta(
                        EDefmodule(name, exunitBody),
                        ast.metadata,
                        ast.pos
                    );
                }
                // Not an ExUnit module, return as-is
                return ast;

            case EDefmodule(name, body):
                #if debug_annotation_transforms
                trace('[XRay ExUnit Transform] Found EDefmodule: $name');
                if (ast.metadata != null) {
                    trace('[XRay ExUnit Transform] Module metadata exists, isExunit=${ast.metadata.isExunit}');
                } else {
                    trace('[XRay ExUnit Transform] Module has NO metadata!');
                }
                #end

                // Check if metadata indicates ExUnit module
                var isExunit = ast.metadata?.isExunit == true;
                
                // WORKAROUND: If metadata is missing, detect ExUnit module by checking for test functions
                if (!isExunit) {
                    switch(body.def) {
                        case EBlock(exprs):
                            for (expr in exprs) {
                                if (expr.metadata?.isTest == true || 
                                    expr.metadata?.isSetup == true || 
                                    expr.metadata?.isSetupAll == true ||
                                    expr.metadata?.isTeardown == true ||
                                    expr.metadata?.isTeardownAll == true) {
                                    #if debug_annotation_transforms
                                    trace('[XRay ExUnit Transform] ✓ Detected ExUnit module by test function metadata');
                                    #end
                                    isExunit = true;
                                    break;
                                }
                            }
                        default:
                    }
                }
                
                if (isExunit) {
                    #if debug_annotation_transforms
                    trace('[XRay ExUnit Transform] ✓ Processing @:exunit module: $name');
                    #end
                    
                    var exunitBody = buildExUnitBody(name, body);
                    
                    return makeASTWithMeta(
                        EDefmodule(name, exunitBody),
                        ast.metadata,
                        ast.pos
                    );
                }
                // Not an ExUnit module, return as-is
                return ast;
                
            default:
                // Not a module, just pass through
                return ast;
        }
    }
    
    /**
     * Build ExUnit.Case module body
     * 
     * WHY: ExUnit modules need use ExUnit.Case and test macros
     * WHAT: Transforms regular functions into test blocks with support for describe blocks, async, and tags
     * HOW: Adds use statement, groups tests by describe blocks, and transforms @:test methods with proper attributes
     */
    static function buildExUnitBody(moduleName: String, existingBody: ElixirAST): ElixirAST {
        var statements = [];
        
        // Check if module should be async by scanning for any async tests
        var hasAsyncTests = false;
        switch(existingBody.def) {
            case EBlock(exprs):
                for (expr in exprs) {
                    if (expr.metadata?.isAsync == true) {
                        hasAsyncTests = true;
                        break;
                    }
                }
            default:
        }
        
        // use ExUnit.Case with async option if needed
        if (hasAsyncTests) {
            // Create keyword list [async: true] for ExUnit.Case options
            statements.push(makeAST(EUse("ExUnit.Case", [
                makeAST(EKeywordList([
                    {key: "async", value: makeAST(EAtom(ElixirAtom.true_()))}
                ]))
            ])));
        } else {
            statements.push(makeAST(EUse("ExUnit.Case", [])));
        }

        // Optional Phoenix test helpers: only inject when app_name is defined (indicates Phoenix app context)
        var appName = Context.definedValue("app_name");
        if (appName != null && appName.length > 0) {
            // Import brings functions like build_conn/0 into scope; alias supports ConnTest.* calls.
            statements.push(makeAST(EImport("Phoenix.ConnTest", null, null)));
            statements.push(makeAST(EAlias("Phoenix.ConnTest", "ConnTest")));
            // Inject Phoenix.LiveViewTest helpers and alias for LiveViewTest.* calls
            statements.push(makeAST(EImport("Phoenix.LiveViewTest", null, null)));
            statements.push(makeAST(EAlias("Phoenix.LiveViewTest", "LiveViewTest")));
            // Set @endpoint for ConnTest when app_name is provided
            var endpointModule = appName + "Web.Endpoint";
            statements.push(makeAST(EModuleAttribute("endpoint", makeAST(EVar(endpointModule)))));
        }
        
        // Group tests by describe blocks
        var testsWithoutDescribe = [];
        var describeGroups = new Map<String, Array<ElixirAST>>();
        
        // Process existing body to transform test methods
        switch(existingBody.def) {
            case EBlock(exprs):
                for (expr in exprs) {
                    switch(expr.def) {
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isTest == true):
                            // Transform function into test block
                            var testName = name;
                            // Remove "test" prefix if present
                            if (StringTools.startsWith(testName, "test_")) {
                                testName = testName.substring(5);
                            } else if (StringTools.startsWith(testName, "test")) {
                                testName = testName.substring(4);
                            }
                            // Convert to readable name (snake_case to spaces)
                            testName = StringTools.replace(testName, "_", " ");
                            
                            // Check for tags
                            var testTags = expr.metadata?.testTags;
                            var taggedTestName = testName;
                            if (testTags != null && testTags.length > 0) {
                                // Add tags as @tag annotations before the test
                                for (tag in testTags) {
                                    taggedTestName = '@tag $tag\n  $taggedTestName';
                                }
                            }
                            
                            var testBlock = makeAST(
                                EMacroCall(
                                    "test",
                                    [makeAST(EString(testName))],
                                    body
                                )
                            );
                            
                            // Check if this test belongs to a describe block
                            var describeBlock = expr.metadata?.describeBlock;
                            if (describeBlock != null) {
                                if (!describeGroups.exists(describeBlock)) {
                                    describeGroups.set(describeBlock, []);
                                }
                                describeGroups.get(describeBlock).push(testBlock);
                            } else {
                                testsWithoutDescribe.push(testBlock);
                            }
                            
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isSetup == true):
                            // Transform @:setup function into ExUnit setup callback
                            var setupBlock = makeAST(
                                EMacroCall(
                                    "setup",
                                    [makeAST(EVar("context"))],
                                    body
                                )
                            );
                            statements.push(setupBlock);
                            
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isSetupAll == true):
                            // Transform @:setupAll function into ExUnit setup_all callback
                            var setupAllBlock = makeAST(
                                EMacroCall(
                                    "setup_all",
                                    [makeAST(EVar("context"))],
                                    body
                                )
                            );
                            statements.push(setupAllBlock);
                            
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isTeardown == true):
                            // Transform @:teardown function into ExUnit on_exit callback
                            var teardownBody = makeAST(
                                EBlock([
                                    makeAST(
                                        ECall(
                                            null,  // No target needed for on_exit
                                            "on_exit",
                                            [makeAST(EFn([{args: [], guard: null, body: body}]))]
                                        )
                                    ),
                                    makeAST(EAtom(ElixirAtom.ok()))
                                ])
                            );
                            var teardownBlock = makeAST(
                                EMacroCall(
                                    "setup",
                                    [makeAST(EVar("context"))],
                                    teardownBody
                                )
                            );
                            statements.push(teardownBlock);
                            
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isTeardownAll == true):
                            // Transform @:teardownAll function into ExUnit on_exit callback in setup_all
                            var teardownAllBody = makeAST(
                                EBlock([
                                    makeAST(
                                        ECall(
                                            null,  // No target needed for on_exit
                                            "on_exit",
                                            [makeAST(EFn([{args: [], guard: null, body: body}]))]
                                        )
                                    ),
                                    makeAST(EAtom(ElixirAtom.ok()))
                                ])
                            );
                            var teardownAllBlock = makeAST(
                                EMacroCall(
                                    "setup_all",
                                    [makeAST(EVar("context"))],
                                    teardownAllBody
                                )
                            );
                            statements.push(teardownAllBlock);
                            
                        case EDef(name, _, _, _) if (name == "setup" || name == "setupAll"):
                            // Keep setup functions as-is for backward compatibility
                            statements.push(expr);
                            
                        case EDefp(name, _, _, _) if (name == "setup" || name == "setupAll"):
                            // Keep private setup functions as-is for backward compatibility
                            statements.push(expr);
                            
                        default:
                            // Keep other expressions (but not in main statements yet)
                            // They'll be added after describe blocks
                    }
                }
                
                // First add setup/teardown blocks
                for (expr in exprs) {
                    switch(expr.def) {
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isSetup == true || 
                                                                                                       expr.metadata?.isSetupAll == true ||
                                                                                                       expr.metadata?.isTeardown == true ||
                                                                                                       expr.metadata?.isTeardownAll == true):
                            // Already processed above, skip
                        case EDef(name, params, guards, body) | EDefp(name, params, guards, body) if (expr.metadata?.isTest == true):
                            // Already processed above, skip
                        default:
                            // Keep other expressions
                            statements.push(expr);
                    }
                }
                
                // Add tests without describe blocks
                for (test in testsWithoutDescribe) {
                    statements.push(test);
                }
                
                // Add describe blocks with their grouped tests
                for (describeName in describeGroups.keys()) {
                    var tests = describeGroups.get(describeName);
                    if (tests.length > 0) {
                        // Create describe block containing all tests in this group
                        var describeBlock = makeAST(
                            EMacroCall(
                                "describe",
                                [makeAST(EString(describeName))],
                                makeAST(EBlock(tests))
                            )
                        );
                        statements.push(describeBlock);
                    }
                }
                
            default:
                // Single expression body
                statements.push(existingBody);
        }
        
        return makeAST(EBlock(statements));
    }
    
    /**
     * supervisorTransformPass: Preserve supervisor functions from dead code elimination
     * 
     * WHY: Phoenix/OTP calls child_spec/1 and start_link/1 at runtime via supervision tree
     * WHAT: Ensures these functions are marked with @:keep metadata to prevent DCE
     * HOW: Detects isSupervisor metadata and marks critical functions for preservation
     * 
     * BACKGROUND: Haxe's Dead Code Elimination (DCE) removes "unused" functions. But
     * supervisor child_spec and start_link are called by the OTP framework at runtime,
     * not from our Haxe code. Without @:keep, they get deleted and Phoenix crashes.
     */
    public static function supervisorTransformPass(ast: ElixirAST): ElixirAST {
        #if debug_annotation_transforms
        if (ast.metadata?.isSupervisor == true) {
            trace('[XRay Supervisor Transform] PASS START - Found Supervisor module');
            trace('[XRay Supervisor Transform] AST type: ${Type.enumConstructor(ast.def)}');
        }
        #end
        
        // Check if this is a supervisor module
        var isSupervisor = ast.metadata?.isSupervisor == true;
        if (!isSupervisor) {
            // Not a supervisor, pass through unchanged
            return ast;
        }
        
        // Process the module to ensure critical functions are preserved
        switch(ast.def) {
            case EModule(name, attributes, body):
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Processing supervisor EModule: $name');
                #end
                
                // Transform the body array to preserve supervisor functions
                var transformedBody = preserveSupervisorFunctionsInArray(body, name, ast.metadata);
                
                // Return the module with transformed body
                return makeASTWithMeta(
                    EModule(name, attributes, transformedBody),
                    ast.metadata,
                    ast.pos
                );
                
            case EDefmodule(name, body):
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Processing supervisor EDefmodule: $name');
                #end
                
                // Transform the body to preserve supervisor functions
                var transformedBody = preserveSupervisorFunctionsInAST(body, name, ast.metadata);
                
                // Return the module with transformed body
                return makeASTWithMeta(
                    EDefmodule(name, transformedBody),
                    ast.metadata,
                    ast.pos
                );
                
            default:
                // Not a module definition, pass through
                return ast;
        }
    }
    
    /**
     * Helper to preserve supervisor functions from DCE in Array body (EModule)
     */
    static function preserveSupervisorFunctionsInArray(body: Array<ElixirAST>, moduleName: String, metadata: ElixirMetadata): Array<ElixirAST> {
        var statements = [];
        var hasChildSpec = false;
        var hasStartLink = false;
        
        // Process each statement in the array
        for (expr in body) {
            switch(expr.def) {
                case EDef(name, params, guards, fnBody) | EDefp(name, params, guards, fnBody):
                    if (name == "child_spec") {
                        hasChildSpec = true;
                        // Mark with keep metadata
                        var newMetadata = if (expr.metadata != null) {
                            var meta = Reflect.copy(expr.metadata);
                            meta.isKeep = true;
                            meta;
                        } else {
                            {isKeep: true};
                        };
                        
                        var preservedFunc = makeASTWithMeta(
                            expr.def,
                            newMetadata,
                            expr.pos
                        );
                        statements.push(preservedFunc);
                        #if debug_annotation_transforms
                        trace('[XRay Supervisor Transform] Marked child_spec for preservation');
                        #end
                    } else if (name == "start_link") {
                        hasStartLink = true;
                        // Mark with keep metadata
                        var newMetadata = if (expr.metadata != null) {
                            var meta = Reflect.copy(expr.metadata);
                            meta.isKeep = true;
                            meta;
                        } else {
                            {isKeep: true};
                        };
                        
                        var preservedFunc = makeASTWithMeta(
                            expr.def,
                            newMetadata,
                            expr.pos
                        );
                        statements.push(preservedFunc);
                        #if debug_annotation_transforms
                        trace('[XRay Supervisor Transform] Marked start_link for preservation');
                        #end
                    } else {
                        // Keep other functions as-is
                        statements.push(expr);
                    }
                default:
                    // Keep other expressions
                    statements.push(expr);
            }
        }
        
        // If supervisor module needs use Supervisor statement, add it
        var needsUseSupervisor = metadata?.isSupervisor == true && 
                                 metadata?.isEndpoint != true && 
                                 metadata?.isApplication != true;
        
        if (needsUseSupervisor) {
            // Check if we already have use Supervisor and init/1
            var hasUseSupervisor = false;
            var hasInit = false;
            
            for (stmt in statements) {
                switch(stmt.def) {
                    case EUse("Supervisor", _):
                        hasUseSupervisor = true;
                    case EDef("init", _, _, _):
                        hasInit = true;
                    default:
                }
            }
            
            if (!hasUseSupervisor) {
                // Add use Supervisor at the beginning
                statements.insert(0, makeAST(EUse("Supervisor", [])));
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Added use Supervisor statement');
                #end
            }
            
            if (!hasInit) {
                // Add default init/1 callback that delegates to start_link
                var initBody = makeAST(
                    ETuple([
                        makeAST(EAtom("ok")),
                        makeAST(ETuple([
                            makeAST(EList([])),  // Empty children list
                            makeAST(EKeywordList([
                                {key: "strategy", value: makeAST(EAtom("one_for_one"))},
                                {key: "max_restarts", value: makeAST(EInteger(3))},
                                {key: "max_seconds", value: makeAST(EInteger(5))}
                            ]))
                        ]))
                    ])
                );
                
                var initFunc = makeAST(
                    EDef("init", [PVar("_args")], null, initBody)
                );
                
                statements.push(initFunc);
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Added default init/1 callback');
                #end
            }
        }
        
        return statements;
    }
    
    /**
     * Helper to preserve supervisor functions from DCE in AST body (EDefmodule)
     */
    static function preserveSupervisorFunctionsInAST(body: ElixirAST, moduleName: String, metadata: ElixirMetadata): ElixirAST {
        var statements = [];
        var hasChildSpec = false;
        var hasStartLink = false;
        
        // First, check what functions exist and mark them for preservation
        switch(body.def) {
            case EBlock(exprs):
                for (expr in exprs) {
                    switch(expr.def) {
                        case EDef(name, params, guards, fnBody) | EDefp(name, params, guards, fnBody):
                            if (name == "child_spec") {
                                hasChildSpec = true;
                                // Mark with keep metadata
                                var newMetadata = if (expr.metadata != null) {
                                    var meta = Reflect.copy(expr.metadata);
                                    meta.isKeep = true;
                                    meta;
                                } else {
                                    {isKeep: true};
                                };
                                
                                var preservedFunc = makeASTWithMeta(
                                    expr.def,
                                    newMetadata,
                                    expr.pos
                                );
                                statements.push(preservedFunc);
                                #if debug_annotation_transforms
                                trace('[XRay Supervisor Transform] Marked child_spec for preservation');
                                #end
                            } else if (name == "start_link") {
                                hasStartLink = true;
                                // Mark with keep metadata
                                var newMetadata = if (expr.metadata != null) {
                                    var meta = Reflect.copy(expr.metadata);
                                    meta.isKeep = true;
                                    meta;
                                } else {
                                    {isKeep: true};
                                };
                                
                                var preservedFunc = makeASTWithMeta(
                                    expr.def,
                                    newMetadata,
                                    expr.pos
                                );
                                statements.push(preservedFunc);
                                #if debug_annotation_transforms
                                trace('[XRay Supervisor Transform] Marked start_link for preservation');
                                #end
                            } else {
                                // Keep other functions as-is
                                statements.push(expr);
                            }
                        default:
                            // Keep other expressions
                            statements.push(expr);
                    }
                }
            default:
                // Single expression body
                return body;
        }
        
        // If supervisor module needs use Supervisor statement, add it
        // (This would typically be done in a separate pass, but we can ensure it here)
        var needsUseSupervisor = metadata?.isSupervisor == true && 
                                 metadata?.isEndpoint != true && 
                                 metadata?.isApplication != true;
        
        if (needsUseSupervisor) {
            // Check if we already have use Supervisor and init/1
            var hasUseSupervisor = false;
            var hasInit = false;
            
            for (stmt in statements) {
                switch(stmt.def) {
                    case EUse("Supervisor", _):
                        hasUseSupervisor = true;
                    case EDef("init", _, _, _):
                        hasInit = true;
                    default:
                }
            }
            
            if (!hasUseSupervisor) {
                // Add use Supervisor at the beginning
                statements.insert(0, makeAST(EUse("Supervisor", [])));
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Added use Supervisor statement');
                #end
            }
            
            if (!hasInit) {
                // Add default init/1 callback that delegates to start_link
                var initBody = makeAST(
                    ETuple([
                        makeAST(EAtom("ok")),
                        makeAST(ETuple([
                            makeAST(EList([])),  // Empty children list
                            makeAST(EKeywordList([
                                {key: "strategy", value: makeAST(EAtom("one_for_one"))},
                                {key: "max_restarts", value: makeAST(EInteger(3))},
                                {key: "max_seconds", value: makeAST(EInteger(5))}
                            ]))
                        ]))
                    ])
                );
                
                var initFunc = makeAST(
                    EDef("init", [PVar("_args")], null, initBody)
                );
                
                statements.push(initFunc);
                #if debug_annotation_transforms
                trace('[XRay Supervisor Transform] Added default init/1 callback');
                #end
            }
        }
        
        return makeAST(EBlock(statements));
    }
}

#end
</file>

<file path="src/reflaxe/elixir/ast/ElixirAST.hx">
package reflaxe.elixir.ast;

#if (macro || reflaxe_runtime)

import haxe.macro.Type;
import haxe.macro.Type.TypedExpr;
import haxe.macro.Expr.Position;
import reflaxe.elixir.ast.naming.ElixirAtom;

/**
 * ElixirAST: Strongly-Typed Intermediate AST for Reflaxe.Elixir
 *
 * WHY: Replace string manipulation with type-safe AST operations to enable:
 * - Semantic understanding of code structure
 * - Independent transformation passes
 * - Better debugging and inspection
 * - Context preservation through metadata
 *
 * WHAT: Complete representation of Elixir language constructs with:
 * - All syntax nodes (modules, functions, expressions, patterns)
 * - Rich metadata for each node
 * - Zero Dynamic types - everything strongly typed
 * - Support for all Elixir idioms and Phoenix patterns
 *
 * HOW: Three-phase compilation pipeline uses this AST:
 * 1. ElixirASTBuilder converts TypedExpr → ElixirAST
 * 2. ElixirASTTransformer applies idiom/framework transformations
 * 3. ElixirPrinter generates string output
 *
 * @see docs/03-compiler-development/INTERMEDIATE_AST_REFACTORING_PRD.md
 */

// ============================================================================
// Variable Origin Tracking (January 2025)
// ============================================================================

/**
 * Variable origin enum for distinguishing between different variable sources
 *
 * WHY: To solve false positive detection where legitimate variables like "g" in RGB(r,g,b)
 *      are incorrectly treated as temp variables
 *
 * WHAT: Tracks where a variable came from in the compilation pipeline
 *
 * HOW: Set during ElixirASTBuilder phase, consulted during transformation and printing
 */
enum VarOrigin {
    /** Variable introduced by a user pattern (e.g., r, g, b in RGB pattern) */
    PatternBinder;

    /** Temporary variable generated for TEnumParameter extraction (g, g1, g2) */
    ExtractionTemp;

    /** Other compiler-synthesized locals */
    Synthesized;

    /** User-defined variable from source code */
    UserDefined;
}

// ============================================================================
// Core AST Definition
// ============================================================================

/**
 * Main AST node enum containing all Elixir language constructs
 */
enum ElixirASTDef {
    // ========================================================================
    // Modules and Structure
    // ========================================================================
    
    /** Elixir module definition with attributes and body */
    EModule(name: String, attributes: Array<EAttribute>, body: Array<ElixirAST>);
    
    /** Defmodule block */
    EDefmodule(name: String, doBlock: ElixirAST);
    
    // ========================================================================
    // Functions
    // ========================================================================
    
    /** Public function definition */
    EDef(name: String, args: Array<EPattern>, guards: Null<ElixirAST>, body: ElixirAST);
    
    /** Private function definition */
    EDefp(name: String, args: Array<EPattern>, guards: Null<ElixirAST>, body: ElixirAST);
    
    /** Macro definition */
    EDefmacro(name: String, args: Array<EPattern>, guards: Null<ElixirAST>, body: ElixirAST);
    
    /** Private macro definition */
    EDefmacrop(name: String, args: Array<EPattern>, guards: Null<ElixirAST>, body: ElixirAST);
    
    // ========================================================================
    // Pattern Matching
    // ========================================================================
    
    /** Case expression with pattern matching */
    ECase(expr: ElixirAST, clauses: Array<ECaseClause>);
    
    /** Cond expression for condition chains */
    ECond(clauses: Array<ECondClause>);
    
    /** Pattern match (=) operator */
    EMatch(pattern: EPattern, expr: ElixirAST);
    
    /** With expression for chained pattern matching */
    EWith(clauses: Array<EWithClause>, doBlock: ElixirAST, elseBlock: Null<ElixirAST>);
    
    // ========================================================================
    // Control Flow
    // ========================================================================
    
    /** If expression */
    EIf(condition: ElixirAST, thenBranch: ElixirAST, elseBranch: Null<ElixirAST>);
    
    /** Unless expression (negative if) */
    EUnless(condition: ElixirAST, body: ElixirAST, elseBranch: Null<ElixirAST>);
    
    /** Try-rescue-catch-after expression */
    ETry(body: ElixirAST, rescue: Array<ERescueClause>, catchClauses: Array<ECatchClause>, 
         afterBlock: Null<ElixirAST>, elseBlock: Null<ElixirAST>);
    
    /** Raise exception */
    ERaise(exception: ElixirAST, attributes: Null<ElixirAST>);
    
    /** Throw expression */
    EThrow(value: ElixirAST);
    
    // ========================================================================
    // Data Structures
    // ========================================================================
    
    /** List literal [] */
    EList(elements: Array<ElixirAST>);
    
    /** Tuple literal {} */
    ETuple(elements: Array<ElixirAST>);
    
    /** Map literal %{} */
    EMap(pairs: Array<EMapPair>);
    
    /** Struct literal %Module{} */
    EStruct(module: String, fields: Array<EStructField>);
    
    /** Struct update %{struct | field: value} */
    EStructUpdate(struct: ElixirAST, fields: Array<EStructField>);
    
    /** Keyword list [key: value] */
    EKeywordList(pairs: Array<EKeywordPair>);
    
    /** Binary/Bitstring <<>> */
    EBitstring(segments: Array<EBinarySegment>);
    
    // ========================================================================
    // Expressions
    // ========================================================================
    
    /** Function call */
    ECall(target: Null<ElixirAST>, funcName: String, args: Array<ElixirAST>);
    
    /** Macro call with do-block (like schema, defmodule, etc.) */
    EMacroCall(macroName: String, args: Array<ElixirAST>, doBlock: ElixirAST);
    
    /** Remote call Module.function() */
    ERemoteCall(module: ElixirAST, funcName: String, args: Array<ElixirAST>);
    
    /** Pipe operator |> */
    EPipe(left: ElixirAST, right: ElixirAST);
    
    /** Binary operator */
    EBinary(op: EBinaryOp, left: ElixirAST, right: ElixirAST);
    
    /** Unary operator */
    EUnary(op: EUnaryOp, expr: ElixirAST);
    
    /** Dot access for maps/structs */
    EField(target: ElixirAST, field: String);
    
    /** Bracket access [] */
    EAccess(target: ElixirAST, key: ElixirAST);
    
    /** Range operator .. or ... */
    ERange(start: ElixirAST, end: ElixirAST, exclusive: Bool);
    
    // ========================================================================
    // Literals
    // ========================================================================
    
    /** Atom literal */
    EAtom(value: ElixirAtom);
    
    /** String literal */
    EString(value: String);
    
    /** Integer literal */
    EInteger(value: Int);
    
    /** Float literal */
    EFloat(value: Float);
    
    /** Boolean literal */
    EBoolean(value: Bool);
    
    /** Nil literal */
    ENil;
    
    /** Charlist literal */
    ECharlist(value: String);
    
    // ========================================================================
    // Variables and Binding
    // ========================================================================
    
    /** Variable reference */
    EVar(name: String);
    
    /** Pin operator ^ */
    EPin(expr: ElixirAST);
    
    /** Underscore pattern _ */
    EUnderscore;
    
    // ========================================================================
    // Comprehensions
    // ========================================================================
    
    /** For comprehension */
    EFor(generators: Array<EGenerator>, filters: Array<ElixirAST>, 
         body: ElixirAST, into: Null<ElixirAST>, uniq: Bool);
    
    // ========================================================================
    // Anonymous Functions
    // ========================================================================
    
    /** Anonymous function fn -> end */
    EFn(clauses: Array<EFnClause>);
    
    /** Capture operator & with optional arity for function references */
    ECapture(expr: ElixirAST, ?arity: Int);
    
    // ========================================================================
    // Module Directives
    // ========================================================================
    
    /** Alias directive */
    EAlias(module: String, as: Null<String>);
    
    /** Import directive */
    EImport(module: String, only: Null<Array<EImportOption>>, except: Null<Array<EImportOption>>);
    
    /** Use macro */
    EUse(module: String, options: Array<ElixirAST>);
    
    /** Require directive */
    ERequire(module: String, as: Null<String>);
    
    // ========================================================================
    // Special Forms
    // ========================================================================
    
    /** Quote expression */
    EQuote(options: Array<ElixirAST>, expr: ElixirAST);
    
    /** Unquote expression */
    EUnquote(expr: ElixirAST);
    
    /** Unquote splicing */
    EUnquoteSplicing(expr: ElixirAST);
    
    /** Receive block for message passing */
    EReceive(clauses: Array<ECaseClause>, after: Null<EAfterClause>);
    
    /** Send message */
    ESend(target: ElixirAST, message: ElixirAST);
    
    // ========================================================================
    // Blocks and Grouping
    // ========================================================================
    
    /** Block of expressions */
    EBlock(expressions: Array<ElixirAST>);
    
    /** Parenthesized expression */
    EParen(expr: ElixirAST);
    
    /** Do-end block */
    EDo(body: Array<ElixirAST>);
    
    // ========================================================================
    // Documentation & Module Attributes
    // ========================================================================
    
    /** Module attribute (e.g., @my_constant "value") */
    EModuleAttribute(name: String, value: ElixirAST);
    
    /** @moduledoc documentation */
    EModuledoc(content: String);
    
    /** @doc documentation */
    EDoc(content: String);
    
    /** @spec type specification */
    ESpec(signature: String);
    
    /** @type type definition */
    ETypeDef(name: String, definition: String);
    
    // ========================================================================
    // Phoenix/Framework Specific (for transformation phase)
    // ========================================================================
    
    /** Sigil (like ~H for HEEx templates) */
    ESigil(type: String, content: String, modifiers: String);
    
    /** Raw Elixir code injection (for __elixir__ calls) */
    ERaw(code: String);
    
    /** Attribute @ (for assigns in templates) */
    EAssign(name: String);
    
    /** Fragment for template composition */
    EFragment(tag: String, attributes: Array<EAttribute>, children: Array<ElixirAST>);
}

// ============================================================================
// Supporting Types
// ============================================================================

/**
 * Pattern types for pattern matching contexts
 */
enum EPattern {
    /** Variable pattern */
    PVar(name: String);
    
    /** Literal pattern */
    PLiteral(value: ElixirAST);
    
    /** Tuple pattern */
    PTuple(elements: Array<EPattern>);
    
    /** List pattern */
    PList(elements: Array<EPattern>);
    
    /** Cons pattern [head | tail] */
    PCons(head: EPattern, tail: EPattern);
    
    /** Map pattern */
    PMap(pairs: Array<{key: ElixirAST, value: EPattern}>);
    
    /** Struct pattern */
    PStruct(module: String, fields: Array<{key: String, value: EPattern}>);
    
    /** Pin pattern ^variable */
    PPin(pattern: EPattern);
    
    /** Underscore/wildcard pattern */
    PWildcard;
    
    /** Alias pattern (var = pattern) */
    PAlias(varName: String, pattern: EPattern);
    
    /** Binary pattern */
    PBinary(segments: Array<PBinarySegment>);
}

/**
 * Case clause for case/receive expressions
 */
typedef ECaseClause = {
    pattern: EPattern,
    ?guard: ElixirAST,
    body: ElixirAST
}

/**
 * Cond clause for cond expressions
 */
typedef ECondClause = {
    condition: ElixirAST,
    body: ElixirAST
}

/**
 * With clause for with expressions
 */
typedef EWithClause = {
    pattern: EPattern,
    expr: ElixirAST
}

/**
 * Function clause for anonymous functions
 */
typedef EFnClause = {
    args: Array<EPattern>,
    ?guard: ElixirAST,
    body: ElixirAST
}

/**
 * Rescue clause for try expressions
 */
typedef ERescueClause = {
    pattern: EPattern,
    ?varName: String,
    body: ElixirAST
}

/**
 * Catch clause for try expressions
 */
typedef ECatchClause = {
    kind: ECatchKind,
    pattern: EPattern,
    body: ElixirAST
}

/**
 * After clause for receive expressions
 */
typedef EAfterClause = {
    timeout: ElixirAST,
    body: ElixirAST
}

/**
 * Generator for comprehensions
 */
typedef EGenerator = {
    pattern: EPattern,
    expr: ElixirAST
}

/**
 * Module attribute
 */
typedef EAttribute = {
    name: String,
    value: ElixirAST
}

/**
 * Map pair
 */
typedef EMapPair = {
    key: ElixirAST,
    value: ElixirAST
}

/**
 * Struct field
 */
typedef EStructField = {
    key: String,
    value: ElixirAST
}

/**
 * Keyword pair
 */
typedef EKeywordPair = {
    key: String,
    value: ElixirAST
}

/**
 * Binary segment for binary patterns
 */
typedef EBinarySegment = {
    value: ElixirAST,
    ?size: ElixirAST,
    ?type: String,
    ?modifiers: Array<String>
}

/**
 * Binary pattern segment
 */
typedef PBinarySegment = {
    pattern: EPattern,
    ?size: ElixirAST,
    ?type: String,
    ?modifiers: Array<String>
}

/**
 * Import option for import directive
 */
typedef EImportOption = {
    name: String,
    arity: Int
}

/**
 * Guard branch for guard condition flattening
 * Represents a single guard condition with its associated body
 */
typedef GuardBranch = {
    pattern: EPattern,          // The pattern being matched (e.g., RGB(r, g, b))
    guard: ElixirAST,           // The guard condition (e.g., r > 200)
    body: ElixirAST,            // The expression body when guard matches
    ?originalIfElse: ElixirAST, // Optional: Original if-else for debugging
    ?depth: Int                 // Optional: Nesting depth for debugging
}

/**
 * Validation result for guard condition grouping
 * Used by GuardGroupValidator to report groupability status
 */
typedef ValidationResult = {
    canGroup: Bool,             // Whether conditions can be grouped in a cond
    reason: String,             // Explanation of decision
    groupKey: String,           // Pattern signature for grouping (e.g., "RGB(r,g,b)")
    patterns: Array<String>     // All patterns found in this group
}

/**
 * Binary operators
 */
enum EBinaryOp {
    // Arithmetic
    Add;        // +
    Subtract;   // -
    Multiply;   // *
    Divide;     // /
    Remainder;  // rem
    Power;      // **
    
    // Comparison
    Equal;      // ==
    NotEqual;   // !=
    StrictEqual;    // ===
    StrictNotEqual; // !==
    Less;       // <
    Greater;    // >
    LessEqual;  // <=
    GreaterEqual; // >=
    
    // Logical
    And;        // and
    Or;         // or
    AndAlso;    // &&
    OrElse;     // ||
    
    // Binary
    BitwiseAnd; // &&&
    BitwiseOr;  // |||
    BitwiseXor; // ^^^
    ShiftLeft;  // <<<
    ShiftRight; // >>>
    
    // List
    Concat;     // ++
    ListSubtract;   // --
    
    // String
    StringConcat;   // <>
    
    // Membership
    In;         // in
    
    // Other
    Match;      // =
    Pipe;       // |>
    TypeCheck;  // ::
    When;       // when (guards)
}

/**
 * Unary operators
 */
enum EUnaryOp {
    Not;        // not
    Negate;     // -
    Positive;   // +
    BitwiseNot; // ~~~
    Bang;       // !
}

/**
 * Catch kinds for try-catch
 */
enum ECatchKind {
    Error;
    Exit;
    Throw;
    Any;
}

// ============================================================================
// Context Types
// ============================================================================

/**
 * Phoenix-specific context for LiveView, Router, etc.
 */
enum PhoenixContext {
    LiveView;
    LiveComponent;
    Controller;
    Router;
    Channel;
    Endpoint;
    None;
}

/**
 * Ecto-specific context for schemas, queries, etc.
 */
enum EctoContext {
    Schema;
    Query;
    Changeset;
    Repo;
    Migration;
    None;
}

/**
 * Access pattern hints for optimization
 */
enum AccessPattern {
    Sequential;
    Random;
    WriteOnly;
    ReadOnly;
    ReadWrite;
}

// ============================================================================
// Main AST Type with Metadata
// ============================================================================

/**
 * AST node with metadata for context and optimization
 */
typedef ElixirAST = {
    /** The actual AST node */
    def: ElixirASTDef,
    
    /** Rich metadata for transformation and optimization */
    metadata: ElixirMetadata,
    
    /** Source position for error reporting */
    ?pos: Position
}

/**
 * Comprehensive metadata structure for AST nodes
 */
/**
 * Loop context information for metadata preservation
 * 
 * WHY THIS EXISTS: When Haxe's analyzer optimization is enabled (-D analyzer-optimize),
 * it replaces loop variables with literal values during compilation. For example,
 * `"Cell (" + i + "," + j + ")"` becomes `"Cell (0,1)"` before our compiler sees it.
 * This structure preserves the original loop context so we can restore variable names.
 * 
 * WHAT IT RELATES TO:
 * - Created in: ElixirASTBuilder.hx when processing TFor nodes
 * - Attached to: ElixirAST nodes via metadata field
 * - Consumed by: LoopVariableRestorer.hx to restore variable names in strings
 * 
 * HOW IT WORKS: Each loop creates a context that travels with the AST through all
 * transformation passes, allowing late-stage restoration of variable names.
 */
typedef LoopContext = {
    var variableName: String;         // Original loop variable name from Haxe source (i, j, k)
    var rangeMin: Int;               // Start of range (0 in "0...5") - used to identify which literals to replace
    var rangeMax: Int;               // End of range (4 in "0...5") - helps detect loop-generated values
    var depth: Int;                  // Nesting level (0=outermost, 1=first nested) - handles nested loops
    var iteratorExpr: String;        // Original iterator expression - for debugging and complex cases
}

typedef ElixirMetadata = {
    // Source Information
    ?sourceExpr: haxe.macro.Type.TypedExpr,        // Original Haxe expression
    ?sourceLine: Int,               // Line number in Haxe source
    ?sourceFile: String,            // Source file path
    ?sourceVarId: Int,             // Original TVar.id for variable resolution
    
    // Type Information
    ?type: Type,                   // Haxe type information
    ?elixirType: String,           // Inferred Elixir type
    
    // Semantic Information
    ?purity: Bool,                 // Is expression pure?
    ?tailPosition: Bool,           // Is in tail position?
    ?async: Bool,                  // Is async operation?
    
    // Transformation Hints
    ?requiresReturn: Bool,         // Needs explicit return value
    ?requiresTempVar: Bool,        // Needs temporary variable
    ?inPipeline: Bool,            // Part of pipe chain
    ?inComprehension: Bool,       // Inside for comprehension
    ?inGuard: Bool,               // Inside guard clause
    ?redundantEnumExtraction: Bool, // Marks redundant enum extraction for removal
    
    // Array Comprehension Reconstruction
    ?isUnrolledComprehension: Bool, // Block contains unrolled array comprehension
    ?comprehensionElements: Int,    // Number of elements in unrolled comprehension
    
    // Variable Resolution
    ?varIdToName: Map<Int, String>, // Clause-local variable renaming mappings
    ?requiresIdiomaticTransform: Bool,  // Enum needs idiomatic compilation
    
    // Inheritance Information
    ?parentModule: String,         // Parent class module name for inheritance
    ?isException: Bool,            // Whether this class extends haxe.Exception
    ?idiomaticEnumType: String,   // Name of the idiomatic enum type
    ?hasEnumBindingPlan: Bool,    // M0.5: Case has proper enum parameter mappings
    ?enumBindingPlanId: String,   // Unique ID linking to EnumBindingPlan in context
    ?parentHasBindingPlan: Bool,  // Propagated flag from parent ECase

    // Variable Origin Tracking (January 2025)
    ?varOrigin: VarOrigin,         // Where this variable came from
    ?varId: Int,                   // Unique Haxe TVar ID for identity tracking
    ?tempToBinderMap: Map<Int, Int>, // Maps extraction temp var IDs to pattern binder IDs
    ?isUnused: Bool,               // Whether this variable is actually used in the code

    // Phoenix/Framework Specific
    ?phoenixContext: PhoenixContext,  // LiveView, Router, etc.
    ?ectoContext: EctoContext,        // Schema, Query, etc.
    
    // Ecto-specific hints
    ?ectoPinnedNilGuard: Bool,     // Marks Kernel.is_nil(^var) guard injected for Ecto != semantics
    
    // Annotation-based Module Types
    ?isEndpoint: Bool,            // @:endpoint Phoenix.Endpoint
    ?isLiveView: Bool,            // @:liveview Phoenix.LiveView
    ?isSchema: Bool,              // @:schema Ecto.Schema
    ?isRepo: Bool,                // @:repo Ecto.Repo
    ?isSupervisor: Bool,          // @:supervisor OTP Supervisor
    ?isKeep: Bool,                // @:keep - Prevent dead code elimination
    ?isPostgrexTypes: Bool,       // @:postgrexTypes Postgrex precompiled types module (sugar)
    ?isDbTypes: Bool,             // @:dbTypes generic DB types module
    ?dbAdapter: String,           // Adapter name (e.g., "postgrex")
    ?extensions: Array<String>,   // Optional extensions for types define
    ?isApplication: Bool,         // @:application OTP Application
    ?isGenServer: Bool,           // @:genserver GenServer behavior
    ?isRouter: Bool,              // @:router Phoenix.Router
    ?isController: Bool,          // @:controller Phoenix.Controller
    ?isPresence: Bool,            // @:presence Phoenix.Presence
    ?isPhoenixWeb: Bool,          // @:phoenixWeb AppNameWeb module with macros
    ?isExunit: Bool,              // @:exunit ExUnit.Case test module
    ?isTest: Bool,                // @:test on a method in ExUnit module
    ?isSetup: Bool,               // @:setup on a method in ExUnit module
    ?isSetupAll: Bool,            // @:setupAll on a method in ExUnit module
    ?isTeardown: Bool,            // @:teardown on a method in ExUnit module
    ?isTeardownAll: Bool,         // @:teardownAll on a method in ExUnit module
    ?describeBlock: String,       // @:describe block name for grouping tests
    ?isAsync: Bool,               // @:async for async ExUnit tests
    ?testTags: Array<String>,     // @:tag values for test tagging
    ?appName: String,             // Application name for OTP/Phoenix
    ?tableName: String,           // Table name for Ecto schemas
    ?jsonModule: String,          // JSON library module name for Postgrex.Types.define
    ?poolSize: Int,               // Connection pool size for Repo
    ?needsPostgrexTypes: Bool,    // Whether to generate companion PostgrexTypes module

    // HEEx/HXX annotation (experimental; analysis only)
    ?heexFragments: Array<HeexFragmentMeta>, // Parsed fragments from ~H content for analysis (not used for emission)

    // Schema metadata (for @:schema)
    // haxeFqcn: Fully Qualified Class Name of the original Haxe type that produced this module.
    // Why string: metadata travels outside macro-only phases; we resolve it later when needed.
    // Example: "server.schemas.Todo". Transformers can use this to locate schema info deterministically.
    ?haxeFqcn: String,
    // schemaFields: pre-extracted field list from the Haxe class, used by transformers to emit Ecto fields.
    // Each entry contains the original Haxe field name and a normalized type hint (String, Int, Bool, Date, etc.).
    // Transformers apply name conversion (snake_case) and map types to Ecto atoms (e.g., Int -> :integer).
    ?schemaFields: Array<{ name: String, type: String }>,
    // Whether the original Haxe class had @:timestamps annotation
    ?hasTimestamps: Bool,
    
    // Loop Expression Preservation (Critical for idiomatic Elixir generation)
    // WHY: Haxe's optimizer replaces loop variables with literals BEFORE our compiler runs
    // WHAT: These fields preserve loop information from the original TypedExpr
    // RELATES TO: Loop variable substitution bug (see LOOP_VARIABLE_FIX_PRD.md)
    
    ?originalLoopExpression: String,  // Captures loop body expression before optimization ("i * 2 + 1" not "0 * 2 + 1")
                                     // USED BY: String reconstruction in transformer passes
    
    ?loopVariableName: String,        // Preserves original variable name ("i", "j", "k")
                                     // USED BY: Legacy compatibility with existing restorer code
    
    ?loopContextStack: Array<LoopContext>, // Stack of all enclosing loop contexts for nested loops
                                          // WHY: Nested loops need access to all parent loop variables
                                          // USED BY: LoopVariableRestorer to handle multi-level nesting
    
    ?isWithinLoop: Bool,              // Marks nodes that are inside a loop body
                                     // WHY: Only restore variables in loop contexts, not everywhere
                                     // USED BY: Transformation passes to enable/disable restoration
    
    ?parentLoopVar: String,           // Direct parent loop variable for simple nested detection
                                     // WHY: Quick check for immediate parent without full stack traversal
                                     // USED BY: Optimization passes for common two-level nesting
    
    // Optimization Hints
    ?canInline: Bool,             // Can be inlined
    ?keepInlineInAssignment: Bool, // Keep inline when assigned (e.g., null coalescing)
    ?isConstant: Bool,            // Compile-time constant
    ?accessPattern: AccessPattern, // How value is accessed
    ?sideEffects: Bool,           // Has side effects
    
    // User Annotations
    ?annotations: Array<String>,   // @:native, @:inline, etc.
    ?documentation: String,        // Doc comments
    
    // Variable Context
    ?variableScope: String,        // Current scope identifier
    ?capturedVars: Array<String>, // Variables captured by closure
    
    // Error Handling
    ?canRaise: Bool,              // Can raise exceptions
    ?errorContext: String,        // Error handling context
    
    // Static Extern Method Handling (Added 2025-09-05)
    ?isStaticExternMethod: Bool,  // Marks a static method on an extern class
    ?nativeModule: String,        // The full module path from @:native annotation
    ?methodName: String,          // The method name being called
    
    // Function Reference Handling (Added 2025-09-05)
    ?isFunctionReference: Bool,   // Marks a function being passed as a reference
    ?arity: Int,                  // Function arity for capture operator
    
    // Fluent API Detection (Added 2025-09-10)
    ?isFluentMethod: Bool,         // Method returns 'this' for chaining
    ?mutatesFields: Array<String>, // Fields mutated in this method (e.g., ["columns", "indexes"])
    ?fieldMutations: Array<{field: String, expr: ElixirAST}>, // Field mutation operations
    ?returnsThis: Bool,           // Method returns 'this' for fluent chaining

    // Dead Code Elimination (Added January 2025)
    ?unusedPrivateFunctions: Array<String>,  // List of unused private function names in the module
    ?unusedPrivateFunctionsWithArity: Array<{name: String, arity: Int}>,  // List with arities for @compile directive
    
    // Guard Condition Grouping (Added January 2025)
    ?patternKey: String,          // Normalized pattern signature for grouping (e.g., "tuple:rgb:3")
    ?boundVars: Array<String>,    // Variables bound by this pattern (e.g., ["r", "g", "b"])
    ?hasGuard: Bool,              // Whether this clause has a guard condition

    // HEEx typed AST (Builder-attached; analysis only)
    // WHAT: Typed EFragment/EAssign-based AST parsed from ~H content.
    // WHY: Enable attribute-level static analysis (e.g., assigns lints) without relying on
    //      brittle string scanning. Keeps final emission as ~H while providing structured shape.
    // HOW: ElixirASTBuilder parses ESigil("H", ...) content using HeexFragmentBuilder and
    //      attaches the resulting top-level nodes here. Printer ignores this; transformers/linters
    //      may prefer it over heexFragments when present.
    ?heexAST: Array<ElixirAST>
}

/** Minimal HEEx fragment metadata for analysis (not used for emission) */
typedef HeexFragmentMeta = {
    tag: String,
    attributes: Array<HeexAttributeMeta>,
    childrenText: String
}

typedef HeexAttributeMeta = {
    name: String,
    valueExpr: String,
    isDynamic: Bool
}

// ============================================================================
// Utility Functions (to be implemented by users of this AST)
// ============================================================================

/**
 * Create an empty metadata object
 */
inline function emptyMetadata(): ElixirMetadata {
    return {};
}

/**
 * Create an AST node with empty metadata
 */
inline function makeAST(def: ElixirASTDef, ?pos: Position): ElixirAST {
    return {
        def: def,
        metadata: emptyMetadata(),
        pos: pos
    };
}

/**
 * Create an AST node with specific metadata
 */
inline function makeASTWithMeta(def: ElixirASTDef, meta: ElixirMetadata, ?pos: Position): ElixirAST {
    return {
        def: def,
        metadata: meta,
        pos: pos
    };
}

// ============================================================================
// Shared Transformation Utilities
// ============================================================================

/**
 * Applies idiomatic Elixir transformations to enum constructor calls
 * 
 * WHY: Haxe enums naturally compile to tuples {:constructor, args...} but many
 * Elixir patterns expect different forms (bare atoms, unwrapped values, OTP tuples).
 * This shared utility ensures consistent transformation across the AST pipeline.
 * 
 * WHAT: Detects patterns by structure and arity, transforming enum constructors to:
 * - 0 args: Bare atom (e.g., :telemetry for standalone markers)
 * - 1 arg: Unwrapped value (e.g., "MyModule" for module references)
 * - 2 args with keyword list: OTP tuple {Module, config} for child specs
 * 
 * HOW: Convention-based detection using argument count and type inspection.
 * No hardcoded enum names - works for any enum marked with @:elixirIdiomatic.
 * 
 * @param node The AST node to potentially transform
 * @return Transformed node or original if no transformation applies
 */
function applyIdiomaticEnumTransformation(node: ElixirAST): ElixirAST {
    // Only transform tuples that are enum constructors
    var elements = switch(node.def) {
        case ETuple(els): els;
        default: return node; // Not a tuple, no transformation
    };
    
    if (elements.length == 0) return node;
    
    // First element should be the constructor tag (atom)
    var tag = switch(elements[0].def) {
        case EAtom(name): name; // name is now ElixirAtom
        default: return node; // Not an enum constructor pattern
    };
    
    // Extract constructor arguments (everything after the tag)
    var args = elements.slice(1);
    var argCount = args.length;
    
    // Convention-based transformation based on arity
    switch(argCount) {
        case 0:
            // Zero arguments → bare atom
            // Example: Telemetry() → :telemetry
            return makeASTWithMeta(EAtom(tag), node.metadata, node.pos);
            
        case 1:
            // Single argument → unwrap the value
            // Special handling for module names (strings that look like modules)
            var unwrapped = switch(args[0].def) {
                case EString(s) if (isModuleName(s)):
                    // Module names should be bare identifiers, not strings
                    makeAST(EVar(s), args[0].pos);
                default: 
                    args[0];
            };
            return makeASTWithMeta(unwrapped.def, node.metadata, node.pos);
            
        case 2:
            // Two arguments → check for OTP child spec pattern (Module, config)
            // Transform ModuleWithConfig("Phoenix.PubSub", config) → {Phoenix.PubSub, config}
            
            // First arg should be a module name
            var moduleArg = switch(args[0].def) {
                case EString(s) if (isModuleName(s)):
                    // Convert string module name to bare module reference
                    makeAST(EVar(s), args[0].pos);
                default:
                    args[0];
            };
            
            // Second arg should be config - transform to keyword list if needed
            var configArg = switch(args[1].def) {
                case EKeywordList(_): 
                    // Already a keyword list
                    args[1];
                    
                case EList(elements):
                    // Check if it's a list of {key: "...", value: ...} structures that should be keyword pairs
                    var keywordPairs: Array<EKeywordPair> = [];
                    var isKeyValueConfig = true;
                    
                    for (elem in elements) {
                        switch(elem.def) {
                            case EMap(pairs):
                                // Look for {key: "name", value: data} pattern
                                var keyName: String = null;
                                var keyValue: ElixirAST = null;
                                
                                for (pair in pairs) {
                                    switch(pair.key.def) {
                                        case EAtom(atom) if (atom == "key"):
                                            // Extract the key name from the value
                                            switch(pair.value.def) {
                                                case EString(s): keyName = s;
                                                default: isKeyValueConfig = false;
                                            }
                                        case EAtom(atom) if (atom == "value"):
                                            // This is the actual value
                                            keyValue = pair.value;
                                        default:
                                            // Not the pattern we're looking for
                                            isKeyValueConfig = false;
                                    }
                                }
                                
                                if (keyName != null && keyValue != null) {
                                    // For certain keys, convert strings to appropriate references
                                    var finalValue = if (keyName == "name") {
                                        switch(keyValue.def) {
                                            case EString(s) if (isModuleName(s)):
                                                // Convert module name string to module reference (unquoted)
                                                // Use EVar for module references like TodoApp.PubSub
                                                makeAST(EVar(s), keyValue.pos);
                                            default:
                                                keyValue;
                                        }
                                    } else if (keyName == "keys") {
                                        // Registry keys option should be an atom (:unique or :duplicate)
                                        switch(keyValue.def) {
                                            case EString(s) if (s == "unique" || s == "duplicate"):
                                                // Convert to atom for Registry configuration
                                                makeAST(EAtom(ElixirAtom.raw(s)), keyValue.pos);
                                            default:
                                                keyValue;
                                        }
                                    } else {
                                        keyValue;
                                    };
                                    keywordPairs.push({key: keyName, value: finalValue});
                                } else {
                                    isKeyValueConfig = false;
                                }
                                
                            default:
                                isKeyValueConfig = false;
                        }
                    }
                    
                    if (isKeyValueConfig && keywordPairs.length > 0) {
                        // Convert to keyword list
                        makeAST(EKeywordList(keywordPairs), args[1].pos);
                    } else {
                        args[1];
                    }
                    
                default:
                    args[1];
            };
            
            // For OTP child specs, return a 2-tuple with module and config
            return makeASTWithMeta(
                ETuple([moduleArg, configArg]),
                node.metadata,
                node.pos
            );
    }
    
    // No convention matched, return original
    return node;
}

/**
 * Checks if a string looks like an Elixir module name
 * 
 * @param s String to check
 * @return True if it matches module naming pattern
 */
function isModuleName(s: String): Bool {
    // Module names start with uppercase and can contain dots
    // Examples: "Phoenix.PubSub", "MyApp.Repo", "Task.Supervisor"
    if (s.length == 0) return false;
    
    var firstChar = s.charAt(0);
    if (firstChar != firstChar.toUpperCase()) return false;
    
    // Check if it's a valid module name pattern
    // Allow dots for nested modules, alphanumeric and underscores
    for (i in 0...s.length) {
        var char = s.charAt(i);
        if (!isAlphaNumeric(char) && char != "." && char != "_") {
            return false;
        }
    }
    
    return true;
}

/**
 * Helper to check if a character is alphanumeric
 */
function isAlphaNumeric(char: String): Bool {
    var code = char.charCodeAt(0);
    return (code >= 48 && code <= 57) ||  // 0-9
           (code >= 65 && code <= 90) ||  // A-Z
           (code >= 97 && code <= 122);   // a-z
}

#end
</file>

<file path="src/reflaxe/elixir/ElixirCompiler.hx">
package reflaxe.elixir;

#if (macro || reflaxe_runtime)

import haxe.macro.Context;
import haxe.macro.Type;
import haxe.macro.Type.TConstant;
import haxe.macro.Type.AbstractType;
import haxe.macro.Type.DefType;
import haxe.macro.Type.MethodKind;
import haxe.macro.Expr.Binop;
import haxe.macro.Expr.Unop;
import haxe.macro.Expr;
import haxe.macro.Expr.Constant;

import reflaxe.GenericCompiler;
import reflaxe.compiler.TargetCodeInjection;
import reflaxe.data.ClassFuncData;
import reflaxe.data.ClassVarData;  
import reflaxe.data.EnumOptionData;
import reflaxe.output.DataAndFileInfo;
import reflaxe.output.StringOrBytes;
import reflaxe.elixir.ElixirTyper;
import reflaxe.elixir.PhoenixMapper;
import reflaxe.elixir.SourceMapWriter;
import reflaxe.elixir.ast.ElixirAST.ElixirASTDef;
import reflaxe.elixir.ast.ElixirAST.EPattern;
import reflaxe.elixir.ast.ElixirAST.ElixirMetadata;
import reflaxe.elixir.ast.naming.ElixirAtom;
import reflaxe.elixir.CompilationContext;

using StringTools;
using reflaxe.helpers.NameMetaHelper;
using reflaxe.helpers.TypedExprHelper;
using reflaxe.helpers.TypeHelper;
using reflaxe.helpers.ModuleTypeHelper;

/**
 * Internal helper result for framework-aware naming.
 *
 * Used by ElixirCompiler to keep module naming and file placement decisions
 * in sync for annotations like @:application without leaking implementation
 * details into other modules.
 */
typedef FrameworkNamingResult = {
    var moduleName: String;
    var modulePack: Array<String>;
    var outputPath: Null<String>;
}

/**
 * Reflaxe.Elixir compiler for generating idiomatic Elixir code from Haxe.
 * 
 * This compiler extends GenericCompiler to provide comprehensive Haxe-to-Elixir transpilation
 * with support for Phoenix applications, OTP patterns, and gradual typing.
 * 
 * Key Features:
 * - Phoenix LiveView compilation (@:liveview annotation)
 * - Ecto schema generation (@:schema annotation) 
 * - Router DSL compilation (@:router annotation)
 * - Pattern matching and guard compilation
 * - Array method optimization (transforms to Enum functions)
 * - While loop optimization (detects and converts for-in patterns)
 * - Protocol and behavior support
 * - Type-safe repository operations
 * 
 * The compiler performs macro-time transpilation, transforming Haxe's TypedExpr AST
 * into idiomatic Elixir code. It handles desugaring reversal - detecting patterns
 * that Haxe has desugared and converting them back to idiomatic target constructs.
 * 
 * ARCHITECTURE: Uses GenericCompiler<ElixirAST> following C#'s proven pattern.
 * All compilation methods return AST nodes, which are transformed and printed
 * to strings via ElixirOutputIterator at the end of compilation.
 * 
 * @see docs/05-architecture/GENERICCOMPILER_MIGRATION_PRD.md Migration rationale
 * @see docs/05-architecture/ARCHITECTURE.md Complete architectural overview
 * @see docs/03-compiler-development/TESTING.md Testing methodology and patterns
 */
class ElixirCompiler extends GenericCompiler<
    reflaxe.elixir.ast.ElixirAST,  // CompiledClassType
    reflaxe.elixir.ast.ElixirAST,  // CompiledEnumType
    reflaxe.elixir.ast.ElixirAST,  // CompiledExpressionType
    reflaxe.elixir.ast.ElixirAST,  // CompiledTypedefType
    reflaxe.elixir.ast.ElixirAST   // CompiledAbstractType
> {

    // Global module registry for cross-file qualification decisions
    static var globalModuleRegistry: Map<String, Bool> = new Map();
    public static function registerModule(name: String): Void {
        if (name != null && name.length > 0) globalModuleRegistry.set(name, true);
    }
    public static function isModuleKnown(name: String): Bool {
        return name != null && globalModuleRegistry.exists(name);
    }

    // Static instance reference for helpers to access the compiler
    public static var instance: ElixirCompiler;
    
    // File extension for generated Elixir files
    public var fileExtension: String = ".ex";
    
    // Output directory for generated files (dynamically set by Reflaxe)
    public var outputDirectory: String = "lib/";
    
    // Type mapping system for enhanced enum compilation
    private var typer: reflaxe.elixir.ElixirTyper;
    
    // Context tracking for variable substitution
    public var isInLoopContext: Bool = false;
    
    // Source mapping support for debugging and LLM workflows
    public var currentSourceMapWriter: Null<SourceMapWriter> = null;
    public var sourceMapOutputEnabled: Bool = false;
    public var pendingSourceMapWriters: Array<SourceMapWriter> = [];
    
    // Parameter mapping system for abstract type implementation methods
    public var currentFunctionParameterMap: Map<String, String> = new Map();
    
    // Context-aware pattern usage tracking for enum parameter optimization
    // Tracks which pattern variables are actually used in switch case bodies
    // to prevent generating orphaned enum parameter extractions
    public var patternUsageContext: Null<Map<String, Bool>> = null;
    
    // Return context tracking for case expression assignment
    // When true, indicates we're compiling a return expression and case results
    // need to be assigned to temp_result for proper value capture in Elixir
    public var returnContext: Bool = false;

    
    // Map for tracking variable renames to ensure consistency between declaration and usage
    
    // Track whether we're compiling in a statement context (for mutable operations)
    // When true, array.push(item) generates reassignment: array = array ++ [item]
    public var isStatementContext: Bool = false;
    // Critical for resolving _g variable collisions in desugared loops
    public var variableRenameMap: Null<Map<String, String>> = null;
    
    // Track inline function context across multiple expressions in a block
    // Maps inline variable names (like "struct") to their assigned values (like "struct.buf")
    public var inlineContextMap: Map<String, String> = new Map<String, String>();
    private var isCompilingAbstractMethod: Bool = false;
    public var isCompilingCaseArm: Bool = false;
    
    // Track when we're inside enum parameter extraction to prevent incorrect variable mappings
    public var isInEnumExtraction: Bool = false;
    
    // Track enum extraction variables with their indices to handle multiple parameters correctly
    
    // Track loop variable context to distinguish between counter and limit variables
    public var loopCounterVar: String = null;  // Current loop counter variable name
    public var loopLimitVar: String = null;    // Current loop limit variable name
    public var isInLoopCondition: Bool = false; // Flag when compiling loop conditions
    public var enumExtractionVars: Null<Array<{index: Int, varName: String}>> = null;
    public var currentEnumExtractionIndex: Int = 0;
    
    /**
     * Current switch case body being compiled
     * 
     * WHY: Used by EnumIntrospectionCompiler to perform AST analysis of case bodies
     *      to detect orphaned enum parameter extractions. This prevents generating
     *      unused 'g = elem(spec, N)' assignments for parameters that are never referenced.
     * 
     * WHAT: Contains the TypedExpr of the case body currently being processed by the compiler.
     *       Set when entering switch case compilation, cleared when exiting.
     * 
     * HOW: PatternMatchingCompiler sets this field when compiling each case body,
     *      allowing EnumIntrospectionCompiler to analyze whether extracted parameters
     *      are actually used in the subsequent case logic.
     * 
     * EDGE CASES: Only valid during switch case compilation, null otherwise
     * 
     * ARCHITECTURAL BENEFIT: Provides AST-based orphaned parameter detection without
     *                        hardcoding specific enum names, making the solution general
     *                        and maintainable for any enum type.
     */
    public var currentSwitchCaseBody: Null<TypedExpr> = null;
    
    // Current class context for app name resolution and other class-specific operations
    public var currentClassType: Null<ClassType> = null;
    
    // Track instance variable names for LiveView classes to generate socket.assigns references
    
    /**
     * STATE THREADING MODE
     * 
     * WHY: Transform mutable field assignments in Haxe to immutable struct updates in Elixir
     * WHAT: Track when we're compiling a mutating method that needs state threading
     * HOW: When enabled, field assignments generate struct updates that are threaded through
     */
    public var stateThreadingEnabled: Bool = false;
    // State threading info removed - handled by AST transformer
    
    /**
     * GLOBAL STRUCT METHOD COMPILATION
     * 
     * WHY: Fix JsonPrinter _this issue - parameter mapping gets lost in nested contexts
     * WHAT: Track if we're compiling ANY struct method globally
     * HOW: Set flag when compiling struct methods, use global mapping that persists through all nested compilation
     */
    public var isCompilingStructMethod: Bool = false;
    public var globalStructParameterMap: Map<String, String> = new Map();
    
    // Track temporary variables consumed by array ternary optimization
    // Maps temp_array names to their replacement direct assignments
    public var consumedTempVariables: Null<Map<String, String>> = null;
    
    /**
     * PRESENCE MODULE CONTEXT
     * 
     * WHY: Phoenix.Presence modules have injected functions that require self() as first argument
     * WHAT: Track when we're compiling inside a @:presence module
     * HOW: Set flag when compiling classes with @:presence metadata, use in AST builder for method calls
     */
    public var isInPresenceModule: Bool = false;
    
    /**
     * Module dependency tracking
     * 
     * WHY: When generating scripts with bootstrap code (static main()), we need to
     *      ensure dependent modules are loaded in the correct order. Elixir doesn't
     *      automatically handle module dependencies like some languages.
     * 
     * WHAT: Tracks which modules each module depends on (via remote calls).
     *       Key = module name being compiled, Value = set of modules it depends on
     * 
     * HOW: Populated during AST building when we generate ERemoteCall nodes.
     *      Used by output iterator to generate a bootstrap script or combine modules.
     */
    public var moduleDependencies: Map<String, Map<String, Bool>> = new Map();
    
    /**
     * Current module being compiled
     * Used to track dependencies for the current compilation unit
     */
    public var currentCompiledModule: String = null;
    
    /**
     * Track modules that have bootstrap code (static main())
     * These modules need special handling for script execution
     */
    public var modulesWithBootstrap: Array<String> = [];
    
    /**
     * Track module output file paths for require generation
     * Maps module name -> relative file path from output directory
     */
    public var moduleOutputPaths: Map<String, String> = new Map();
    
    /**
     * Track module packages for proper path resolution
     * Maps module name -> package array (e.g., "Log" -> ["haxe"])
     */
    public var modulePackages: Map<String, Array<String>> = new Map();

    /**
     * Map module name -> BaseType for synthetic outputs (e.g., bootstrap files)
     * WHY: OutputManager requires a BaseType for each DataAndFileInfo; we use the module's
     *      BaseType combined with overrideFileName to write custom files.
     */
    public var moduleBaseTypes: Map<String, BaseType> = new Map();
    
    /**
     * Constructor - Initialize the compiler with type mapping and pattern matching systems
     */
    public function new() {
        super();
        instance = this;  // Set static instance reference
        this.typer = new reflaxe.elixir.ElixirTyper();

        // Enable source mapping if requested
        this.sourceMapOutputEnabled = Context.defined("source_map_enabled") || Context.defined("source-map") || Context.defined("debug");

        // Initialize the BehaviorTransformer system
        // This replaces hardcoded behavior logic with a pluggable architecture
        reflaxe.elixir.behaviors.BehaviorTransformer.initialize();
        reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer = new reflaxe.elixir.behaviors.BehaviorTransformer();
        
        // Preprocessors are now configured in CompilerInit.hx to ensure they aren't overridden
        // The configuration was moved because options passed to ReflectCompiler.AddCompiler
        // override anything set in the constructor
    }

    /**
     * Macro-phase type filter: ensure @:repo externs are scheduled for normal compilation.
     *
     * WHAT
     * - Override BaseCompiler.filterTypes to guarantee extern classes annotated with @:repo
     *   (and related @:postgrexTypes/@:dbTypes) are included in the module list regardless of
     *   usage-driven reachability.
     *
     * WHY
     * - Repo modules must exist at runtime even if not directly referenced by user code.
     *   Emitting them via extra-file helpers creates drift; scheduling for normal compilation
     *   preserves the AST pipeline (repoTransformPass) and deterministic file paths.
     *
     * HOW
     * - Start from the Haxe-provided moduleTypes, append any additional modules discovered
     *   via Context.getTypes() whose classes carry @:repo/@:postgrexTypes/@:dbTypes metadata
     *   but were omitted (e.g., due to DCE). Deduplicate by ModuleType.getPath().
     */
    public override function filterTypes(moduleTypes: Array<haxe.macro.Type.ModuleType>): Array<haxe.macro.Type.ModuleType> {
        #if eval
        var result = moduleTypes != null ? moduleTypes.copy() : [];
        var seen = new Map<String, Bool>();
        for (mt in result) {
            var p = mt.getPath();
            if (p != null) seen.set(p, true);
        }

        // Debug: detect any @:repo classes already present
        try {
            for (mt in result) {
                switch (mt) {
                    case TClassDecl(clsRef):
                        var cls = clsRef.get();
                        if (cls.meta != null && cls.meta.has(":repo")) {
                            #if debug_repo
                            Sys.println('[RepoEnumerator/filterTypes] found @:repo class in moduleTypes: ' + cls.module + '.' + cls.name);
                            #end
                        }
                    case _:
                }
            }
        } catch (_:Dynamic) {}

        // Append force-typed repos discovered in macro phase
        try {
            var mods = reflaxe.elixir.macros.RepoDiscovery.getDiscovered();
            if (mods != null) {
                for (mod in mods) {
                    try {
                        var t = haxe.macro.Context.getType(mod);
                        if (t != null) {
                            var mt = t.toModuleType();
                            if (mt != null) {
                                var pth = mt.getPath();
                                if (pth != null && !seen.exists(pth)) {
                                    result.push(mt);
                                    seen.set(pth, true);
                                }
                            }
                        }
                    } catch (_:Dynamic) {}
                }
            }
        } catch (_:Dynamic) {}

        return result;
        #else
        return moduleTypes;
        #end
    }

    // Note: Directory scanning moved to RepoDiscovery (macro phase)
    
    /**
     * Override shouldGenerateClass to enforce strict std emission policy
     *
     * WHY: Prevent generation of Haxe std extern implementation modules and
     *      macro-time/compiler-time dependencies (e.g., _Any.Any_Impl_, _EnumValue.EnumValue_Impl_,
     *      haxe.iterators.ArrayIterator, haxe._call_stack.CallStack_Impl_, StringBuf, Type, ValueType)
     *      which pollute snapshot outputs and are not required at runtime for idiomatic Elixir.
     * WHAT: Suppress generation for internal/std utility classes unless explicitly whitelisted by
     *      annotations (@:coreApi, @:presence, @:application, @:native for target modules).
     * HOW: Apply name/package based filters early, then fall back to existing allow rules.
     */
    public override function shouldGenerateClass(classType: ClassType): Bool {
        // Suppress obvious internal/impl/iterator/std support modules
        if (shouldSuppressStdEmission(classType)) {
            return false;
        }
        // Debug for TodoApp investigation
        #if debug_annotation_transforms
        if (classType.name == "TodoApp") {
            trace('[shouldGenerateClass] Checking TodoApp...');
            trace('[shouldGenerateClass]   isExtern: ${classType.isExtern}');
            trace('[shouldGenerateClass]   has @:application: ${classType.meta.has(":application")}');
            trace('[shouldGenerateClass]   has @:native: ${classType.meta.has(":native")}');
            var result = super.shouldGenerateClass(classType);
            trace('[shouldGenerateClass]   super.shouldGenerateClass returns: ${result}');
        }
        #end
        
        // Skip internal Haxe types that shouldn't generate modules
        // Module names in Elixir must start with uppercase letters
        if (classType.name.startsWith("__") || classType.name == "___Int64") {
            return false;
        }
        
        // Check if this is an extern class with special annotations
        if (classType.isExtern && hasSpecialAnnotations(classType)) {
            // Force generation for extern classes with framework annotations
            return true;
        }
        
        // Check if this is a class with @:presence annotation
        // These need to be compiled to generate Phoenix.Presence modules
        // This includes both regular classes and @:native classes (which are extern)
        if (classType.meta.has(":presence")) {
            #if debug_behavior_transformer
            trace('[shouldGenerateClass] Forcing compilation of @:presence class: ${classType.name} (isExtern: ${classType.isExtern})');
            #end
            return true;
        }
        
        // Check if this is a @:coreApi class (like Date, Sys, etc.)
        // These need to be generated as Elixir modules
        if (classType.meta.has(":coreApi")) {
            return true;
        }

        // Ensure Phoenix component modules are always generated
        // WHY: `use AppWeb, :html` imports AppWeb.CoreComponents at runtime; Haxe DCE can't see this
        // WHAT: Force generation for classes annotated with @:component (component modules)
        if (classType.meta.has(":component")) {
            return true;
        }
        
        // Check if this is an @:application class
        // These need to be compiled to generate OTP application modules
        if (classType.meta.has(":application")) {
            #if debug_annotation_transforms
            trace('[shouldGenerateClass] Forcing compilation of @:application class: ${classType.name}');
            #end
            return true;
        }
        
        // Force compilation of Date class when used
        // This ensures Date module with __elixir__() implementations is available
        if (classType.name == "Date" && classType.pack.length == 0) {
            return true;
        }
        
        // Otherwise use default behavior
        return super.shouldGenerateClass(classType);
    }

    /**
     * Centralized suppression rules for std and internal modules
     */
    private function shouldSuppressStdEmission(classType: ClassType): Bool {
        // Fast checks by name
        var n = classType.name;
        if (n == null) return false;

        // Skip Haxe internal implementation modules
        if (n.endsWith("_Impl_")) return true;

        // Skip packages that are compiler/macro-only or Haxe-internal
        if (classType.pack != null && classType.pack.length > 0) {
            var top = classType.pack[0];
            if (top == null) top = "";

            // Compiler/macro-only libs (never emit as modules)
            if (top == "reflaxe" || top == "js" || top == "genes") return true;

            // Haxe std: allow by default, but filter internal subpackages starting with underscore
            if (top == "haxe") {
                if (classType.pack.length > 1) {
                    var sub = classType.pack[1];
                    if (sub != null && StringTools.startsWith(sub, "_")) return true; // _call_stack, _constraints, _int32, etc.
                }
            }

            // Underscored pseudo-packages (e.g., _Any, _EnumValue)
            if (StringTools.startsWith(top, "_")) return true;

            // No additional bans beyond leading underscore
        }

        return false;
    }
    
    /**
     * Get the current app name from the class being compiled
     * 
     * @:appName annotation is crucial for Phoenix applications because:
     * 1. **PubSub Module Names**: Phoenix.PubSub requires app-specific module names (e.g., "TodoApp.PubSub")
     * 2. **Telemetry Modules**: Applications need telemetry modules like "TodoAppWeb.Telemetry"
     * 3. **Endpoint Modules**: Web endpoints are named like "TodoAppWeb.Endpoint"
     * 4. **Supervisor Names**: OTP supervisors use app-specific names like "TodoApp.Supervisor"
     * 
     * Without configurable app names, all generated applications would hardcode "TodoApp"
     * making it impossible to create multiple Phoenix apps or rename projects.
     * 
     * Usage: @:appName("MyApp") - generates MyApp.PubSub, MyAppWeb.Telemetry, etc.
     */
    
    /**
     * Get the original variable name before Haxe's renaming.
     * 
     * When Haxe renames variables to avoid shadowing (e.g., todos → todos2),
     * the original name is preserved in Meta.RealPath metadata.
     * This function retrieves the original name if available.
     * 
     * @param v The TVar to get the name from
     * @return The original variable name or the current name if no metadata exists
     */
    /**
     * Get the original variable name before Haxe's internal renaming
     * 
     * WHY: Delegates to VariableCompiler for centralized variable name management
     * 
     * @param v The TVar to get the name from
     * @return The original variable name
     */
    public function getOriginalVarName(v: TVar): String {
        return v.getNameOrMeta(":realPath");
    }
    
    /**
     * Check if an expression contains a reference to a specific variable
     * 
     * WHY: Delegates to VariableCompiler for centralized variable analysis
     * 
     * @param expr The expression to analyze
     * @param variableName The variable name to search for
     * @return True if the expression contains a reference to the variable
     */
    // Pipeline analysis removed - handled by AST transformer
    
    // Pipeline analysis methods removed - functionality moved to AST transformer

    // containsVariableReference moved to VariableCompiler.hx
    
    
    /**
     * Generate annotation-aware output path for framework convention adherence.
     * 
     * Uses framework-specific paths for annotated classes:
     * - @:router → /lib/app_web/router.ex
     * - @:liveview → /lib/app_web/live/class_name.ex  
     * - @:controller → /lib/app_web/controllers/class_name.ex
     * - @:schema → /lib/app/schemas/class_name.ex
     * - No annotation → /lib/ClassName.ex (default 1:1 mapping)
     */
    
    
    
    /**
     * Convert PascalCase to snake_case for Elixir file naming conventions.
     * Examples: TodoApp → todo_app, UserController → user_controller
     */
    
    /**
     * DEPRECATED: Framework-aware file relocation is now handled using Reflaxe's built-in system
     * 
     * Files are now placed in correct Phoenix locations during compilation using:
     * - setOutputFileName() for custom file names 
     * - setOutputFileDir() for custom directory paths
     * 
     * This approach is better because:
     * 1. No post-compilation file moves needed
     * 2. Integrates properly with Reflaxe's OutputManager
     * 3. Respects Reflaxe's file tracking and cleanup
     * 4. Works with all Reflaxe features (source maps, etc.)
     * 
     * See setFrameworkAwareOutputPath() for the new implementation.
     */
    
    /**
     * Convert Haxe names to Elixir naming conventions
     * Uses NameUtils for consistency
     */
    public function toElixirName(haxeName: String): String {
        return reflaxe.elixir.ast.NameUtils.toElixirName(haxeName);
    }
    
    /**
     * Convert package.ClassName to package/class_name.ex path
     * Examples: 
     * - haxe.CallStack → haxe/call_stack  
     * - TestDocClass → test_doc_class
     * - my.nested.Module → my/nested/module
     */
    private function convertPackageToDirectoryPath(classType: ClassType): String {
        if (classType.pack.length == 0) return "";
        
        var segments = classType.pack.map(function(segment) {
            return reflaxe.elixir.ast.NameUtils.toSnakeCase(segment);
        });
        
        return segments.join("/");
    }
    
    /**
     * Get the output path for a module (for tracking)
     *
     * NOTE: For framework-aware modules (e.g. @:application), the compiler calls
     * `setFrameworkAwareOutputPath` which computes a concrete `outputPath` and
     * stores it in `moduleOutputPaths`. This helper is used as a fallback when
     * no framework override exists.
     */
    public function getModuleOutputPath(moduleName: String, pack: Array<String> = null): String {
        var fileName = reflaxe.elixir.ast.NameUtils.toSnakeCase(moduleName) + ".ex";
        
        if (pack != null && pack.length > 0) {
            var dirPath = pack.map(function(segment) {
                return reflaxe.elixir.ast.NameUtils.toSnakeCase(segment);
            }).join("/");
            return dirPath + "/" + fileName;
        }
        
        return fileName;
    }
    
    /**
     * Set output path for ANY module type using the universal naming system.
     * This ensures consistent snake_case naming for all generated files.
     */
    private function setUniversalOutputPath(moduleName: String, pack: Array<String> = null): Void {
        // Convert module name to snake_case
        var fileName = reflaxe.elixir.ast.NameUtils.toSnakeCase(moduleName);
        
        // Set the output file name
        setOutputFileName(fileName);
        
        // Convert package to directory path if provided
        if (pack != null && pack.length > 0) {
            var dirPath = pack.map(function(segment) {
                return reflaxe.elixir.ast.NameUtils.toSnakeCase(segment);
            }).join("/");
            
            setOutputFileDir(dirPath);
        }
    }
    
    /**
     * setFrameworkAwareOutputPath
     *
     * WHAT
     * - Computes framework-specific module names and file paths for annotated
     *   classes such as `@:application`, while delegating all other classes to
     *   the universal snake_case naming system.
     *
     * WHY
     * - Phoenix conventions expect OTP application modules like
     *   `TodoApp.Application` to live under `lib/todo_app/application.ex`.
     *   Previously the compiler generated correct module names via
     *   `ModuleBuilder.extractModuleName`, but still wrote files as
     *   `lib/todo_app.ex`, causing `TodoApp.Application` to be missing at
     *   runtime for the todo-app.
     *
     * HOW
     * - For `@:application` classes:
     *     - Derives the app module prefix from `PhoenixMapper.getAppModuleName`
     *       (backed by `-D app_name` / @:appName annotations).
     *     - Sets `moduleName` to `<App>.Application`.
     *     - Sets `outputPath` and OutputManager state to
     *       `todo_app/application.ex` (snake_case app name + fixed filename).
     *   All other classes:
     *     - Use `setUniversalOutputPath` + `getModuleOutputPath` for the
     *       existing snake_case-per-module behavior.
     *
     * EXAMPLES
     * Haxe:
     *   @:application
     *   @:appName("TodoApp")
     *   class TodoApp { ... }
     *
     * Elixir (before – buggy):
     *   # No TodoApp.Application module generated; runtime crash at boot.
     *
     * Elixir (after):
     *   # lib/todo_app/application.ex
     *   defmodule TodoApp.Application do
     *     use Application
     *     def start(type, args), do: ...
     *   end
     */
    private function setFrameworkAwareOutputPath(
        classType: ClassType,
        moduleName: String,
        modulePack: Array<String>
    ): FrameworkNamingResult {
        // Application modules: map to lib/<app_snake>/application.ex
        if (classType.meta.has(":application")) {
            var appModuleName = reflaxe.elixir.PhoenixMapper.getAppModuleName();
            var appSnake = reflaxe.elixir.ast.NameUtils.toSnakeCase(appModuleName);
            
            // Final Elixir module name (TodoApp.Application)
            var finalModuleName = appModuleName + ".Application";
            var finalPack: Array<String> = [appSnake];
            
            // File placement: lib/todo_app/application.ex
            setOutputFileName("application");
            setOutputFileDir(appSnake);
            
            var outputPath = appSnake + "/application.ex";
            #if debug_annotation_transforms
            Sys.println('[setFrameworkAwareOutputPath] @:application ${classType.name} -> module=${finalModuleName}, path=${outputPath}');
            #end
            return {
                moduleName: finalModuleName,
                modulePack: finalPack,
                outputPath: outputPath
            };
        }
        
        // Default path: snake_case(moduleName) under snake_case(pack)
        setUniversalOutputPath(moduleName, modulePack);
        return {
            moduleName: moduleName,
            modulePack: modulePack,
            outputPath: null
        };
    }
    
    
    
    
    
    
    
    /**
     * Required implementation for GenericCompiler - implements class compilation
     * @param classType The Haxe class type
     * @param varFields Class variables
     * @param funcFields Class functions
     * @return ElixirAST representing the compiled module
     */
    public function compileClassImpl(classType: ClassType, varFields: Array<ClassVarData>, funcFields: Array<ClassFuncData>): Null<reflaxe.elixir.ast.ElixirAST> {
        #if debug_compilation_flow
        trace('[ElixirCompiler.compileClassImpl] START compiling class: ${classType.name}');
        trace('[ElixirCompiler.compileClassImpl] varFields: ${varFields.length}, funcFields: ${funcFields.length}');
        #end

        if (classType == null) return null;

        // Debug output for TodoApp investigation
        #if debug_annotation_transforms
        if (classType.name == "TodoApp") {
            trace('[ElixirCompiler.compileClassImpl] === TodoApp Debug Info ===');
            trace('[ElixirCompiler.compileClassImpl] funcFields received: ${funcFields.length}');
            for (f in funcFields) {
                trace('[ElixirCompiler.compileClassImpl]   - Function: ${f.field.name}');
            }
            trace('[ElixirCompiler.compileClassImpl] isExtern: ${classType.isExtern}');
            trace('[ElixirCompiler.compileClassImpl] metadata: [${[for (m in classType.meta.get()) m.name].join(", ")}]');
            
            // Check if GenericCompiler considers this class extern
            trace('[ElixirCompiler.compileClassImpl] classType.fields.get().length: ${classType.fields.get().length}');
            trace('[ElixirCompiler.compileClassImpl] classType.statics.get().length: ${classType.statics.get().length}');
            for (field in classType.statics.get()) {
                trace('[ElixirCompiler.compileClassImpl]   Static field: ${field.name}, kind: ${field.kind}');
            }
        }
        #end

        // Skip standard library/internal classes that shouldn't generate Elixir modules
        if (isStandardLibraryClass(classType.name) || shouldSuppressStdEmission(classType)) {
            #if debug_compilation_flow
            trace('[ElixirCompiler.compileClassImpl] Skipping std/internal class: ${classType.name}');
            #end
            return null;
        }

        // Initialize function usage collector for this module
        var functionUsageCollector = new reflaxe.elixir.helpers.FunctionUsageCollector();
        functionUsageCollector.currentModule = classType.name;

        // Check for @:native annotation to determine base module name/pack
        var moduleName = classType.name;
        var modulePack = classType.pack;
        
        if (classType.meta.has(":native")) {
            var nativeMeta = classType.meta.extract(":native");
            if (nativeMeta.length > 0 && nativeMeta[0].params != null && nativeMeta[0].params.length > 0) {
                switch(nativeMeta[0].params[0].expr) {
                    case EConst(CString(s, _)):
                        // Parse the native module name for package and name
                        var parts = s.split(".");
                        if (parts.length > 1) {
                            moduleName = parts[parts.length - 1];
                            modulePack = parts.slice(0, parts.length - 1).map(p -> reflaxe.elixir.ast.NameUtils.toSnakeCase(p));
                        } else {
                            moduleName = s;
                            modulePack = [];
                        }
                    default:
                        // Keep original if annotation is malformed
                }
            }
        }

        // Apply framework-aware naming (e.g., @:application → TodoApp.Application,
        // lib/todo_app/application.ex) while preserving default behavior for other
        // modules via the universal naming system.
        var frameworkNaming = setFrameworkAwareOutputPath(classType, moduleName, modulePack);
        moduleName = frameworkNaming.moduleName;
        modulePack = frameworkNaming.modulePack;
        
        // Set current module for dependency tracking using the final module name
        currentCompiledModule = moduleName;
        // Initialize dependency map for this module if not exists
        if (!moduleDependencies.exists(moduleName)) {
            moduleDependencies.set(moduleName, new Map<String, Bool>());
        }
        
        // Track the output path for this module. Use the framework override when
        // provided; otherwise fall back to universal naming rules.
        var outputPath = frameworkNaming.outputPath != null
            ? frameworkNaming.outputPath
            : getModuleOutputPath(moduleName, modulePack);
        moduleOutputPaths.set(moduleName, outputPath);
        // Track BaseType for synthetic outputs
        moduleBaseTypes.set(moduleName, classType);
        
        // Store current class context for use in expression compilation
        this.currentClassType = classType;
        
        // Activate behavior transformer based on class metadata
        // This replaces the old isInPresenceModule flag with a more generic system
        #if debug_behavior_transformer
        trace('[ElixirCompiler] Compiling class: ${classType.name}');
        #end
        
        if (reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer != null) {
            var behaviorName = reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.checkAndActivateBehavior(classType);
            #if debug_behavior_transformer
            if (behaviorName != null) {
                trace('[BehaviorTransformer] Activated behavior "${behaviorName}" for class ${classType.name}');
            } else {
                trace('[BehaviorTransformer] No behavior found for class ${classType.name}');
            }
            #end
        }
        
        // Use AST pipeline for class compilation
        var moduleAST = buildClassAST(classType, varFields, funcFields);

        // Ensure Phoenix component modules are always emitted
        // WHAT: Classes annotated with @:component define Phoenix.Component functions
        // WHY: Phoenix apps using `use AppWeb, :html` import AppWeb.CoreComponents unconditionally
        //      Even if DCE removes unused functions, the module itself must exist at runtime
        // HOW: Mark the module AST with metadata.forceEmit so the output iterator never suppresses it
        if (classType.meta.has(":component")) {
            if (moduleAST != null) {
                if (moduleAST.metadata == null) moduleAST.metadata = {};
                Reflect.setField(moduleAST.metadata, "forceEmit", true);
            }
        }

        // Add function usage information to module metadata
        if (functionUsageCollector != null && moduleAST != null) {
            if (moduleAST.metadata == null) {
                moduleAST.metadata = {};
            }
            // Store the list of unused functions in metadata
            moduleAST.metadata.unusedPrivateFunctions = functionUsageCollector.getUnusedPrivateFunctions();
            moduleAST.metadata.unusedPrivateFunctionsWithArity = functionUsageCollector.getUnusedPrivateFunctionsWithArity();

            #if debug_function_usage
            functionUsageCollector.printStats();
            #end
        }

        #if debug_compilation_flow
        trace('[ElixirCompiler.compileClassImpl] END compiling class: ${classType.name}');
        #end

        // Return AST directly - transformation and printing handled by ElixirOutputIterator
        return moduleAST;
    }
    
    
    /**
     * Required implementation for GenericCompiler - implements enum compilation
     */
    public function compileEnumImpl(enumType: EnumType, options: Array<EnumOptionData>): Null<reflaxe.elixir.ast.ElixirAST> {
        if (enumType == null) return null;
        
        // Set output file path with snake_case naming
        setUniversalOutputPath(enumType.name, enumType.pack);
        
        // Use AST pipeline for enum compilation
        var enumAST = buildEnumAST(enumType, options);
        
        // Return AST directly - transformation and printing handled by ElixirOutputIterator
        return enumAST;
    }
    
    /**
     * Compile expression - required by GenericCompiler (implements abstract method)
     * 
     * WHY: Delegates to AST builder to construct typed AST nodes
     * WHAT: Clean entry point that routes TypedExpr compilation to AST generation
     * HOW: Returns ElixirAST nodes that are later transformed and printed
     */
    /**
     * Override compileExpression to handle __elixir__ injection properly using Reflaxe's system
     * 
     * WHY: We need to use checkTargetCodeInjectionGeneric like other Reflaxe compilers (C#, etc.)
     * to properly handle __elixir__() injection with the GenericCompiler base class.
     * 
     * WHAT: Uses Reflaxe's built-in TargetCodeInjection system for code injection
     * 
     * HOW: Calls checkTargetCodeInjectionGeneric and processes the results into ERaw nodes
     */
    public override function compileExpression(expr: TypedExpr, topLevel: Bool = false): Null<reflaxe.elixir.ast.ElixirAST> {
        // Check for target code injection using Reflaxe's built-in system
        switch(expr.expr) {
            case TCall(e, args):
                // Use Reflaxe's TargetCodeInjection system like C# compiler does
                if (options.targetCodeInjectionName != null) {
                    #if debug_injection
                    trace('[ElixirCompiler] Checking injection for: ${options.targetCodeInjectionName}');
                    trace('[ElixirCompiler] Expression type: ${expr.expr}');
                    trace('[ElixirCompiler] Call target: ${e.expr}');
                    #end

                    final result = TargetCodeInjection.checkTargetCodeInjectionGeneric(
                        options.targetCodeInjectionName,
                        expr,
                        this
                    );

                    #if debug_injection
                    if (result == null) {
                        trace('[ElixirCompiler] ❌ checkTargetCodeInjectionGeneric returned NULL');
                        trace('[ElixirCompiler] Trying manual TField detection...');
                    } else {
                        trace('[ElixirCompiler] ✓ checkTargetCodeInjectionGeneric returned result with ${result.length} entries');
                    }
                    #end

                    if (result != null) {
                        // Special-case: Build AST for known patterns instead of ERaw strings
                        var ectoAst = tryBuildEctoWhereAST(result, expr.pos);
                        if (ectoAst != null) {
                            return ectoAst;
                        }
                        // Process the injection result as string fallback
                        var finalCode = "";
                        var insideString = false;  // Track if we're currently inside a string literal

                        #if debug_injection
                        trace('[ElixirCompiler] Processing ${result.length} injection entries');
                        #end

                        for (i in 0...result.length) {
                            var entry = result[i];
                            switch(entry) {
                                case Left(code):
                                    // Direct string code - check for string delimiters
                                    #if debug_injection
                                    trace('[ElixirCompiler] Entry $i - Left: "$code"');
                                    trace('[ElixirCompiler] insideString BEFORE: $insideString');
                                    #end

                                    finalCode += code;

                                    // Update insideString state by counting unescaped quotes
                                    var j = 0;
                                    while (j < code.length) {
                                        if (code.charAt(j) == '"' && (j == 0 || code.charAt(j-1) != '\\')) {
                                            insideString = !insideString;
                                            #if debug_injection
                                            trace('[ElixirCompiler] Quote at position $j, insideString now: $insideString');
                                            #end
                                        }
                                        j++;
                                    }

                                    #if debug_injection
                                    trace('[ElixirCompiler] insideString AFTER: $insideString');
                                    #end

                                case Right(ast):
                                    // Compiled AST - convert to string
                                    var astStr = reflaxe.elixir.ast.ElixirASTPrinter.printAST(ast);

                                    #if debug_injection
                                    trace('[ElixirCompiler] Entry $i - Right: AST → "$astStr"');
                                    trace('[ElixirCompiler] insideString: $insideString');
                                    #end

                                    if (insideString) {
                                        // Inside string literal: ensure the interpolated expression is a single valid expression
                                        // Wrap multi-statement or assignment-heavy outputs in an IIFE inside #{...}
                                        var needsIife = (astStr.indexOf("\n") != -1) || (astStr.indexOf("=") != -1 && astStr.indexOf("==") == -1);
                                        var wrapped = needsIife ? '(fn -> ' + astStr + ' end).()' : astStr;
                                        finalCode += '#{' + wrapped + '}';
                                    } else {
                                        // Outside string: direct substitution
                                        #if debug_injection
                                        trace('[ElixirCompiler] Direct substitution (not in string)');
                                        #end
                                        finalCode += astStr;
                                    }
                            }
                        }

                        #if debug_injection
                        trace('[ElixirCompiler] Final injection code: "$finalCode"');
                        #end

                        // Return as raw Elixir code
                        return reflaxe.elixir.ast.ElixirAST.makeAST(
                            reflaxe.elixir.ast.ElixirASTDef.ERaw(finalCode)
                        );
                    }

                    // WORKAROUND: Reflaxe's checkTargetCodeInjectionGeneric only detects TIdent,
                    // but Haxe sometimes types untyped __elixir__() as TField or other patterns.
                    // Manually check for __elixir__ in TField, TLocal, etc.
                    var isInjectionCall = switch(e.expr) {
                        case TIdent(id): id == options.targetCodeInjectionName;
                        case TField(_, fa):
                            switch(fa) {
                                case FInstance(_, _, cf) | FStatic(_, cf) | FAnon(cf) | FClosure(_, cf):
                                    cf.get().name == options.targetCodeInjectionName;
                                case FEnum(_, ef):
                                    ef.name == options.targetCodeInjectionName;
                                case FDynamic(s):
                                    s == options.targetCodeInjectionName;
                            }
                        case TLocal(v): v.name == options.targetCodeInjectionName;
                        case _: false;
                    };

                    #if debug_injection
                    if (isInjectionCall) {
                        trace('[ElixirCompiler] ✓ Manual detection: Found ${options.targetCodeInjectionName} call');
                    }
                    #end

                    if (isInjectionCall && args.length > 0) {
                        // Manual injection processing (same as Reflaxe's algorithm)
                        final injectionString: String = switch(args[0].expr) {
                            case TConst(TString(s)): s;
                            case _: "";
                        };

                        if (injectionString != "") {
                            #if debug_injection
                            trace('[ElixirCompiler] Manual injection processing: "${injectionString.substr(0, 50)}..."');
                            trace('[ElixirCompiler] Number of parameter arguments: ${args.length - 1}');
                            #end

                            // Try Ecto where AST build from manual path
                            if (injectionString.indexOf("Ecto.Query.where") != -1 && injectionString.indexOf("[t]") != -1 && args.length >= 3) {
                                var queryAst = compileExpression(args[1]);
                                var rhsAst = compileExpression(args[2]);
                                if (queryAst != null && rhsAst != null) {
                                    var rx = ~/\[t\]\s*,\s*t\.([a-zA-Z0-9_]+)\s*(==|!=|<=|>=|<|>)\s*\^\(/;
                                    if (rx.match(injectionString)) {
                                        var fieldName = rx.matched(1);
                                        var opStr = rx.matched(2);
                                        var binding = reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EList([
                                            reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("t"))
                                        ]));
                                        var rhsStr = reflaxe.elixir.ast.ElixirASTPrinter.printAST(rhsAst);
                                        var condition = reflaxe.elixir.ast.ElixirAST.makeAST(
                                            reflaxe.elixir.ast.ElixirASTDef.ERaw('t.' + fieldName + ' ' + opStr + ' ^(' + rhsStr + ')')
                                        );
                                        var whereCall = reflaxe.elixir.ast.ElixirAST.makeAST(
                                            reflaxe.elixir.ast.ElixirASTDef.ERemoteCall(
                                                reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("Ecto.Query")),
                                                "where",
                                                [queryAst, binding, condition]
                                            )
                                        );
                                        return whereCall;
                                    }
                                }
                            }

                            // Build finalCode by processing character by character
                            var finalCode = "";
                            var insideString = false;
                            var i = 0;

                            while (i < injectionString.length) {
                                var char = injectionString.charAt(i);

                                // Track string state
                                if (char == '"' && (i == 0 || injectionString.charAt(i-1) != '\\')) {
                                    insideString = !insideString;
                                    finalCode += char;
                                    i++;
                                    continue;
                                }

                                // Check for {N} placeholder
                                if (char == '{' && i + 1 < injectionString.length) {
                                    var j = i + 1;
                                    var numStr = "";

                                    // Collect digits
                                    while (j < injectionString.length && injectionString.charAt(j) >= '0' && injectionString.charAt(j) <= '9') {
                                        numStr += injectionString.charAt(j);
                                        j++;
                                    }

                                    // Check if we found a valid placeholder like {0}, {1}, etc.
                                    if (numStr != "" && j < injectionString.length && injectionString.charAt(j) == '}') {
                                        final num = Std.parseInt(numStr);
                                        if (num != null && num + 1 < args.length) {
                                            // Compile the argument
                                            var argAst = compileExpression(args[num + 1]);
                                            if (argAst != null) {
                                                var argStr = reflaxe.elixir.ast.ElixirASTPrinter.printAST(argAst);

                                                #if debug_injection
                                                trace('[ElixirCompiler] Substituting {$num} with "$argStr" (insideString: $insideString)');
                                                #end

                                                if (insideString) {
                                                    // Inside string: wrap in #{...} for interpolation
                                                    finalCode += '#{$argStr}';
                                                } else {
                                                    // Outside string: direct substitution
                                                    finalCode += argStr;
                                                }

                                                // Skip past the placeholder
                                                i = j + 1;
                                                continue;
                                            }
                                        }
                                    }
                                }

                                // Regular character - just append
                                finalCode += char;
                                i++;
                            }

                            #if debug_injection
                            trace('[ElixirCompiler] Manual injection final code: "$finalCode"');
                            #end

                            return reflaxe.elixir.ast.ElixirAST.makeAST(
                                reflaxe.elixir.ast.ElixirASTDef.ERaw(finalCode)
                            );
                        }
                    }
                }
            case _:
        }

        // Not an injection, use normal compilation
        return super.compileExpression(expr, topLevel);
    }

    /**
     * Attempts to build a typed ElixirAST for Ecto.Query.where injection patterns.
     * Recognizes strings generated by TypedQueryLambda where code looks like:
     * (require Ecto.Query; Ecto.Query.where({0}, [t], t.<field> <op> ^({1})))
     */
    private function tryBuildEctoWhereAST(result:Array<haxe.ds.Either<String, reflaxe.elixir.ast.ElixirAST>>, ?pos:haxe.macro.Expr.Position): Null<reflaxe.elixir.ast.ElixirAST> {
        if (result == null) return null;
        // Concatenate string parts and capture first two AST args ({0} and {1})
        var code = new StringBuf();
        var queryAst: Null<reflaxe.elixir.ast.ElixirAST> = null;
        var rhsAst: Null<reflaxe.elixir.ast.ElixirAST> = null;
        for (entry in result) switch (entry) {
            case Left(s): code.add(s);
            case Right(ast):
                if (queryAst == null) queryAst = ast; else if (rhsAst == null) rhsAst = ast;
        }
        var s = code.toString();
        #if debug_injection
        trace('[ElixirCompiler] tryBuildEctoWhereAST code="$s"');
        trace('[ElixirCompiler] tryBuildEctoWhereAST queryAst=' + (queryAst != null));
        trace('[ElixirCompiler] tryBuildEctoWhereAST rhsAst=' + (rhsAst != null));
        #end
        // Fast check: contains Ecto.Query.where and [t]
        if (s.indexOf("Ecto.Query.where") == -1 || s.indexOf("[t]") == -1) return null;
        // Extract field and operator in pattern: [t], t.<field> <op> ^(
        var fieldName:String = null;
        var opStr:String = null;
        var rx = ~/\[t\]\s*,\s*t\.([a-zA-Z0-9_]+)\s*(==|!=|<=|>=|<|>)\s*\^\(/;
        if (rx.match(s)) {
            fieldName = rx.matched(1);
            opStr = rx.matched(2);
        } else {
            #if debug_injection
            trace('[ElixirCompiler] tryBuildEctoWhereAST regex did not match');
            #end
            return null;
        }
        if (queryAst == null || rhsAst == null) return null;
        // Build AST: Ecto.Query.where(queryAst, [t], t.field <op> ^(rhs))
        var mod = reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.ERemoteCall(
            reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("Kernel")),
            "require",
            [reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("Ecto.Query"))]
        ));
        // We do not emit explicit require; compiler can add imports elsewhere.
        var binding = reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EList([
            reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("t"))
        ]));
        // Build condition as structured AST to enable downstream analysis (no ERaw)
        var lhsField = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.EField(
                reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("t")),
                fieldName
            )
        );
        inline function toOp(op:String): reflaxe.elixir.ast.ElixirAST.EBinaryOp {
            return switch (op) {
                case "==": reflaxe.elixir.ast.ElixirAST.EBinaryOp.Equal;
                case "!=": reflaxe.elixir.ast.ElixirAST.EBinaryOp.NotEqual;
                case "<":  reflaxe.elixir.ast.ElixirAST.EBinaryOp.Less;
                case "<=": reflaxe.elixir.ast.ElixirAST.EBinaryOp.LessEqual;
                case ">":  reflaxe.elixir.ast.ElixirAST.EBinaryOp.Greater;
                case ">=": reflaxe.elixir.ast.ElixirAST.EBinaryOp.GreaterEqual;
                default: reflaxe.elixir.ast.ElixirAST.EBinaryOp.Equal; // conservative fallback
            };
        }
        var pinnedRhs = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.EPin(rhsAst)
        );
        var condition = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.EBinary(toOp(opStr), lhsField, pinnedRhs)
        );
        var whereCall = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.ERemoteCall(
                reflaxe.elixir.ast.ElixirAST.makeAST(reflaxe.elixir.ast.ElixirASTDef.EVar("Ecto.Query")),
                "where",
                [queryAst, binding, condition]
            )
        );
        return whereCall;
    }
    
    /**
     * Creates a properly initialized CompilationContext
     *
     * WHY: Centralizes context creation to ensure all contexts have proper initialization
     * including the new AST modularization infrastructure (Phase 2)
     *
     * WHAT: Creates context with BuilderFacade and all necessary references
     *
     * HOW: Initializes context, sets up BuilderFacade if enabled, registers builders
     */
    private function createCompilationContext(): CompilationContext {
        var context = new CompilationContext();
        context.compiler = this;

        // Check if we're compiling within an ExUnit test class
        // This enables proper handling of instance variables in test methods
        if (currentClassType != null && currentClassType.meta.has(":exunit")) {
            context.isInExUnitTest = true;
            #if debug_exunit
            trace('[ElixirCompiler] Setting isInExUnitTest=true for context (class: ${currentClassType.name})');
            #end
        }

        // Initialize behavior transformer
        if (context.behaviorTransformer == null) {
            context.behaviorTransformer = new reflaxe.elixir.behaviors.BehaviorTransformer();
        }

        // Initialize feature flags from compiler defines
        initializeFeatureFlags(context);

        // Phase 2: Initialize BuilderFacade for gradual migration
        // Only create if we're using any new builders
        if (context.isFeatureEnabled("use_new_pattern_builder") ||
            context.isFeatureEnabled("use_new_loop_builder") ||
            context.isFeatureEnabled("use_new_function_builder") ||
            context.isFeatureEnabled("use_new_comprehension_builder")) {

            context.builderFacade = new reflaxe.elixir.ast.builders.BuilderFacade(this, context);

            // Register specialized builders as they become available
            // TODO: Restore when PatternMatchBuilder import is fixed
            // var patternBuilder = new reflaxe.elixir.ast.builders.PatternMatchBuilder(
            //     context,
            //     context.getExpressionBuilder()
            // );
            // context.builderFacade.registerBuilder("pattern", patternBuilder);

            #if debug_ast_builder
            trace('[ElixirCompiler] BuilderFacade initialized with registered builders');
            #end
        }

        return context;
    }

    /**
     * Initialize feature flags from compiler defines (-D flags)
     *
     * WHY: Allow users to enable/disable features via command line without
     * code changes. Critical for gradual migration and testing.
     *
     * WHAT: Reads specific -D defines and sets corresponding feature flags
     * in the compilation context.
     *
     * HOW: Check for known feature defines and set them in the context
     *
     * Examples:
     * - -D elixir.feature.new_module_builder=true
     * - -D elixir.feature.loop_builder_enabled=true
     * - -D elixir.feature.idiomatic_comprehensions=true
     */
    private function initializeFeatureFlags(context: CompilationContext): Void {
        // Check for individual feature flags
        if (haxe.macro.Context.defined("elixir.feature.new_module_builder")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.new_module_builder");
            context.setFeatureFlag("new_module_builder", value != "false");
        }

        // Enable loop_builder by default - can be disabled with -D elixir.feature.loop_builder_enabled=false
        if (haxe.macro.Context.defined("elixir.feature.loop_builder_enabled")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.loop_builder_enabled");
            context.setFeatureFlag("loop_builder_enabled", value != "false");
        } else {
            // Default to enabled for better loop generation
            context.setFeatureFlag("loop_builder_enabled", true);
        }

        if (haxe.macro.Context.defined("elixir.feature.idiomatic_comprehensions")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.idiomatic_comprehensions");
            context.setFeatureFlag("idiomatic_comprehensions", value != "false");
        }

        if (haxe.macro.Context.defined("elixir.feature.pattern_extraction")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.pattern_extraction");
            context.setFeatureFlag("pattern_extraction", value != "false");
        }

        // Check for the new builder flags that are already being used
        if (haxe.macro.Context.defined("elixir.feature.use_new_pattern_builder")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.use_new_pattern_builder");
            context.setFeatureFlag("use_new_pattern_builder", value != "false");
        }

        if (haxe.macro.Context.defined("elixir.feature.use_new_loop_builder")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.use_new_loop_builder");
            context.setFeatureFlag("use_new_loop_builder", value != "false");
        }

        // Global flag to enable all experimental features
        if (haxe.macro.Context.defined("elixir.feature.experimental")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.experimental");
            if (value != "false") {
                context.setFeatureFlag("new_module_builder", true);
                context.setFeatureFlag("loop_builder_enabled", true);
                context.setFeatureFlag("idiomatic_comprehensions", true);
                context.setFeatureFlag("pattern_extraction", true);
                context.setFeatureFlag("use_new_pattern_builder", true);
                context.setFeatureFlag("use_new_loop_builder", true);
            }
        }

        // Legacy compatibility mode - defaults to old behavior
        if (haxe.macro.Context.defined("elixir.feature.legacy")) {
            var value = haxe.macro.Context.definedValue("elixir.feature.legacy");
            if (value != "false") {
                // Explicitly disable all new features
                context.setFeatureFlag("new_module_builder", false);
                context.setFeatureFlag("loop_builder_enabled", false);
                context.setFeatureFlag("idiomatic_comprehensions", false);
                context.setFeatureFlag("pattern_extraction", false);
                context.setFeatureFlag("use_new_pattern_builder", false);
                context.setFeatureFlag("use_new_loop_builder", false);
            }
        }

        // Debug flag to print enabled features
        #if debug_feature_flags
        trace("Feature flags initialized:");
        for (key in context.astContext.featureFlags.keys()) {
            trace('  $key: ${context.astContext.featureFlags.get(key)}');
        }
        #end
    }

    /**
     * Implement the required abstract method for expression compilation
     *
     * WHY: Reflaxe's GenericCompiler calls this to compile individual expressions.
     * This is the correct integration point for our AST pipeline.
     * Function boundary detection enables persistent context for variable naming consistency.
     *
     * WHAT: Builds AST for individual expressions, with function boundary detection
     *
     * HOW: Detects TFunction boundaries and delegates to compileFunctionWithPersistentContext()
     *      for function-scoped transformation contexts. Other expressions use standard flow.
     */
    public function compileExpressionImpl(expr: TypedExpr, topLevel: Bool): Null<reflaxe.elixir.ast.ElixirAST> {
        // CRITICAL: Function boundary detection for persistent context
        // WHY: Functions need persistent nameMapping across all statements in their body
        // WHAT: TFunction indicates function definition with parameters and body
        // HOW: Delegate to specialized method that maintains context across statements
        switch(expr.expr) {
            case TFunction(f):
                return compileFunctionWithPersistentContext(expr, f, topLevel);
            default:
                // Standard compilation flow for non-function expressions
        }

        // Create a fresh compilation context for this expression
        // This ensures complete isolation between compilation units during parallel execution
        var context = createCompilationContext();

        // CRITICAL: Preprocess TypedExpr to eliminate infrastructure variables FIRST
        // This must happen BEFORE any other processing to ensure clean patterns
        expr = reflaxe.elixir.preprocessor.TypedExprPreprocessor.preprocess(expr);

        // Capture infrastructure variable substitutions for builder reference
        // Band-aid fix: Builders re-compile sub-expressions and lose preprocessor work
        // TODO Phase 2: Refactor builders to accept pre-built AST instead
        context.infraVarSubstitutions = reflaxe.elixir.preprocessor.TypedExprPreprocessor.getLastSubstitutions();

        // Analyze variable usage before building AST
        // This enables context-aware naming to prevent Elixir compilation warnings
        var usageMap = reflaxe.elixir.helpers.VariableUsageAnalyzer.analyzeUsage(expr);
        context.variableUsageMap = usageMap;

        // Collect function calls if we have a collector active
        // TODO: Restore when FunctionUsageCollector is implemented
        // if (functionUsageCollector != null) {
        //     functionUsageCollector.collectCalls(expr);
        // }

        // Build AST for the expression with compilation context
        // Pass context as second parameter to ensure isolated state
        var ast = reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(expr, context);

        trace('[AST Pipeline] After Builder - AST type: ${ast != null ? Type.enumConstructor(ast.def) : "null"}');

        // Apply transformations to all expressions, not just function bodies
        // Pass context to transformer as well
        if (ast != null) {
            var originalAstId = Std.string(ast);
            var transformedAst = reflaxe.elixir.ast.ElixirASTTransformer.transform(ast, context);
            var transformedAstId = Std.string(transformedAst);

            trace('[AST Pipeline] After Transformer - Same object: ${originalAstId == transformedAstId}');
            trace('[AST Pipeline]   Original AST ID: $originalAstId');
            trace('[AST Pipeline]   Transformed AST ID: $transformedAstId');

            ast = transformedAst;

            #if debug_loop_builder
            // Check if this is a reduce_while call to inspect lambda integrity
            if (ast != null) {
                switch(ast.def) {
                    case ERemoteCall(module, funcName, args):
                        switch(module.def) {
                            case EVar("Enum"):
                                if (funcName == "reduce_while" && args != null && args.length >= 3) {
                                    trace('[XRay Pipeline] After transformation - Enum.reduce_while detected');
                                    var reducerArg = args[2];
                                    trace('[XRay Pipeline]   Reducer arg type: ${Type.enumConstructor(reducerArg.def)}');
                                    switch(reducerArg.def) {
                                        case EFn(clauses):
                                            if (clauses.length > 0) {
                                                var clause = clauses[0];
                                                trace('[XRay Pipeline]   Lambda body type: ${Type.enumConstructor(clause.body.def)}');
                                                switch(clause.body.def) {
                                                    case EBlock(exprs):
                                                        trace('[XRay Pipeline]   Lambda body is EBlock with ${exprs.length} expressions');
                                                    case EIf(_, _, _):
                                                        trace('[XRay Pipeline]   Lambda body is EIf (correct structure)');
                                                    default:
                                                        trace('[XRay Pipeline]   Lambda body is: ${Type.enumConstructor(clause.body.def)}');
                                                }
                                            }
                                        default:
                                            trace('[XRay Pipeline]   Reducer is not EFn: ${Type.enumConstructor(reducerArg.def)}');
                                    }
                                }
                            default:
                        }
                    default:
                }
            }
            #end
        }

        trace('[AST Pipeline] Returning AST to caller');
        return ast;
    }

    /**
     * Compile function with persistent transformation context
     *
     * WHY: Variable renames must be consistent across all statements in a function body.
     *      Previous approach created fresh context per expression, losing nameMapping.
     *
     * WHAT: Compiles function with single parent context shared across all body statements
     *
     * HOW:
     * 1. Create function-scoped parent context
     * 2. Process function body by preprocessing and analyzing usage
     * 3. Build AST using the persistent context
     * 4. Apply transformations with the same context
     * 5. Return completed function AST
     *
     * @param expr The complete TFunction expression
     * @param f The TFunc structure containing parameters and body
     * @param topLevel Whether this is a top-level function
     * @return ElixirAST node for the function
     */
    function compileFunctionWithPersistentContext(expr: TypedExpr, f: haxe.macro.Type.TFunc, topLevel: Bool): Null<reflaxe.elixir.ast.ElixirAST> {
        // Create function-scoped parent context that persists across all statements
        var functionContext = createCompilationContext();

        // Preprocess the entire function expression
        var preprocessedExpr = reflaxe.elixir.preprocessor.TypedExprPreprocessor.preprocess(expr);

        // Analyze variable usage for the entire function
        var usageMap = reflaxe.elixir.helpers.VariableUsageAnalyzer.analyzeUsage(preprocessedExpr);
        functionContext.variableUsageMap = usageMap;

        // Build AST using the function-scoped context
        // The builder will process parameters and create the function structure
        var ast = reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(preprocessedExpr, functionContext);

        // Apply transformations with the persistent context
        // This ensures nameMapping from parameters flows into body
        if (ast != null) {
            var transformedAst = reflaxe.elixir.ast.ElixirASTTransformer.transform(ast, functionContext);
            ast = transformedAst;
        }

        return ast;
    }
    
    /**
     * Generate output iterator for converting AST to strings
     * 
     * WHY: GenericCompiler produces AST nodes, but Reflaxe needs strings for file output
     * WHAT: Returns an iterator that processes all compiled AST nodes
     * HOW: Delegates to ElixirOutputIterator which handles transformation and printing
     */
    public function generateOutputIterator(): Iterator<DataAndFileInfo<StringOrBytes>> {
        return new ElixirOutputIterator(this);
    }
    
    /**
     * Get modules sorted by dependency order (topological sort)
     * 
     * WHY: When generating scripts with bootstrap code, modules must be loaded
     *      in dependency order to avoid "module not found" errors.
     * 
     * WHAT: Returns a list of module names sorted so that dependencies come before
     *       modules that depend on them.
     * 
     * HOW: Simple topological sort - modules with no dependencies first,
     *      then modules that only depend on already-sorted modules.
     * 
     * @return Array of module names in dependency order
     */
    public function getSortedModules(): Array<String> {
        var sorted: Array<String> = [];
        var remaining = new Map<String, Bool>();
        
        // Collect all modules
        for (moduleName in moduleDependencies.keys()) {
            remaining.set(moduleName, true);
        }
        
        // Keep adding modules that have all dependencies satisfied
        while (remaining.keys().hasNext()) {
            var added = false;
            for (moduleName in remaining.keys()) {
                var deps = moduleDependencies.get(moduleName);
                var canAdd = true;
                
                // Check if all dependencies are already in sorted list
                if (deps != null) {
                    for (dep in deps.keys()) {
                        if (remaining.exists(dep)) {
                            canAdd = false;
                            break;
                        }
                    }
                }
                
                if (canAdd) {
                    sorted.push(moduleName);
                    remaining.remove(moduleName);
                    added = true;
                }
            }
            
            // Break if we can't add any more (circular dependencies)
            if (!added) {
                // Debug trace for circular dependency detection
                #if debug_module_sorting
                trace('[ElixirCompiler] Breaking circular dependency, remaining: ' + [for (k in remaining.keys()) k].join(', '));
                #end

                // Add remaining modules anyway to avoid infinite loop
                for (moduleName in remaining.keys()) {
                    sorted.push(moduleName);
                }

                // CRITICAL FIX: Clear the remaining map to actually exit the while loop
                remaining.clear();
                break;
            }
        }
        
        return sorted;
    }
    
    /**
     * Check if a class has special annotations that need framework-specific handling
     */
    function hasSpecialAnnotations(classType: ClassType): Bool {
        return classType.meta.has(":endpoint") ||
               classType.meta.has(":liveview") ||
               classType.meta.has(":schema") ||
               classType.meta.has(":repo") ||
               classType.meta.has(":dbTypes") ||
               classType.meta.has(":postgrexTypes") ||
               classType.meta.has(":application") ||
               classType.meta.has(":genserver") ||
               classType.meta.has(":router") ||
               classType.meta.has(":controller") ||
               classType.meta.has(":presence") ||
               classType.meta.has(":phoenixWeb") ||
               classType.meta.has(":phoenixWebModule") ||
               classType.meta.has(":exunit") ||
               classType.meta.has(":coreApi");  // Include @:coreApi classes like Date
    }
    
    /**
     * Discover dependencies by pre-compiling function bodies
     * 
     * WHY: Dependencies are tracked when ERemoteCall nodes are generated during function compilation.
     *      We need to discover these before building the module structure.
     * 
     * WHAT: Compiles all function bodies to trigger dependency tracking without generating output
     * 
     * HOW: Iterates through all functions and compiles their expressions, which populates
     *      the moduleDependencies map as a side effect of trackDependency() calls
     */
    function discoverDependencies(classType: ClassType, funcFields: Array<ClassField>): Void {
        #if debug_compilation_flow
        trace('[ElixirCompiler.discoverDependencies] START for class: ${classType.name} with ${funcFields.length} functions');
        #end

        // Activate behavior transformer for dependency discovery
        // This replaces the old isInPresenceModule flag with a generic system
        var previousBehavior: Null<String> = null;
        if (reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer != null) {
            previousBehavior = reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.activeBehavior;
            var behaviorName = reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.checkAndActivateBehavior(classType);
            #if debug_behavior_transformer
            if (behaviorName != null) {
                trace('[BehaviorTransformer] Activated behavior "${behaviorName}" for dependency discovery of ${classType.name}');
            }
            #end
        }
        
        // Set compiler reference for dependency tracking
        reflaxe.elixir.ast.ElixirASTBuilder.compiler = this;
        
        // Compile each function body to discover dependencies
        for (func in funcFields) {
            var funcExpr = func.expr();
            if (funcExpr != null) {
                // Compile the function body - this triggers dependency tracking
                // We don't need the result, just the side effect of tracking
                switch(funcExpr.expr) {
                    case TFunction(tfunc):
                        if (tfunc.expr != null) {
                            // Create context for dependency tracking
                            var context = createCompilationContext();

                            // Initialize behavior transformer if needed
                            if (context.behaviorTransformer == null) {
                                context.behaviorTransformer = new reflaxe.elixir.behaviors.BehaviorTransformer();
                            }

                            // CRITICAL: Preprocess function body to eliminate infrastructure variables
                            tfunc.expr = reflaxe.elixir.preprocessor.TypedExprPreprocessor.preprocess(tfunc.expr);

                            // Analyze variable usage for the function
                            var usageMap = reflaxe.elixir.helpers.VariableUsageAnalyzer.analyzeUsage(tfunc.expr);
                            context.variableUsageMap = usageMap;

                            // Build AST which triggers dependency tracking
                            reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(tfunc.expr, context);
                        }
                    default:
                        // Not a function, skip
                }
            }
        }
        
        #if debug_dependencies
        var deps = moduleDependencies.get(currentCompiledModule);
        if (deps != null) {
            trace('[ElixirCompiler] After dependency discovery for ${currentCompiledModule}: ${[for (k in deps.keys()) k].join(", ")}');
        }
        #end
        
        // Restore previous behavior state
        if (reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer != null) {
            reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.activeBehavior = previousBehavior;
        }

        #if debug_compilation_flow
        trace('[ElixirCompiler.discoverDependencies] END for class: ${classType.name}');
        #end
    }
    
    /**
     * Build AST for a class (generates Elixir module)
     */
    function buildClassAST(classType: ClassType, varFields: Array<ClassVarData>, funcFields: Array<ClassFuncData>): Null<reflaxe.elixir.ast.ElixirAST> {

        #if debug_behavior_transformer
        trace('[ElixirCompiler.buildClassAST] Building class: ${classType.name}');
        trace('[ElixirCompiler.buildClassAST] Metadata: ${[for (m in classType.meta.get()) m.name]}');
        #end

        #if debug_annotation_transforms
        if (classType.name == "TodoApp") {
            trace('[ElixirCompiler.buildClassAST] TodoApp received ${funcFields.length} functions');
            for (f in funcFields) {
                trace('[ElixirCompiler.buildClassAST] Function: ${f.field.name}');
            }
        }
        #end

        // Skip built-in types and std/internal classes that shouldn't generate modules
        if (isBuiltinAbstractType(classType.name) || isStandardLibraryClass(classType.name) || shouldSuppressStdEmission(classType)) {
            return null;
        }
        
        // Activate behavior transformer if this class has a behavior annotation
        // This ensures that when the class's methods are compiled, the behavior transformer
        // is active and can inject self() or other behavior-specific transformations
        var previousBehavior: Null<String> = null;
        if (reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer != null) {
            previousBehavior = reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.activeBehavior;
            var behaviorName = reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.checkAndActivateBehavior(classType);
            #if debug_behavior_transformer
            if (behaviorName != null) {
                trace('[BehaviorTransformer] Activated behavior "${behaviorName}" for building ${classType.name} module');
            } else {
                trace('[BehaviorTransformer] No behavior found for ${classType.name}');
            }
            #end
        }
        
        // Special-case: Generate Gettext module skeletons from @:gettext classes
        if (classType.meta.has(":gettext")) {
            var moduleName = reflaxe.elixir.ast.builders.ModuleBuilder.extractModuleName(classType);
            // Determine otp_app from module prefix before "Web" when available (TodoAppWeb.* → :todo_app)
            var appPrefix: Null<String> = null;
            var webIdx = moduleName.indexOf("Web");
            if (webIdx > 0) appPrefix = moduleName.substr(0, webIdx);
            if (appPrefix == null || appPrefix.length == 0) {
                try appPrefix = reflaxe.elixir.PhoenixMapper.getAppModuleName() catch (e:Dynamic) {}
            }
            if (appPrefix == null || appPrefix.length == 0) appPrefix = classType.name; // conservative fallback
            var appAtom = reflaxe.elixir.ast.NameUtils.toSnakeCase(appPrefix);
            // Build: defmodule <Module> do\n  use Gettext.Backend, otp_app: :app\nend
            var useStmt = reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EUse("Gettext.Backend", [
                reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EKeywordList([
                    { key: "otp_app", value: reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EAtom(appAtom)) }
                ]))
            ]));
            var mod = {
                def: reflaxe.elixir.ast.ElixirASTDef.EDefmodule(moduleName, {
                    def: reflaxe.elixir.ast.ElixirASTDef.EBlock([useStmt]),
                    metadata: {},
                    pos: classType.pos
                }),
                metadata: {},
                pos: classType.pos
            };
            // Ensure this is emitted even if empty of functions
            Reflect.setField(mod.metadata, "forceEmit", true);
            return mod;
        }

        // ALWAYS use ModuleBuilder for ALL other classes to eliminate duplication
        // All classes go through ModuleBuilder now for consistency

        #if debug_module_builder
        trace('[ElixirCompiler] Using provided funcFields parameter: ${funcFields.length} functions');
        trace('[ElixirCompiler] Using provided varFields parameter: ${varFields.length} variables');
        #end
        
        // PASS 1: Discover dependencies by pre-compiling function bodies
        // This populates the moduleDependencies map before we build the module
        // Extract ClassField array from ClassFuncData array for discoverDependencies
        var funcClassFields = funcFields.map(fd -> fd.field);
        discoverDependencies(classType, funcClassFields);
        
        // PASS 2: Build the module with discovered dependencies
        // Set compiler reference for dependency tracking and bootstrap generation
        reflaxe.elixir.ast.ElixirASTBuilder.compiler = this;

        // Create a compilation context for this class
        var context = createCompilationContext();

        // Set current class in context for same-module optimization
        context.currentClass = classType;

        // Build fields from the funcFields parameter (which is already ClassFuncData array)
        var fields: Array<reflaxe.elixir.ast.ElixirAST> = [];

        // Compile each function field
        for (funcData in funcFields) {
            // Skip constructor for now
            if (funcData.field.name == "new") continue;

            // Get the function expression and preprocess it
            var expr = funcData.expr;
            // Skip functions without body - they might be extern or abstract
            if (expr == null) continue;
            
            // Preprocess the function body to eliminate infrastructure variables
            expr = reflaxe.elixir.preprocessor.TypedExprPreprocessor.preprocess(expr);

            #if debug_ast_builder
            trace('[ElixirCompiler] Compiling function: ${funcData.field.name}');
            if (expr != null) {
                trace('[ElixirCompiler]   Body type: ${Type.enumConstructor(expr.expr)}');
                switch(expr.expr) {
                    case TReturn(e) if (e != null):
                        trace('[ElixirCompiler]   TReturn contains: ${Type.enumConstructor(e.expr)}');
                        switch(e.expr) {
                            case TSwitch(_, cases, _):
                                trace('[ElixirCompiler]     Direct return of TSwitch with ${cases.length} cases');
                            case TLocal(v):
                                trace('[ElixirCompiler]     Return of TLocal: ${v.name}');
                            default:
                                trace('[ElixirCompiler]     Return of: ${Type.enumConstructor(e.expr)}');
                        }
                    case TBlock(exprs):
                        trace('[ElixirCompiler]   TBlock with ${exprs.length} expressions');
                        if (exprs.length > 0) {
                            var last = exprs[exprs.length - 1];
                            trace('[ElixirCompiler]     Last expr: ${Type.enumConstructor(last.expr)}');
                        }
                    default:
                        trace('[ElixirCompiler]   Other: ${Type.enumConstructor(expr.expr)}');
                }
            }
            #end

            // Check if this is an ExUnit test method FIRST
            // ExUnit test methods are special - they're NOT instance methods
            // even if they appear to be in the Haxe class structure
            // Note: In some cases, metadata is stored with the colon prefix (":test")
            // Check both with and without colon to be safe
            var isExUnitTestMethod = funcData.field.meta.has("test") || 
                                     funcData.field.meta.has("setup") ||
                                     funcData.field.meta.has("setupAll") ||
                                     funcData.field.meta.has("teardown") ||
                                     funcData.field.meta.has("teardownAll") ||
                                     funcData.field.meta.has(":test") ||
                                     funcData.field.meta.has(":setup") ||
                                     funcData.field.meta.has(":setupAll") ||
                                     funcData.field.meta.has(":teardown") ||
                                     funcData.field.meta.has(":teardownAll");
            
            #if debug_exunit
            trace('[ElixirCompiler] Checking ${funcData.field.name}: has("test")=${funcData.field.meta.has("test")}, isExUnitTestMethod=$isExUnitTestMethod');
            // Let's see what metadata IS present
            if (funcData.field.name.indexOf("test") == 0) {
                var metaList = [];
                for (m in funcData.field.meta.get()) {
                    metaList.push(m.name);
                }
                trace('[ElixirCompiler]   Metadata present on ${funcData.field.name}: [${metaList.join(", ")}]');
            }
            #end
            
            // Set method context for instance methods
            // Instance methods need a struct parameter in Elixir
            var isStaticMethod = funcData.isStatic;
            
            if (isExUnitTestMethod) {
                // ExUnit test functions are standalone, not methods on a struct
                // They don't have access to instance variables via 'this'
                context.isInClassMethodContext = false;
                context.currentReceiverParamName = null;
                context.isInExUnitTest = true;
                #if debug_exunit
                trace('[ElixirCompiler] Set isInExUnitTest=true for function ${funcData.field.name}');
                trace('[ElixirCompiler] Context check immediately after setting: isInExUnitTest=${context.isInExUnitTest}');
                #end
            } else {
                // Regular method handling
                context.isInClassMethodContext = !isStaticMethod;
                context.isInExUnitTest = false;
                
                // For instance methods, set the receiver parameter name to "struct"
                if (!isStaticMethod) {
                    context.currentReceiverParamName = "struct";
                } else {
                    context.currentReceiverParamName = null;
                }
            }

            // Populate tempVarRenameMap for function parameters BEFORE building the body
            // This fixes the issue where parameters with numeric suffixes (like options2)
            // aren't mapped correctly in the function body
            if (funcData.tfunc != null) {
                #if debug_variable_renaming
                trace('[ElixirCompiler] Processing ${funcData.field.name} - funcData.tfunc is NOT null, registering ${funcData.tfunc.args.length} parameters');
                trace('[ElixirCompiler] Context tempVarRenameMap BEFORE registration: ${Lambda.count(context.tempVarRenameMap)} entries');
                #end

                for (arg in funcData.tfunc.args) {
                    var originalName = arg.v.name;
                    var idKey = Std.string(arg.v.id);

                    #if debug_variable_renaming
                    trace('[ElixirCompiler] Processing parameter for ${funcData.field.name}: "$originalName" (id: $idKey)');
                    #end

                    // Check if parameter has numeric suffix that indicates shadowing
                    var strippedName = originalName;
                    var renamedPattern = ~/^(.+?)(\d+)$/;
                    if (renamedPattern.match(originalName)) {
                        var baseWithoutSuffix = renamedPattern.matched(1);
                        var suffix = renamedPattern.matched(2);

                        // Only strip suffix for common field names
                        var commonFieldNames = ["options", "columns", "name", "value", "type", "data", "fields", "items", "priority"];
                        if ((suffix == "2" || suffix == "3") && commonFieldNames.indexOf(baseWithoutSuffix) >= 0) {
                            strippedName = baseWithoutSuffix;

                            #if debug_variable_renaming
                            trace('[ElixirCompiler] Registering renamed parameter mapping: $originalName (id: ${arg.v.id}) -> $strippedName');
                            #end
                        }
                    }

                    // Check if this parameter is unused in the function body
                    var isUnused = if (arg.v.meta != null && arg.v.meta.has("-reflaxe.unused")) {
                        true;
                    } else if (funcData.expr != null) {
                        // Use UsageDetector to check if parameter is actually used
                        !reflaxe.elixir.helpers.UsageDetector.isParameterUsed(arg.v, funcData.expr);
                    } else {
                        false;
                    };
                    
                    // Register the mapping for use in function body
                    // Use toSafeElixirParameterName to handle reserved keywords
                    var baseName = reflaxe.elixir.ast.NameUtils.toSafeElixirParameterName(strippedName);
                    // Add underscore prefix for unused parameters
                    var finalName = if (isUnused && !baseName.startsWith("_")) {
                        "_" + baseName;
                    } else {
                        baseName;
                    };
                    #if debug_variable_renaming
                    trace('[ElixirCompiler] About to register for ${funcData.field.name}: idKey="$idKey" originalName="$originalName" finalName="$finalName" unused=$isUnused');
                    trace('[ElixirCompiler] Map exists check: ${context.tempVarRenameMap.exists(idKey)}');
                    #end

                    if (!context.tempVarRenameMap.exists(idKey)) {
                        #if debug_variable_renaming
                        trace('[ElixirCompiler] ENTERED if block - about to set mappings');
                        #end

                        // Dual-key storage: ID for pattern positions, name for EVar references
                        context.tempVarRenameMap.set(idKey, finalName);           // ID-based (pattern matching)
                        context.tempVarRenameMap.set(originalName, finalName);    // NAME-based (EVar renaming)

                        #if debug_variable_renaming
                        trace('[ElixirCompiler] COMPLETED setting mappings for idKey=$idKey');
                        trace('[ElixirCompiler] Context hashcode: ${untyped context.__id}');
                        trace('[ElixirCompiler] Map hashcode: ${untyped context.tempVarRenameMap.__id}');
                        #end

                        #if debug_variable_renaming
                        trace('[ElixirCompiler] ✓ Registered dual-key: id=$idKey name=$originalName -> $finalName');
                        trace('[ElixirCompiler] Map size after registration: ${Lambda.count(context.tempVarRenameMap)}');
                        #end

                        #if debug_hygiene
                        trace('[Hygiene] Dual-key registered: id=$idKey name=$originalName -> $finalName');
                        #end
                    } else {
                        #if debug_variable_renaming
                        trace('[ElixirCompiler] ✗ Skipped registration (idKey already exists): $idKey');
                        #end
                    }
                }

                #if debug_variable_renaming
                trace('[ElixirCompiler] AFTER registration loop for ${funcData.field.name} - map has ${Lambda.count(context.tempVarRenameMap)} entries');
                #end
            }

            // Build the function body with proper context
            // Special handling for direct switch returns that may have lost context
            #if debug_switch_return
            trace("[SwitchReturnDebug] Building function body for: " + funcData.field.name);
            if (expr != null) {
                trace("[SwitchReturnDebug] expr.expr type: " + Type.enumConstructor(expr.expr));
            } else {
                trace("[SwitchReturnDebug] expr is null (no body)");
            }
            #end

            #if debug_exunit
            trace('[ElixirCompiler] About to build funcBody for ${funcData.field.name}, context.isInExUnitTest=${context.isInExUnitTest}');
            #end
            
            var funcBody = switch(expr.expr) {
                case TReturn(e) if (e != null):
                    #if debug_switch_return
                    trace("[SwitchReturnDebug] Found TReturn with non-null expression");
                    trace("[SwitchReturnDebug] Return expr type: " + (e != null ? Type.enumConstructor(e.expr) : "null"));
                    #end

                    // Check if it's a return of a switch (potentially wrapped in metadata)
                    var innerExpr = e;
                    switch(e.expr) {
                        case TMeta(_, inner):
                            #if debug_switch_return
                            trace("[SwitchReturnDebug] Found TMeta wrapper, unwrapping");
                            #end
                            innerExpr = inner;
                        case _:
                    }

                    #if debug_switch_return
                    trace("[SwitchReturnDebug] Inner expr type: " + Type.enumConstructor(innerExpr.expr));
                    #end

                    switch(innerExpr.expr) {
                        case TSwitch(_, _, _):
                            #if debug_switch_return
                            trace("[SwitchReturnDebug] *** Direct switch return detected! Building switch AST directly ***");
                            #end
                            // For direct switch returns, build the switch expression and wrap in parentheses
                            // This ensures the full case structure is preserved
                            var switchAST = reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(e, context);

                            #if debug_switch_return
                            trace("[SwitchReturnDebug] Built switch AST def: " + switchAST.def);
                            #end

                            // The switch itself is the body - no need for additional wrapping
                            switchAST;
                        case _:
                            #if debug_switch_return
                            trace("[SwitchReturnDebug] Not a switch, building normal return");
                            #end
                            // Normal return handling
                            reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(expr, context);
                    }
                case _:
                    #if debug_switch_return
                    trace("[SwitchReturnDebug] Not a direct return, building normally");
                    #end
                    // Normal expression handling
                    #if debug_variable_renaming
                    trace('[ElixirCompiler] About to call buildFromTypedExpr for ${funcData.field.name} - context.tempVarRenameMap has ${Lambda.count(context.tempVarRenameMap)} entries');
                    #end
                    reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(expr, context);
            };

            #if debug_ast_builder
            trace('[ElixirCompiler] Function ${funcData.field.name} body AST: ${funcBody.def}');
            #end

            // Get function parameters from tfunc
            var params: Array<EPattern> = [];

            // For instance methods, add struct as first parameter
            // BUT NOT for ExUnit test methods - they don't get struct parameters
            if (!isStaticMethod && !isExUnitTestMethod) {
                params.push(PVar("struct"));
            }

            // Add the regular function parameters
            if (funcData.tfunc != null) {
                for (arg in funcData.tfunc.args) {
                    // Look up the mapped name from tempVarRenameMap
                    // This will have the underscore prefix if the parameter is unused
                    var idKey = Std.string(arg.v.id);
                    var paramName = if (context.tempVarRenameMap.exists(idKey)) {
                        context.tempVarRenameMap.get(idKey);
                    } else {
                        // Fallback to original logic if not mapped (shouldn't happen)
                        var originalName = arg.v.name;
                        var strippedName = originalName;

                        // Apply same stripping logic as above for consistency
                        var renamedPattern = ~/^(.+?)(\d+)$/;
                        if (renamedPattern.match(originalName)) {
                            var baseWithoutSuffix = renamedPattern.matched(1);
                            var suffix = renamedPattern.matched(2);

                            var commonFieldNames = ["options", "columns", "name", "value", "type", "data", "fields", "items"];
                            if ((suffix == "2" || suffix == "3") && commonFieldNames.indexOf(baseWithoutSuffix) >= 0) {
                                strippedName = baseWithoutSuffix;
                            }
                        }

                        // Use toSafeElixirParameterName to handle reserved keywords
                        reflaxe.elixir.ast.NameUtils.toSafeElixirParameterName(strippedName);
                    };
                    
                    params.push(PVar(paramName));
                }
            }

            // Create function definition
            // Use toSafeElixirFunctionName to handle reserved keywords
            var elixirName = reflaxe.elixir.ast.NameUtils.toSafeElixirFunctionName(funcData.field.name);

            var funcDef = funcData.field.isPublic ?
                EDef(elixirName, params, null, funcBody) :
                EDefp(elixirName, params, null, funcBody);

            // Check for test-related metadata on the function field
            var funcMetadata: reflaxe.elixir.ast.ElixirAST.ElixirMetadata = {};

            // Set ExUnit-related metadata flags directly (accept both forms with and without ':')
            inline function hasMeta(name:String):Bool {
                return funcData.field.meta.has(name) || funcData.field.meta.has(":" + name);
            }
            funcMetadata.isTest = hasMeta("test");
            funcMetadata.isSetup = hasMeta("setup");
            funcMetadata.isSetupAll = hasMeta("setupAll");
            funcMetadata.isTeardown = hasMeta("teardown");
            funcMetadata.isTeardownAll = hasMeta("teardownAll");
            funcMetadata.isAsync = hasMeta("async");

            #if debug_exunit
            if (funcMetadata.isTest) {
                trace('[ElixirCompiler] Set isTest=true for function ${funcData.field.name}');
            }
            #end

            // Check for test tags (gather both :tag and tag forms)
            var tagMeta = funcData.field.meta.extract("tag");
            var tagMetaAlt = funcData.field.meta.extract(":tag");
            if (tagMetaAlt != null && tagMetaAlt.length > 0) {
                if (tagMeta == null) tagMeta = tagMetaAlt; else tagMeta = tagMeta.concat(tagMetaAlt);
            }
            if (tagMeta != null && tagMeta.length > 0) {
                var tags = [];
                for (entry in tagMeta) {
                    if (entry.params != null) {
                        for (param in entry.params) {
                            switch(param.expr) {
                                case EConst(CString(tag)): tags.push(tag);
                                default:
                            }
                        }
                    }
                }
                if (tags.length > 0) {
                    funcMetadata.testTags = tags;
                }
            }

            // Check for describe block (accept both forms)
            var describeMeta = funcData.field.meta.extract("describe");
            var describeMetaAlt = funcData.field.meta.extract(":describe");
            if (describeMetaAlt != null && describeMetaAlt.length > 0) {
                if (describeMeta == null) describeMeta = describeMetaAlt; else describeMeta = describeMeta.concat(describeMetaAlt);
            }
            if (describeMeta != null && describeMeta.length > 0) {
                for (entry in describeMeta) {
                    if (entry.params != null && entry.params.length > 0) {
                        switch(entry.params[0].expr) {
                            case EConst(CString(block)):
                                funcMetadata.describeBlock = block;
                            default:
                        }
                    }
                }
            }

            // Create AST node directly (makeAST is an inline function, not a static method)
            fields.push({
                def: funcDef,
                metadata: funcMetadata,
                pos: funcData.field.pos
            });
        }

        // Prepare metadata for special module types BEFORE building the module
        var metadata: ElixirMetadata = {};
        
        // Detect and store parent class information for inheritance handling
        if (classType.superClass != null) {
            var parentClass = classType.superClass.t.get();
            var parentModuleName = if (parentClass.meta.has(":native")) {
                // Use @:native name if specified
                var nativeMeta = parentClass.meta.extract(":native");
                if (nativeMeta.length > 0 && nativeMeta[0].params != null && nativeMeta[0].params.length > 0) {
                    switch(nativeMeta[0].params[0].expr) {
                        case EConst(CString(s, _)): s;
                        default: parentClass.name;
                    }
                } else {
                    parentClass.name;
                }
            } else {
                parentClass.name;
            };
            
            metadata.parentModule = parentModuleName;
            
            // Check if this extends haxe.Exception or any Exception subclass
            var isException = false;
            var currentClass = parentClass;
            while (currentClass != null) {
                if (currentClass.pack.length == 1 && currentClass.pack[0] == "haxe" && currentClass.name == "Exception") {
                    isException = true;
                    break;
                }
                currentClass = if (currentClass.superClass != null) currentClass.superClass.t.get() else null;
            }
            metadata.isException = isException;
            
            #if debug_inheritance
            trace('[ElixirCompiler] Class ${classType.name} extends ${parentModuleName}, isException: ${isException}');
            #end
        }

        // Enable ExUnit transformation pass for @:exunit modules
        // Meta names in Haxe macros are stored without the leading colon.
        // Be tolerant and check both with and without ':' to avoid fragile assumptions.
        if (classType.meta.has("exunit") || classType.meta.has(":exunit")) {
            metadata.isExunit = true;
        }

        // Enable LiveView transformation pass for @:liveview modules
        if (classType.meta.has(":liveview")) {
            metadata.isLiveView = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isLiveView=true metadata for ${classType.name}');
            #end
        }

        // Enable Application transformation pass for @:application modules
        if (classType.meta.has(":application")) {
            metadata.isApplication = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isApplication=true metadata for ${classType.name}');
            trace('[ElixirCompiler] Passing ${fields.length} fields to ModuleBuilder for ${classType.name}');
            #end
        }
        
        // Enable Repo transformation pass for @:repo modules
        // Note: After prior refactors, some repo metadata fields were lost; restore
        // essential flags here to ensure companion modules (PostgrexTypes) are generated.
        if (classType.meta.has(":repo")) {
            metadata.isRepo = true;
            
            // Extract repo configuration if provided
            var repoMeta = classType.meta.extract(":repo");
            if (repoMeta.length > 0 && repoMeta[0].params != null && repoMeta[0].params.length > 0) {
                // Parse the configuration object
                // The configuration handling was also lost in the refactoring
                // For now, just set the basic metadata
                metadata.dbAdapter = "Ecto.Adapters.Postgres"; // Default to Postgres
                // Companion module generation for Postgres
                metadata.needsPostgrexTypes = true;
                // Default JSON library (configurable via @:repo json field when parser restored)
                metadata.jsonModule = "Jason";
            }
            
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isRepo=true metadata for ${classType.name}');
            #end
        }
        
        // Enable Schema transformation pass for @:schema modules
        if (classType.meta.has(":schema")) {
            metadata.isSchema = true;
            
            // Extract table name from @:schema annotation if provided
            var schemaMeta = classType.meta.extract(":schema");
            if (schemaMeta.length > 0 && schemaMeta[0].params != null && schemaMeta[0].params.length > 0) {
                switch(schemaMeta[0].params[0].expr) {
                    case EConst(CString(tableName, _)):
                        metadata.tableName = tableName;
                    default:
                }
            }
            
            // Check for @:timestamps annotation
            if (classType.meta.has(":timestamps")) {
                metadata.hasTimestamps = true;
            }
            
            // Collect schema fields from varFields for the transformation pass
            var schemaFields = [];
            for (varData in varFields) {
                // Skip if it's a static field or not a regular field
                if (!varData.isStatic && varData.field.kind.match(FVar(_, _))) {
                    var fieldName = varData.field.name;
                    var fieldType = schemaTypeNameFromType(varData.field.type);
                    schemaFields.push({
                        name: fieldName,
                        type: fieldType
                    });
                }
            }
            metadata.schemaFields = schemaFields;
            
            // Store the fully qualified class name for lookups
            metadata.haxeFqcn = classType.pack.length > 0 
                ? classType.pack.join(".") + "." + classType.name 
                : classType.name;
            
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isSchema=true metadata for ${classType.name}');
            trace('[ElixirCompiler] Table name: ${metadata.tableName}, hasTimestamps: ${metadata.hasTimestamps}');
            trace('[ElixirCompiler] Schema fields: ${schemaFields.length} fields collected');
            #end
        }
        
        // Enable Supervisor transformation pass for @:supervisor modules
        if (classType.meta.has(":supervisor")) {
            metadata.isSupervisor = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isSupervisor=true metadata for ${classType.name}');
            #end
        }

        // Enable Router transformation pass for @:router modules
        if (classType.meta.has(":router")) {
            metadata.isRouter = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isRouter=true metadata for ${classType.name}');
            #end
        }

        // Enable Presence transformation pass for @:presence modules
        if (classType.meta.has(":presence")) {
            metadata.isPresence = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isPresence=true metadata for ${classType.name}');
            #end
        }

        // Enable Endpoint transformation pass for @:endpoint modules
        // Endpoints are also supervisors and need child_spec/start_link preservation
        if (classType.meta.has(":endpoint")) {
            metadata.isEndpoint = true;
            // Endpoints are supervisors too - they need child_spec/start_link
            metadata.isSupervisor = true;
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Set isEndpoint=true and isSupervisor=true metadata for ${classType.name}');
            #end
        }

        // Build the module using ModuleBuilder with metadata
        var moduleAST = reflaxe.elixir.ast.builders.ModuleBuilder.buildClassModule(classType, fields, metadata);

        // Additional metadata settings if needed
        if (moduleAST != null && moduleAST.metadata == null) {
            moduleAST.metadata = metadata;
        }
        
        // ExUnit debug output
        if (moduleAST != null && moduleAST.metadata != null && moduleAST.metadata.isExunit == true) {
            #if debug_exunit
            trace('[ElixirCompiler] Set isExunit=true metadata for ${classType.name}');
            #end
        }

        // Application debug output
        if (moduleAST != null && moduleAST.metadata != null && moduleAST.metadata.isApplication == true) {
            #if debug_annotation_transforms
            trace('[ElixirCompiler] Module ${classType.name} has isApplication metadata after building');
            #end
        }

        #if debug_module_builder
        if (classType.name == "Main") {
            trace('[ElixirCompiler] Received module AST for Main from ModuleBuilder');
            // trace('[ElixirCompiler] Main module metadata: ${moduleAST.metadata}');
            // if (moduleAST != null && moduleAST.metadata != null) {
            //     trace('[ElixirCompiler] Main module metadata.isExunit: ${moduleAST.metadata.isExunit}');
            // }
        }
        #end

        // PASS 3: Generate companion modules if needed (e.g., PostgrexTypes for Repo)
        if (moduleAST != null && moduleAST.metadata != null) {
            generateCompanionModules(classType, moduleAST.metadata);
        }
        
        // Restore previous behavior transformer state
        if (reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer != null) {
            reflaxe.elixir.ast.ElixirASTBuilder.behaviorTransformer.activeBehavior = previousBehavior;
            #if debug_behavior_transformer
            if (previousBehavior != null) {
                trace('[BehaviorTransformer] Restored previous behavior: ${previousBehavior}');
            } else {
                trace('[BehaviorTransformer] Deactivated behavior after building ${classType.name}');
            }
            #end
        }
        
        return moduleAST;
    }

    /**
     * Normalize Haxe type to a simple schema type string for Ecto field mapping.
     * - Unwrap Null<T> to T
     * - Map Array<T> to "Array<TName>"
     * - Map core types to their canonical names used by schema mapping
     */
    static function schemaTypeNameFromType(t: Type): String {
        return switch (t) {
            case TType(td, params):
                // Unwrap type aliases (including Null<T>)
                var underlying = td.get();
                if (underlying.name == "Null" && params != null && params.length == 1) {
                    return schemaTypeNameFromType(params[0]);
                } else {
                    // Fallback to the aliased name
                    underlying.name;
                }
            case TAbstract(ad, params):
                var n = ad.get().name;
                if (n == "Null" && params != null && params.length == 1) {
                    return schemaTypeNameFromType(params[0]);
                }
                switch (n) {
                    case "Int": return "Int";
                    case "Bool": return "Bool";
                    case "Single", "Float": return "Float";
                    default: return n;
                }
            case TInst(td, params):
                var cls = td.get();
                if (cls.name == "Array" && params != null && params.length == 1) {
                    return "Array<" + schemaTypeNameFromType(params[0]) + ">";
                }
                switch (cls.name) {
                    case "String": return "String";
                    case "Int": return "Int";
                    case "Bool": return "Bool";
                    case "Date": return "Date";
                    default: return cls.name;
                }
            case TAnonymous(_):
                // Treat anonymous objects as Dynamic
                "Dynamic";
            case _: "String"; // Reasonable default
        }
    }

    /**
     * Generate companion modules based on metadata (e.g., PostgrexTypes for Repo)
     * 
     * WHY: Some Elixir modules require companion modules for configuration.
     *      For example, Ecto.Repo with PostgreSQL needs a PostgrexTypes module
     *      that defines type encoding/decoding using Postgrex.Types.define.
     * 
     * WHAT: Generates additional modules as separate files when needed
     * 
     * HOW: Checks metadata flags and generates appropriate companion modules
     *      using setExtraFile to create additional output files
     */
    function generateCompanionModules(classType: ClassType, metadata: ElixirMetadata): Void {
        // Check if this Repo needs a PostgrexTypes companion module
        if (metadata.isRepo && metadata.needsPostgrexTypes) {
            generatePostgrexTypesModule(classType, metadata);
        }
    }
    
    /**
     * Generate PostgrexTypes companion module for Ecto.Repo with PostgreSQL
     * 
     * WHY: PostgreSQL adapter requires a types module for JSON encoding/decoding
     * 
     * WHAT: Creates a separate module that calls Postgrex.Types.define
     * 
     * HOW: Builds the module AST and writes it as a separate file
     * 
     * Example output:
     * ```elixir
     * defmodule TodoApp.PostgrexTypes do
     *   Postgrex.Types.define(TodoApp.PostgrexTypes, [], json: Jason)
     * end
     * ```
     */
    function generatePostgrexTypesModule(classType: ClassType, metadata: ElixirMetadata): Void {
        // Get the base module name (e.g., "TodoApp.Repo" -> "TodoApp")
        var moduleName = reflaxe.elixir.ast.builders.ModuleBuilder.extractModuleName(classType);
        
        // Extract the base app name (before .Repo)
        var appName = moduleName.split(".")[0];
        
        // Create the PostgrexTypes module name
        var typesModuleName = appName + ".PostgrexTypes";
        
        #if debug_repo
        trace('[ElixirCompiler] Generating PostgrexTypes companion module: ${typesModuleName}');
        trace('[ElixirCompiler] JSON module: ${metadata.jsonModule}, Extensions: ${metadata.extensions}');
        #end
        
        // Build the module body
        var statements = [];
        
        // Build extensions array - empty by default
        var extensionsAST = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.EList([])
        );
        if (metadata.extensions != null && metadata.extensions.length > 0) {
            var extElements = metadata.extensions.map(ext -> 
                reflaxe.elixir.ast.ElixirAST.makeAST(
                    reflaxe.elixir.ast.ElixirASTDef.EAtom(ext)
                )
            );
            extensionsAST = reflaxe.elixir.ast.ElixirAST.makeAST(
                reflaxe.elixir.ast.ElixirASTDef.EList(extElements)
            );
        }
        
        // Build keyword list for options (json: Jason)
        var options = [];
        if (metadata.jsonModule != null) {
            // Create a keyword list element for json: Jason
            var jsonAtom = reflaxe.elixir.ast.ElixirAST.makeAST(
                reflaxe.elixir.ast.ElixirASTDef.EAtom(ElixirAtom.raw("json"))
            );
            var jsonModule = reflaxe.elixir.ast.ElixirAST.makeAST(
                reflaxe.elixir.ast.ElixirASTDef.EVar(metadata.jsonModule)
            );
            var keywordElement = reflaxe.elixir.ast.ElixirAST.makeAST(
                reflaxe.elixir.ast.ElixirASTDef.ETuple([jsonAtom, jsonModule])
            );
            options.push(keywordElement);
        }
        
        // Build the Postgrex.Types.define call
        var moduleRef = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.EVar(typesModuleName)
        );
        var args = [
            moduleRef,          // Module reference
            extensionsAST,      // Extensions array
            reflaxe.elixir.ast.ElixirAST.makeAST(
                reflaxe.elixir.ast.ElixirASTDef.EList(options)
            )  // Options keyword list
        ];
        
        var defineCall = reflaxe.elixir.ast.ElixirAST.makeAST(
            reflaxe.elixir.ast.ElixirASTDef.ERemoteCall(
                reflaxe.elixir.ast.ElixirAST.makeAST(
                    reflaxe.elixir.ast.ElixirASTDef.EVar("Postgrex.Types")
                ),
                "define",
                args
            )
        );
        
        statements.push(defineCall);
        
        // For PostgrexTypes, we don't need a module wrapper - Postgrex.Types.define creates it
        // Just generate the top-level macro call
        var moduleAST = defineCall;

        // Create a compilation context for transformation
        var context = createCompilationContext();

        // Apply transformations with context
        moduleAST = reflaxe.elixir.ast.ElixirASTTransformer.transform(moduleAST, context);

        // Convert to string with context
        var moduleString = reflaxe.elixir.ast.ElixirASTPrinter.printAST(moduleAST, context);
        
        // Set the output path for this companion module
        // Use snake_case for the file name
        var fileName = reflaxe.elixir.ast.NameUtils.toSnakeCase("PostgrexTypes");
        var filePackage = [reflaxe.elixir.ast.NameUtils.toSnakeCase(appName)];
        
        // Create the output path
        var outputPath = filePackage.join("/") + "/" + fileName + ".ex";
        
        #if debug_repo
        trace('[ElixirCompiler] Writing PostgrexTypes module to: ${outputPath}');
        #end
        
        // Use setExtraFile to generate the companion module
        setExtraFile(outputPath, moduleString);
    }
    
    /**
     * Helper to build AST from TypedExpr (delegates to builder)
     */
    function buildFromTypedExpr(expr: TypedExpr, ?usageMap: Map<Int, Bool>): reflaxe.elixir.ast.ElixirAST {
        // Create a fresh compilation context for this expression
        var context = createCompilationContext();

        // Set usage map if provided
        if (usageMap != null) {
            context.variableUsageMap = usageMap;
        }

        return reflaxe.elixir.ast.ElixirASTBuilder.buildFromTypedExpr(expr, context);
    }
    
    /**
     * Check if this is a built-in abstract type that should NOT generate an Elixir module
     */
    private function isBuiltinAbstractType(name: String): Bool {
        // Built-in abstracts that shouldn't generate modules
        return switch(name) {
            case "Int" | "Float" | "Bool" | "String" | "Void" | "Dynamic": true;
            case "__Int64" | "Int64": true; // Haxe Int64 types
            case _: false;
        }
    }
    
    /**
     * Check if this is a standard library class type that should NOT generate an Elixir module
     */
    private function isStandardLibraryClass(name: String): Bool {
        // Standard library classes handled elsewhere
        return switch(name) {
            case "String" | "Array" | "Map" | "Date" | "Math" | "List": true;
            case "__Int64" | "Int64" | "Int64_Impl_": true; // Haxe Int64 internal types
            case _: false;
        }
    }
    
    /**
     * Build enum AST - creates module with constructor functions
     */
    function buildEnumAST(enumType: EnumType, options: Array<EnumOptionData>): Null<reflaxe.elixir.ast.ElixirAST> {
        // Suppress std/internal enums that should not become modules in Elixir output
        if (shouldSuppressEnumEmission(enumType)) {
            return null;
        }
        var NameUtils = reflaxe.elixir.ast.NameUtils;
        
        // Check if this enum has @:elixirIdiomatic metadata
        var isIdiomatic = enumType.meta.has(":elixirIdiomatic");
        
        // In Elixir, enums become modules with functions that return tagged tuples
        // Extract module name - check for @:native annotation first
        var moduleName = if (enumType.meta.has(":native")) {
            // Use explicit @:native module name if provided
            var nativeMeta = enumType.meta.extract(":native");
            if (nativeMeta.length > 0 && nativeMeta[0].params != null && nativeMeta[0].params.length > 0) {
                switch(nativeMeta[0].params[0].expr) {
                    case EConst(CString(s, _)):
                        s;
                    default:
                        // Fall back to package-based name if annotation is malformed
                        buildEnumModuleName(enumType);
                }
            } else {
                buildEnumModuleName(enumType);
            }
        } else {
            buildEnumModuleName(enumType);
        };
        var functions = [];
        
        // Build an index map for enum constructors
        var constructorIndexMap = new Map<String, Int>();
        for (name in enumType.constructs.keys()) {
            var constructor = enumType.constructs.get(name);
            constructorIndexMap.set(name, constructor.index);
        }
        
        for (option in options) {
            // Each enum constructor becomes a function
            // Use safe function name to handle reserved keywords
            var funcName = NameUtils.toSafeElixirFunctionName(option.name);
            
            // Build parameter patterns from the option data
            var args = [];
            for (i in 0...option.args.length) {
                args.push(EPattern.PVar('arg$i'));
            }
            
            // Create the tagged tuple return value
            // For non-idiomatic enums, use integer indices; for idiomatic, use atoms
            var tag = if (isIdiomatic) {
                reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EAtom(option.name));
            } else {
                // Use the constructor's index for non-idiomatic enums
                var index = constructorIndexMap.get(option.name);
                if (index == null) index = 0; // Fallback, should not happen
                reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EInteger(index));
            };
            var tupleElements = [tag];
            
            // Add constructor arguments to tuple
            for (i in 0...option.args.length) {
                tupleElements.push(reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EVar('arg$i')));
            }
            
            var returnValue = reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.ETuple(tupleElements));
            
            // If idiomatic, mark the return value with metadata
            if (isIdiomatic) {
                returnValue.metadata.requiresIdiomaticTransform = true;
                returnValue.metadata.idiomaticEnumType = enumType.name;
            }
            
            var funcDef = ElixirASTDef.EDef(funcName, args, null, returnValue);
            functions.push(reflaxe.elixir.ast.ElixirAST.makeAST(funcDef));
        }
        
        // Create module AST
        var moduleBody = reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EBlock(functions));
        var moduleAST = reflaxe.elixir.ast.ElixirAST.makeAST(ElixirASTDef.EDefmodule(moduleName, moduleBody));
        
        // Mark the module itself if idiomatic
        if (isIdiomatic) {
            moduleAST.metadata.requiresIdiomaticTransform = true;
            moduleAST.metadata.idiomaticEnumType = enumType.name;
        }
        
        return moduleAST;
    }

    /**
     * Suppression rules for enum emission (std/internal)
     */
    private function shouldSuppressEnumEmission(enumType: EnumType): Bool {
        if (enumType == null) return false;
        var n = enumType.name;
        if (n == null) return false;

        // Common Haxe std enums not needed as modules in Elixir
        if (n == "ValueType" || n == "StackItem") return true;

        if (enumType.pack != null && enumType.pack.length > 0) {
            var top = enumType.pack[0];
            if (top == "haxe") return true;
            if (StringTools.startsWith(top, "_")) return true;
        }

        return false;
    }
    
    /**
     * Build the full module name for an enum including package
     * Ensures proper capitalization for Elixir module names
     */
    function buildEnumModuleName(enumType: EnumType): String {
        var parts = enumType.pack.copy();
        parts.push(enumType.name);
        
        // Handle nested module paths with underscores
        // ecto._migration.ConstraintType -> Ecto.Migration.ConstraintType
        var processedParts = [];
        for (part in parts) {
            if (part.length > 0) {
                // Remove leading underscores and capitalize
                var cleanPart = part;
                while (cleanPart.charAt(0) == "_") {
                    cleanPart = cleanPart.substr(1);
                }
                if (cleanPart.length > 0) {
                    // Capitalize the first letter
                    cleanPart = cleanPart.charAt(0).toUpperCase() + cleanPart.substr(1);
                    processedParts.push(cleanPart);
                }
            }
        }
        
        return processedParts.join(".");
    }
    
    public function generateFunctionReference(functionName: String): String {
        // Convert function name to snake_case for Elixir
        var elixirFunctionName = reflaxe.elixir.ast.NameUtils.toSnakeCase(functionName);
        
        // Get the current module name for the function reference
        var currentModuleName = getCurrentModuleName();
        
        // Determine the arity by looking up the function
        var arity = getFunctionArity(functionName);
        
        // Generate Elixir function reference syntax
        return '&${currentModuleName}.${elixirFunctionName}/${arity}';
    }
    
    /**
     * Get the current module name for function references
     */
    public function getCurrentModuleName(): String {
        if (currentClassType != null) {
            // Use the current class name as the module name
            return currentClassType.name;
        }
        return "UnknownModule";
    }
    
    /**
     * Get module name for a specific ClassType
     */
    public function getModuleName(classType: ClassType): String {
        return classType.name;
    }
    
    /**
     * Check if a TypedExpr is being immediately called (part of a TCall expression)
     * This is used to determine if a field access should be compiled as a function reference
     * 
     * @param expr The expression to check
     * @return True if the expression is the function part of a TCall, false otherwise
     */
    private function isBeingCalled(expr: TypedExpr): Bool {
        // This is a simplified check - in a real implementation, we'd need to 
        // traverse the parent AST to see if this expression is the function part of a TCall
        // For now, we'll return false to always generate function references when appropriate
        return false;
    }
    
    /**
     * Get the arity (number of parameters) for a function by name
     * 
     * @param functionName The function name to look up
     * @return The arity of the function, or 1 as a reasonable default
     */
    private function getFunctionArity(functionName: String): Int {
        if (currentClassType != null) {
            // Look for static methods in the current class
            var classFields = currentClassType.statics.get();
            for (field in classFields) {
                if (field.name == functionName) {
                    switch (field.type) {
                        case TFun(args, _):
                            return args.length;
                        case _:
                    }
                }
            }
            
            // Look for instance methods
            var instanceFields = currentClassType.fields.get();
            for (field in instanceFields) {
                if (field.name == functionName) {
                    switch (field.type) {
                        case TFun(args, _):
                            return args.length;
                        case _:
                    }
                }
            }
        }
        
        // Default to arity 1 for unknown functions
        return 1;
    }
    
    /**
     * Compile a block of expressions while preserving inline context across all expressions.
     * This is crucial for handling Haxe's inline function expansion correctly.
     */
    
    /**
     * Set case arm compilation context
     */
    public function setCaseArmContext(inCaseArm: Bool): Void {
        isCompilingCaseArm = inCaseArm;
    }
    
    /**
     * Clear parameter mapping after function compilation
     */
    public function clearFunctionParameterMapping(): Void {
        currentFunctionParameterMap.clear();
        // Reset array desugaring tracking after function compilation
        isCompilingAbstractMethod = false;
    }
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    



    
    /**
     * Extract the lambda parameter variable from a loop body that contains a TFunction
     * 
     * This is used for array method transformations (map, filter) where we need to 
     * identify the lambda parameter to substitute it with the target variable name.
     */
    private function getLambdaParameterFromBody(expr: TypedExpr): Null<TVar> {
        switch (expr.expr) {
            case TFunction(func):
                // Found the lambda function - return its first parameter
                if (func.args.length > 0) {
                    return func.args[0].v;
                }
            case TBlock(exprs):
                // Look through block for lambda function
                for (e in exprs) {
                    var result = getLambdaParameterFromBody(e);
                    if (result != null) return result;
                }
            case TBinop(_, e1, e2):
                // Check both operands
                var result = getLambdaParameterFromBody(e1);
                if (result != null) return result;
                return getLambdaParameterFromBody(e2);
            case TCall(e, args):
                // Check function and arguments
                var result = getLambdaParameterFromBody(e);
                if (result != null) return result;
                for (arg in args) {
                    result = getLambdaParameterFromBody(arg);
                    if (result != null) return result;
                }
            case TIf(econd, eif, eelse):
                // Check condition and branches
                var result = getLambdaParameterFromBody(econd);
                if (result != null) return result;
                result = getLambdaParameterFromBody(eif);
                if (result != null) return result;
                if (eelse != null) {
                    result = getLambdaParameterFromBody(eelse);
                    if (result != null) return result;
                }
            case _:
                // Other expression types don't contain lambda functions
        }
        return null;
    }

    
    
    /**
     * Helper function to determine if a variable should be substituted in loop contexts
     * @param varName The variable name to check
     * @param sourceVar The specific source variable we're looking for (null for aggressive mode)
     * @param isAggressiveMode Whether to substitute any non-system variable
     */
    public function shouldSubstituteVariable(varName: String, sourceVar: String = null, isAggressiveMode: Bool = false): Bool {
        // Don't substitute system variables (starting with g_ or temp_)
        if (varName.indexOf("g_") == 0 || varName.indexOf("temp_") == 0) {
            return false;
        }
        
        if (sourceVar != null) {
            // Exact match mode - only substitute the specific variable
            return varName == sourceVar;
        }
        
        if (isAggressiveMode) {
            // Aggressive mode - only substitute when we're actually in a loop context
            // This prevents function parameters like "transform" from being substituted
            return isInLoopContext;
        }
        
        // Default: don't substitute
        return false;
    }

    
    /**
     * Compile expression with variable substitution using TVar object comparison
     */
    
    
    
    // Loop compilation is handled through AST transformation to Elixir's functional constructs.
    // Loops are transformed into recursive functions or Enum operations as appropriate.
    
    
    
    
    
    
    
    
    
    
    
    
    
    /**
     * Get field name from field access
     * Handles @:native annotations on extern methods
     */
    /**
     * Get field name with proper @:native annotation support
     * 
     * WHY: @:native annotations allow library authors to specify exact Elixir names
     * WHAT: Uses Reflaxe's standardized NameMetaHelper for consistent metadata handling
     * HOW: Delegates to getFieldAccessNameMeta() and getNameOrNative() for proper extraction
     * 
     * ARCHITECTURE: This replaces manual metadata extraction with Reflaxe's standardized
     * infrastructure, ensuring consistent handling of @:native across all field access types.
     */
    public function getFieldName(fa: FieldAccess): String {
        #if debug_method_name_resolution
        // trace('[XRay getFieldName] Processing FieldAccess: ${fa}');
        #end
        
        // Use Reflaxe's standardized helper instead of manual extraction
        var nameMeta = NameMetaHelper.getFieldAccessNameMeta(fa);
        var name = nameMeta.getNameOrNative();
        
        #if debug_method_name_resolution
        // trace('[XRay getFieldName] Field name: ${nameMeta.name}, has @:native: ${nameMeta.hasMeta(":native")}, resolved: ${name}');
        #end
        
        // Convert to snake_case for Elixir if not already specified by @:native
        return if (nameMeta.hasMeta(":native")) {
            name; // Use exact name from @:native annotation
        } else {
            reflaxe.elixir.ast.NameUtils.toSnakeCase(name); // Convert to snake_case for idiomatic Elixir
        }
    }
    
    /**
     * Check if a string can be a valid Elixir atom name
     * Elixir atom rules: start with lowercase/underscore, contain alphanumeric/underscore
     */
    private function isValidAtomName(name: String): Bool {
        if (name == null || name.length == 0) return false;
        
        // Check first character: must be lowercase letter or underscore
        var firstChar = name.charAt(0);
        if (!((firstChar >= 'a' && firstChar <= 'z') || firstChar == '_')) {
            return false;
        }
        
        // Check remaining characters: alphanumeric or underscore
        for (i in 1...name.length) {
            var char = name.charAt(i);
            if (!((char >= 'a' && char <= 'z') || 
                  (char >= 'A' && char <= 'Z') || 
                  (char >= '0' && char <= '9') || 
                  char == '_')) {
                return false;
            }
        }
        
        return true;
    }
    
    /**
     * Determine if an object should use atom keys based on field patterns
     * Takes a conservative approach - defaults to string keys unless we're certain
     * Only uses atoms for very specific OTP patterns to avoid breaking user code
     */
    private function shouldUseAtomKeys(fields: Array<{name: String, expr: TypedExpr}>): Bool {
        // First check if this matches known OTP patterns
        if (false) { // OTP compilation now handled by AST pipeline
            return true;
        }
        
        // Check for Phoenix.PubSub configuration pattern
        // Objects with just a "name" field are typically PubSub configs
        if (fields != null && fields.length == 1 && fields[0].name == "name") {
            return isValidAtomName("name");
        }
        
        // Default to string keys for all other cases
        // This is safer and more predictable than trying to guess patterns
        return false;
    }
    
    /**
     * Check if an object declaration represents a Supervisor child spec
     * Child specs have "id" and "start" fields
     */
    private function isChildSpecObject(fields: Array<{name: String, expr: TypedExpr}>): Bool {
        if (fields == null || fields.length == 0) return false;
        
        var fieldNames = fields.map(f -> f.name);
        return fieldNames.indexOf("id") != -1 && fieldNames.indexOf("start") != -1;
    }
    
    /**
     * Child spec format types for structure-based detection
     */
    private static inline var MODERN_TUPLE = "ModernTuple";    // {Module, args} - for modules with child_spec/1
    private static inline var SIMPLE_MODULE = "SimpleModule";   // ModuleName - simple module reference
    private static inline var TRADITIONAL_MAP = "TraditionalMap"; // %{id: ..., start: ...} - explicit map format
    
    
    
    /**
     * Generate modern tuple format for child specs
     * Examples: {Phoenix.PubSub, name: MyApp.PubSub}, MyApp.Repo
     */
    private function generateModernTupleFormat(idField: String, startField: String, appName: String): String {
        var cleanId = idField.split('"').join('');
        
        // Special handling for Phoenix.PubSub with name parameter
        if (cleanId == "Phoenix.PubSub") {
            var pubsubName = '${appName}.PubSub';
            // Extract name from start args if available
            if (startField.indexOf('[%{name: ') > -1) {
                var namePattern = ~/\[%\{name: ([^}]+)\}\]/;
                if (namePattern.match(startField)) {
                    pubsubName = namePattern.matched(1);
                }
            }
            // Convert to atom format for Phoenix compatibility
            // Phoenix expects name to be an atom, not a string
            var atomName = pubsubName.split('"').join(''); // Remove any quotes
            return '{Phoenix.PubSub, name: ${atomName}}';
        }
        
        // For other modules, check if they have simple args
        if (startField.indexOf(", []") > -1) {
            // No args - use simple module reference
            return cleanId;
        } else if (startField.indexOf("[%{") > -1) {
            // Has configuration args - extract and use tuple format
            var argsPattern = ~/\[(%\{[^}]+\})\]/;
            if (argsPattern.match(startField)) {
                var args = argsPattern.matched(1);
                return '{${cleanId}, ${args}}';
            }
        }
        
        // Fallback to simple module reference
        return cleanId;
    }
    
    /**
     * Generate simple module reference format
     * Examples: MyApp.Repo, MyAppWeb.Endpoint
     */
    private function generateSimpleModuleFormat(idField: String, appName: String): String {
        var cleanId = idField.split('"').join('');
        
        // Apply common Phoenix naming conventions if not already prefixed
        if (cleanId.indexOf("Telemetry") > -1 && cleanId.indexOf(appName) == -1) {
            return '${appName}Web.Telemetry';
        }
        if (cleanId.indexOf("Endpoint") > -1 && cleanId.indexOf(appName) == -1) {
            return '${appName}Web.Endpoint';
        }
        if (cleanId.indexOf("Repo") > -1 && cleanId.indexOf(appName) == -1) {
            return '${appName}.Repo';
        }
        
        return cleanId;
    }
    
    
    /**
    
    
    /**
     * Check if an object declaration represents Supervisor options
     * Supervisor options have "strategy" and usually "name" fields
     */
    private function isSupervisorOptionsObject(fields: Array<{name: String, expr: TypedExpr}>): Bool {
        if (fields == null || fields.length == 0) return false;
        
        var fieldNames = fields.map(f -> f.name);
        return fieldNames.indexOf("strategy") != -1;
    }
    
    /**
     * Check if this is a call to elixir.Syntax static methods
     * 
     * @param obj The object expression (should be TTypeExpr for elixir.Syntax)
     * @param fieldName The method name being called
     * @return true if this is an elixir.Syntax call
     */
    
    /**
     * Compile elixir.Syntax method calls to __elixir__ injection calls
     * 
     * This transforms type-safe elixir.Syntax calls into the underlying __elixir__
     * injection mechanism that Reflaxe processes via targetCodeInjectionName.
     * 
     * @param methodName The elixir.Syntax method being called (code, atom, tuple, etc.)
     * @param args The arguments to the method call
     * @return Compiled Elixir code
     */
    
    /**
     * Check if a TypedExpr represents a field assignment (this.field = value)
     */
    private function isFieldAssignment(expr: TypedExpr): Bool {
        return switch (expr.expr) {
            case TBinop(OpAssign, e1, e2):
                switch (e1.expr) {
                    case TField(e, fa):
                        // Check if the field access is on 'this' 
                        switch (e.expr) {
                            case TConst(TThis): true;
                            case TLocal(v): v.name == "this" || v.name == "_this";
                            case _: false;
                        }
                    case _: false;
                }
            case _: false;
        };
    }
    
    // All temp variable optimization and assignment extraction functions
    // have been removed - now handled by the AST pipeline
    
    /**
     * Check if expression is nil
     */
    private function isNilExpression(expr: TypedExpr): Bool {
        return switch (expr.expr) {
            case TConst(TNull): true;
            case TIdent("nil"): true;
            case _: false;
        };
    }
    
    /**
     * Check if this is a TypeSafeChildSpec enum constructor call
     */
    
    /**
     * Compile TypeSafeChildSpec enum constructor calls directly to ChildSpec format
     */
    
    /**
     * Detect if an AST expression will generate a Y combinator pattern.
     * 
     * This function analyzes the AST structure BEFORE string compilation
     * to identify patterns that will result in Y combinator generation,
     * preventing the inline syntax bug where ", else: nil" gets misplaced.
     * 
     * @param expr The TypedExpr to analyze
     * @return True if this expression will generate a Y combinator
     */
    private function detectYCombinatorInAST(expr: TypedExpr): Bool {
        // Y combinators are no longer used - we use idiomatic Elixir patterns
        return false;
    }
    
    /**
     * Check if a block of expressions contains Reflect.fields iteration.
     * 
     * @param expressions Array of expressions to check
     * @return True if contains Reflect.fields iteration pattern
     */
    /**
     * Enhanced Reflect.fields detection with comprehensive debugging.
     * 
     * WHY: The original detection was missing Reflect.fields patterns, causing
     * Y combinator syntax errors. This enhanced version traces the AST structure
     * to understand why patterns aren't being detected.
     * 
     * HOW: Iterates through expressions in a TBlock, specifically looking for:
     * 1. TVar assignments that call Reflect.fields
     * 2. TFor loops that iterate over Reflect.fields results
     * 3. Any nested expressions that contain these patterns
     * 
     * DEBUGGING: Uses XRay debugging to trace AST structure when debug_compiler flag is enabled,
     * allowing us to understand exactly what AST patterns we're encountering.
     * 
     * @param expressions Array of expressions from a TBlock to analyze
     * @return True if any expression uses Reflect.fields (indicating Y combinator generation)
     */

    /**
     * Check if a TypedExpr contains an ~H sigil (Phoenix component template)
     * 
     * WHY: Phoenix components using ~H sigil require 'assigns' parameter without underscore
     * WHAT: Recursively searches expression tree for HXX.hxx calls (which compile to ~H sigil)
     * HOW: Pattern matches on TCall to find HXX.hxx, recursively checks child expressions
     * 
     * @param expr The expression to check for ~H sigil usage
     * @return True if expression contains ~H sigil
     */
    private function containsHSigil(expr: TypedExpr): Bool {
        if (expr == null) return false;
        
        switch(expr.expr) {
            case TCall(e, _):
                // Check if this is an HXX.hxx call (compiles to ~H sigil)
                switch(e.expr) {
                    case TField(_, FStatic(_, cf)):
                        if (cf.get().name == "hxx") {
                            return true;
                        }
                    default:
                }
                // Continue checking in the call target and arguments
                return containsHSigil(e);
                
            case TBlock(exprs):
                for (e in exprs) {
                    if (containsHSigil(e)) return true;
                }
                
            case TReturn(e):
                return containsHSigil(e);
                
            case TIf(econd, eif, eelse):
                return containsHSigil(econd) || containsHSigil(eif) || (eelse != null && containsHSigil(eelse));
                
            case TSwitch(e, cases, edef):
                if (containsHSigil(e)) return true;
                for (c in cases) {
                    if (containsHSigil(c.expr)) return true;
                }
                if (edef != null && containsHSigil(edef)) return true;
                
            case TFunction(tfunc):
                return containsHSigil(tfunc.expr);
                
            case TVar(_, expr):
                return expr != null && containsHSigil(expr);
                
            default:
                // For other expression types, we don't need to check deeper
        }
        return false;
    }
    
    /**
     * Override called after all files have been generated by GenericCompiler.
     * This is the proper place to generate source maps since the main .ex files exist now.
     */
    public override function onCompileEnd() {
        // Generate all pending source maps after all .ex files are written
        if (sourceMapOutputEnabled) {
            for (writer in pendingSourceMapWriters) {
                if (writer != null) {
                    writer.generateSourceMap();
                }
            }
            pendingSourceMapWriters = [];
        }
    }
    
    /**
     * Convert a Haxe Type to string representation
     * 
     * WHY: SubstitutionCompiler needs type information for variable tracking
     * WHAT: Provides basic type-to-string conversion for debugging and analysis
     * HOW: Simple pattern matching on Type enum with fallback to "Dynamic"
     * 
     * @param type The Haxe Type to convert
     * @return String representation of the type
     */
    public function typeToString(type: Type): String {
        return switch (type) {
            case TInst(t, _): t.get().name;
            case TAbstract(t, _): t.get().name;
            case TEnum(t, _): t.get().name;
            case TFun(_, ret): "Function";
            case TMono(_): "Mono";
            case TDynamic(_): "Dynamic";
            case TAnonymous(_): "Anonymous";
            case TType(t, _): t.get().name;
            case TLazy(_): "Lazy";
        }
    }
    
}

#end
</file>

<file path="src/reflaxe/elixir/ElixirOutputIterator.hx">
package reflaxe.elixir;

#if (macro || elixir_runtime)

import reflaxe.output.DataAndFileInfo;
import reflaxe.output.StringOrBytes;
import reflaxe.elixir.ast.builders.ModuleBuilder; // For strategy
import reflaxe.elixir.ast.NameUtils; // snake_case helpers
import reflaxe.elixir.ast.ElixirAST;
import reflaxe.elixir.ast.ElixirASTTransformer;
import reflaxe.elixir.ast.ElixirASTPrinter;

/**
 * ElixirOutputIterator: Handles AST to String Conversion
 * 
 * WHY: GenericCompiler returns AST nodes, but Reflaxe needs strings for file output.
 * This iterator bridges that gap by transforming and printing AST nodes to strings.
 * 
 * WHAT: Iterates through compiled AST nodes (classes, enums, etc.) and converts them
 * to properly formatted Elixir source code strings.
 * 
 * HOW: 
 * - Iterates through all compiled AST nodes from ElixirCompiler
 * - Applies transformation passes via ElixirASTTransformer
 * - Converts to strings via ElixirASTPrinter
 * - Returns DataAndFileInfo with string output for Reflaxe to write to files
 * - If bootstrap strategy is External, also emits bootstrap_<module>.ex files after
 *   module generation that load transitive dependencies in topological order and
 *   call Module.main(). This defers require generation to the final output phase
 *   for deterministic and complete loading semantics.
 * 
 * ARCHITECTURE BENEFITS:
 * - Clean separation between AST compilation and string generation
 * - Enables multi-pass transformations before final output
 * - Follows C# compiler's proven pattern
 * 
 * @see CSOutputIterator for the C# reference implementation
 */
@:access(reflaxe.elixir.ElixirCompiler)
class ElixirOutputIterator {
    /**
     * Reference to the compiler containing compiled AST nodes
     */
    var compiler: ElixirCompiler;

    /**
     * Compilation context for transformations
     */
    var context: reflaxe.elixir.CompilationContext;

    /**
     * Current position in the iteration
     */
    var index: Int;
    
    /**
     * Total number of items to iterate
     */
    var maxIndex: Int;

    // Extra outputs generated after all normal modules (e.g., bootstrap files)
    var extraOutputs: Array<DataAndFileInfo<StringOrBytes>> = [];
    var extraIndex: Int = 0;
    
    /**
     * Constructor
     * @param compiler The ElixirCompiler instance with compiled AST nodes
     */
    public function new(compiler: ElixirCompiler) {
        this.compiler = compiler;
        this.context = compiler.createCompilationContext();
        index = 0;

        // Repo emission is now scheduled during normal compilation via filterTypes + repoTransformPass.
        // No extra outputs are synthesized here.

        // Calculate total items (classes + enums + typedefs + abstracts)
        maxIndex = compiler.classes.length + 
                   compiler.enums.length + 
                   compiler.typedefs.length + 
                   compiler.abstracts.length;
        
        #if debug_output_iterator
        #if debug_output_iterator trace('[ElixirOutputIterator] Initialized with ${maxIndex} items to process'); #end
        #if debug_output_iterator trace('[ElixirOutputIterator] Classes: ${compiler.classes.length}'); #end
        #if debug_output_iterator trace('[ElixirOutputIterator] Enums: ${compiler.enums.length}'); #end
        #if debug_output_iterator trace('[ElixirOutputIterator] Typedefs: ${compiler.typedefs.length}'); #end
        #if debug_output_iterator trace('[ElixirOutputIterator] Abstracts: ${compiler.abstracts.length}'); #end
        #end

        // Prepare external bootstrap files if strategy requires it
        prepareExternalBootstraps();
    }
    
    /**
     * Check if there are more items to iterate
     * @return True if there are more items
     */
    public function hasNext(): Bool {
        return index < maxIndex || extraIndex < extraOutputs.length;
    }
    
    /**
     * Get the next item and convert it to string output
     * @return DataAndFileInfo with string output
     */
    public function next(): DataAndFileInfo<StringOrBytes> {
        // If normal items are exhausted, serve extra outputs
        if (index >= maxIndex) {
            if (extraIndex < extraOutputs.length) {
                return extraOutputs[extraIndex++];
            }
            // Should not happen if hasNext() is respected
            return new DataAndFileInfo(StringOrBytes.fromString(""), null, "", null);
        }

        // Determine which collection to pull from based on current index
        var astData: DataAndFileInfo<ElixirAST> = if (index < compiler.classes.length) {
            // Get from classes
            compiler.classes[index];
        } else if (index < compiler.classes.length + compiler.enums.length) {
            // Get from enums
            compiler.enums[index - compiler.classes.length];
        } else if (index < compiler.classes.length + compiler.enums.length + compiler.typedefs.length) {
            // Get from typedefs
            compiler.typedefs[index - compiler.classes.length - compiler.enums.length];
        } else {
            // Get from abstracts
            compiler.abstracts[index - compiler.classes.length - compiler.enums.length - compiler.typedefs.length];
        }

        index++;
        
        #if debug_output_iterator
        #if debug_output_iterator trace('[ElixirOutputIterator] Processing item ${index}/${maxIndex}'); #end
        #end
        
        // Apply transformation passes to the AST
        // The metadata from the outer AST node needs to be preserved
        // when passing to the transformer
        // Pass the context to ensure metadata is available to transformation passes
        final transformedAST = ElixirASTTransformer.transform(astData.data, context);

        #if debug_output_iterator trace('[ElixirOutputIterator] Transformation complete'); #end

        // Generic gating: suppress emission of compile-time-only empty modules
        // WHAT: Avoid generating `.ex` files for modules that have no runtime content
        // WHY: Macro-only helpers (e.g., std/ecto/*Macros, std/HXX) previously emitted empty stubs
        // HOW: Detect EDefmodule/EModule nodes with empty bodies and skip yielding output
        if (shouldSuppressEmission(transformedAST)) {
            // Recursively advance to the next item; hasNext() already reflects remaining items
            return next();
        }

        // Convert AST to string
        var output = ElixirASTPrinter.print(transformedAST, 0);

        // Debug: Check if we're getting empty output
        if (output == null || output.length == 0) { /* silent by default */ }
        
        #if debug_output_iterator trace('[ElixirOutputIterator] Generated ${output.length} characters of output'); #end
        
        // Inline-deterministic strategy: inject requires + Module.main() into the
        // module file AFTER compilation using the full dependency graph.
        //
        // WHY: Guarantees deterministic ordering (topological) and complete transitive
        // closure while keeping a single-file entrypoint (no .exs runner).
        if (ModuleBuilder.getBootstrapStrategy() == BootstrapStrategy.InlineDeterministic) {
            // Attempt to map the current BaseType back to the module name used in maps
            var moduleName: Null<String> = null;
            for (name in compiler.moduleBaseTypes.keys()) {
                if (compiler.moduleBaseTypes.get(name) == astData.baseType) {
                    moduleName = name;
                    break;
                }
            }
            if (moduleName != null && compiler.modulesWithBootstrap.indexOf(moduleName) >= 0) {
                // Compute deterministic require list using transitive closure and topo order
                var closure = computeTransitiveDependencies(moduleName);
                var topo = compiler.getSortedModules();
                var ordered: Array<String> = [];
                for (m in topo) if (closure.exists(m)) ordered.push(m);
                if (ordered.length < Lambda.count(closure)) {
                    var allKeys: Array<String> = [for (k in closure.keys()) k];
                    allKeys.sort((a, b) -> Reflect.compare(a, b));
                    ordered = allKeys;
                }
                var lines: Array<String> = [];
                for (dep in ordered) {
                    // Skip self when injecting inline
                    if (dep == moduleName) continue;
                    var p = compiler.moduleOutputPaths.get(dep);
                    if (p == null) {
                        var pack = compiler.modulePackages.get(dep);
                        p = compiler.getModuleOutputPath(dep, pack);
                    }
                    if (p != null) lines.push('Code.require_file("' + p + '", __DIR__)');
                }
                // Build final inline output: requires + module + main call
                var injected = (lines.length > 0 ? lines.join("\n") + "\n" : "")
                    + output + "\n" + moduleName + ".main()";
                // Ensure trailing newline for consistent diffs
                output = injected + "\n";
            }
        }

        // Return the same DataAndFileInfo but with string output instead of AST
        return astData.withOutput(output);
    }

    /**
     * Returns true when the transformed AST corresponds to an empty module that
     * should not be emitted as a file (compile-time-only helpers, inline-only).
     */
    static function shouldSuppressEmission(ast: ElixirAST): Bool {
        if (ast == null) return false;
        // Honor explicit metadata first
        if (ast.metadata != null) {
            // Allow any future pass to set `suppressEmission = true`
            var m: Dynamic = ast.metadata;
            try {
                // If explicitly forced to emit, never suppress
                if (Reflect.hasField(m, "forceEmit") && Reflect.field(m, "forceEmit") == true) {
                    return false;
                }
                if (Reflect.hasField(m, "suppressEmission") && Reflect.field(m, "suppressEmission") == true) {
                    return true;
                }
            } catch (_:Dynamic) {}
        }

        // Structural empty-module detection
        return switch (ast.def) {
            case EDefmodule(_, doBlock):
                switch (doBlock.def) {
                    case EBlock(exprs): exprs == null || exprs.length == 0;
                    case EDo(body): body == null || body.length == 0;
                    default: false;
                }
            case EModule(_, _, body):
                body == null || body.length == 0;
            default:
                false;
        }
    }

    /**
     * Prepare external bootstrap files when using the External strategy.
     * Aggregates dependency graph AFTER compilation for deterministic and complete requires.
     */
    function prepareExternalBootstraps(): Void {
        // Respect bootstrap strategy: only generate externals for External strategy
        if (ModuleBuilder.getBootstrapStrategy() != BootstrapStrategy.External) return;
        // Only emit scripts when explicitly requested to avoid cluttering snapshots
        #if macro
        if (!haxe.macro.Context.defined("emit_bootstrap_scripts")) return;
        #end
        if (compiler.modulesWithBootstrap.length == 0) return;

        // Build global topological order once
        var topo = compiler.getSortedModules();

        var generatedFor: Array<String> = [];
        for (moduleName in compiler.modulesWithBootstrap) {
            // Compute transitive closure for this module
            var closure = computeTransitiveDependencies(moduleName);
            // Ordered list filtered by topo
            var ordered: Array<String> = [];
            for (m in topo) if (closure.exists(m)) ordered.push(m);
            // Fallback: alpha order of closure keys if needed
            if (ordered.length < Lambda.count(closure)) {
                var allKeys: Array<String> = [for (k in closure.keys()) k];
                allKeys.sort((a, b) -> Reflect.compare(a, b));
                ordered = allKeys;
            }

            // Build bootstrap script content
            var lines: Array<String> = [];
            for (dep in ordered) {
                var filePath = compiler.moduleOutputPaths.get(dep);
                if (filePath == null) {
                    var pack = compiler.modulePackages.get(dep);
                    filePath = compiler.getModuleOutputPath(dep, pack);
                }
                if (filePath != null) {
                    lines.push('Code.require_file("' + filePath + '", __DIR__)');
                }
            }
            // Require the main module file itself
            var mainPath = compiler.moduleOutputPaths.get(moduleName);
            if (mainPath == null) {
                var pack = compiler.modulePackages.get(moduleName);
                mainPath = compiler.getModuleOutputPath(moduleName, pack);
            }
            if (mainPath != null) {
                lines.push('Code.require_file("' + mainPath + '", __DIR__)');
            }
            // Call Main.main()
            lines.push(moduleName + '.main()');

            var content = lines.join("\n");
            // Emit a separate bootstrap script to avoid colliding with module files.
            // Use a distinct name (bootstrap_<module>). Output manager will add .ex.
            var fileBase = 'bootstrap_' + NameUtils.toSnakeCase(moduleName);

            // Construct output info with override name/dir
            var baseType = compiler.moduleBaseTypes.exists(moduleName) ? compiler.moduleBaseTypes.get(moduleName) : null;
            // SAFETY: OutputManager requires a non-null BaseType for filename resolution.
            // If we cannot map a BaseType (unexpected), skip emitting the script to avoid crashes.
            if (baseType != null) {
                var data = new DataAndFileInfo<StringOrBytes>(StringOrBytes.fromString(content), baseType, fileBase, null);
                extraOutputs.push(data);
            }
            generatedFor.push(moduleName);
        }

        // No generic main file to avoid name collision with module file.
    }

    /**
     * Compute transitive dependency closure for a module using compiler.moduleDependencies
     */
    inline function computeTransitiveDependencies(root: String): Map<String, Bool> {
        var result = new Map<String, Bool>();
        var graph = compiler.moduleDependencies;
        var stack: Array<String> = [];
        var direct = graph.get(root);
        if (direct != null) for (k in direct.keys()) stack.push(k);
        while (stack.length > 0) {
            var m = stack.pop();
            if (m == null) break;
            if (m == root) continue;
            if (result.exists(m)) continue;
            result.set(m, true);
            var next = graph.get(m);
            if (next != null) for (n in next.keys()) if (!result.exists(n)) stack.push(n);
        }
        return result;
    }
}

#end
</file>

<file path="src/reflaxe/elixir/PhoenixMapper.hx">
package reflaxe.elixir;

#if (macro || reflaxe_runtime)

import haxe.macro.Context;
import haxe.macro.Type;
import haxe.macro.Expr;
// Using centralized NameUtils for name conversion
import reflaxe.elixir.ast.NameUtils;

using StringTools;
using reflaxe.helpers.NameMetaHelper;
using reflaxe.helpers.TypeHelper;

#if macro
typedef PresenceBootstrap = {
    var moduleName: String;
    var otpAppAtom: String;
    var pubsubModule: String;
}
#end

/**
 * Phoenix-specific compilation features and transformations
 * Handles context annotations, Phoenix conventions, and framework integrations
 */
@:nullSafety(Off)
class PhoenixMapper {
#if macro
    /**
     * Presence bootstrap registration captured during macro expansion.
     *
     * WHAT
     * - Records the Elixir module name plus otp_app and pubsub server for each
     *   Presence behavior so the backend can emit the tiny `use Phoenix.Presence`
     *   module automatically (instead of hand-written .ex shims).
     *
     * WHY
     * - PresenceBehavior assumes `use Phoenix.Presence` injected functions exist.
     *   When the implementation is extern, we must still generate the module.
     */
    static var presenceBootstraps: Array<PresenceBootstrap> = [];
    static var presenceEmitterRegistered: Bool = false;
#end
    
    
    /**
     * Check if a class has @:context annotation for Phoenix context generation
     */
    public static function isPhoenixContext(classType: ClassType): Bool {
        return classType.hasMeta(":context");
    }
    
    /**
     * Check if a class extends Phoenix.Controller
     */
    public static function isPhoenixController(classType: ClassType): Bool {
        if (classType.superClass == null) return false;
        var superClassName = classType.superClass.t.get().getNameOrNative();
        return superClassName.contains("Phoenix.Controller") || superClassName.contains("PhoenixController");
    }
    
    /**
     * Check if a class extends Phoenix.LiveView
     */
    public static function isPhoenixLiveView(classType: ClassType): Bool {
        if (classType.superClass == null) return false;
        var superClassName = classType.superClass.t.get().getNameOrNative();
        return superClassName.contains("Phoenix.LiveView") || superClassName.contains("PhoenixLiveView");
    }
    
    /**
     * Generate Phoenix context module structure
     * Contexts organize related functionality and follow Phoenix conventions
     */
    public static function generatePhoenixContext(classType: ClassType): String {
        var moduleName = NameUtils.getElixirModuleName(classType.getNameOrNative());
        var contextName = getPhoenixContextName(classType);
        
        var result = new StringBuf();
        result.add('defmodule ${moduleName} do\n');
        result.add('  @moduledoc """\n');
        result.add('  The ${contextName} context - Generated from Haxe @:context class\n');
        result.add('  """\n\n');
        
        // Add standard Phoenix context imports
        result.add('  import Ecto.Query, warn: false\n');
        result.add('  alias ${getRepoModuleName()}\n\n');
        
        return result.toString();
    }
    
    /**
     * Generate Phoenix controller module structure
     */
    public static function generatePhoenixController(classType: ClassType): String {
        var moduleName = NameUtils.getElixirModuleName(classType.getNameOrNative());
        
        var result = new StringBuf();
        result.add('defmodule ${moduleName} do\n');
        result.add('  use ${getAppModuleName()}Web, :controller\n\n');
        result.add('  @moduledoc """\n');
        result.add('  Phoenix Controller - Generated from Haxe\n');
        result.add('  """\n\n');
        
        return result.toString();
    }
    
    /**
     * Generate Phoenix LiveView module structure
     */
    public static function generatePhoenixLiveView(classType: ClassType): String {
        var moduleName = NameUtils.getElixirModuleName(classType.getNameOrNative());
        
        var result = new StringBuf();
        result.add('defmodule ${moduleName} do\n');
        result.add('  use ${getAppModuleName()}Web, :live_view\n\n');
        result.add('  @moduledoc """\n');
        result.add('  Phoenix LiveView - Generated from Haxe\n');
        result.add('  """\n\n');
        
        // Add standard LiveView imports
        result.add('  import Phoenix.LiveView.Helpers\n');
        result.add('  alias Phoenix.LiveView.Socket\n\n');
        
        return result.toString();
    }
    
    /**
     * Generate Ecto schema imports and aliases for Phoenix contexts
     */
    public static function generateEctoImports(): String {
        var result = new StringBuf();
        result.add('  import Ecto\n');
        result.add('  import Ecto.Changeset\n');
        result.add('  import Ecto.Query\n\n');
        return result.toString();
    }
    
    /**
     * Get Phoenix context name from class metadata or class name
     */
    public static function getPhoenixContextName(classType: ClassType): String {
        // Check for custom context name in metadata
        var contextMeta = classType.meta.extract(":context");
        if (contextMeta.length > 0 && contextMeta[0].params != null && contextMeta[0].params.length > 0) {
            switch (contextMeta[0].params[0].expr) {
                case EConst(CString(s, _)): return s;
                default:
            }
        }
        
        // Default to class name without "Context" suffix
        var className = classType.getNameOrNative();
        if (className.endsWith("Context")) {
            className = className.substr(0, className.length - 7);
        }
        return className;
    }
    
    /**
     * Get the application's Repo module name
     * Configurable via -D app_name compiler flag, defaults to MyApp.Repo
     */
    public static function getRepoModuleName(): String {
        #if app_name
        return haxe.macro.Compiler.getDefine("app_name") + ".Repo";
        #else
        return "MyApp.Repo";
        #end
    }
    
    /**
     * Get the application's main module name  
     * Configurable via -D app_name compiler flag, defaults to MyApp
     */
    public static function getAppModuleName(): String {
        var v = Context.definedValue("app_name");
        if (v == null || v == "") {
            #if debug_presence
            trace('[PhoenixMapper] getAppModuleName default=MyApp (define not set)');
            #end
            return "MyApp";
        }
        #if debug_presence
        trace('[PhoenixMapper] getAppModuleName define=' + v);
        #end
        return v;
    }
    
    /**
     * Generate Phoenix naming conventions for URLs and paths
     */
    public static function getPhoenixResourceName(className: String): String {
        // Convert UserController -> users, PostController -> posts
        var name = className;
        if (name.endsWith("Controller")) {
            name = name.substr(0, name.length - 10);
        }
        
        // Pluralize and convert to snake_case
        var snakeName = NameUtils.toSnakeCase(name);
        return pluralize(snakeName);
    }
    
    /**
     * Simple pluralization for Phoenix resource names
     */
    private static function pluralize(singular: String): String {
        // Basic English pluralization rules
        if (singular.endsWith("y")) {
            return singular.substr(0, singular.length - 1) + "ies";
        } else if (singular.endsWith("s") || singular.endsWith("sh") || singular.endsWith("ch")) {
            return singular + "es";
        } else {
            return singular + "s";
        }
    }

    #if macro
    /**
     * Register a Presence module that needs a generated `use Phoenix.Presence` stub.
     *
     * Called from PresenceMacro.build(); safe to call multiple times (dedupes).
     */
    public static function registerPresenceModule(b: PresenceBootstrap): Void {
        #if debug_presence
        trace('[PhoenixMapper] registerPresenceModule ' + b.moduleName + ' otp=' + b.otpAppAtom + ' pubsub=' + b.pubsubModule);
        #end
        for (p in presenceBootstraps) {
            if (p.moduleName == b.moduleName) return;
        }
        presenceBootstraps.push(b);

        // Delay emission until codegen; only install once.
        if (!presenceEmitterRegistered) {
            presenceEmitterRegistered = true;
            Context.onGenerate(function(_) {
                emitPresenceModules();
            });
        }
    }

    static function emitPresenceModules(): Void {
        // If compiler instance is unavailable (e.g., tests), skip quietly.
        if (reflaxe.elixir.ElixirCompiler.instance == null) {
            return;
        }

        for (p in presenceBootstraps) {
            var parts = p.moduleName.split(".");
            if (parts.length == 0) continue;
            var fileName = NameUtils.toSnakeCase(parts.pop());
            var dir = parts.map(NameUtils.toSnakeCase).join("/");
            var outputPath = (dir.length > 0 ? dir + "/" : "") + fileName + ".ex";
            #if debug_presence
            trace('[PhoenixMapper] Emitting Presence bootstrap ' + p.moduleName + ' -> ' + outputPath);
            #end
            var code = 'defmodule ${p.moduleName} do\n' +
                '  use Phoenix.Presence,\n' +
                '    otp_app: ${p.otpAppAtom},\n' +
                '    pubsub_server: ${p.pubsubModule}\n' +
                'end\n';
            reflaxe.elixir.ElixirCompiler.instance.setExtraFile(outputPath, code);
        }
    }
    #end
}

#end
</file>

<file path="AGENTS.md">
# AI/Agent Development Context for Haxe→Elixir Compiler

## 🚦 Non-Blocking Todo-App QA (Required)

Agents must never block the terminal when validating the todo-app. Use the provided QA sentinels which build, start Phoenix in the background, probe readiness, and tear down cleanly.

- Quick (repo root):
  - `npm run qa:sentinel`  → runs `scripts/qa-sentinel.sh --app examples/todo-app --port 4001`
- Async, non-blocking (returns immediately):
  - `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --async --verbose --deadline 300`
  - Prints `QA_SENTINEL_PID` and log path.
  - View logs without blocking:
    - One‑shot: `scripts/qa-logpeek.sh --run-id <RUN_ID> --last 200`
    - Bounded follow: `scripts/qa-logpeek.sh --run-id <RUN_ID> --follow 60`
    - Stop server: `kill -TERM $QA_SENTINEL_PID`
- Keep server alive for manual browsing:
  - `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --keep-alive -v`
  - Prints `PHX_PID` and `PORT`; stop with `kill -TERM $PHX_PID`.
- App-local helper (one-shot, :4000):
  - `examples/todo-app/scripts/qa-sentinel-local.sh`

What these scripts do
- Build Haxe → Elixir (`build-server.hxml`), `mix deps.get`, `mix compile` (WAE), boot `mix phx.server` in background, wait for readiness with bounded probes, curl `/`, scan logs for errors, and tear down (unless `--keep-alive`).
- All steps have timeouts with heartbeat progress lines to avoid hangs.

Always use these sentinels for runtime checks. Do not run `mix phx.server` in the foreground during agent work.

### ⛔ Hard Rule: No Sync Sentinel During Agent Work

- Agents must never invoke `scripts/qa-sentinel.sh` in synchronous mode while working in the terminal.
- Required invocation for agents: `--async` AND `--deadline <secs>` on every sentinel run.
  - Example: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --env e2e --async --deadline 600 -v`
- Log viewing must be bounded or finish‑aware only:
  - One‑shot: `scripts/qa-logpeek.sh --run-id <RUN_ID> --last 200`
  - Bounded follow: `scripts/qa-logpeek.sh --run-id <RUN_ID> --follow 60`
  - Finish‑aware follow: `scripts/qa-logpeek.sh --run-id <RUN_ID> --until-done 60`
- Prohibited during agent work:
  - Running sentinel without `--deadline`.
  - Running sentinel without `--async`.
  - Any `tail -f`, watchers, or foreground servers that do not auto‑finish.
- If a prior run may be active, terminate it first to ensure non‑blocking behavior:
  - `kill -TERM $QA_SENTINEL_PID` (or `pgrep -f qa-sentinel | xargs kill -TERM` as a fallback)
  - For Phoenix: `pgrep -f "mix phx.server" | xargs kill -TERM`

Note: CI may use synchronous mode for readability, but MUST include `--deadline` and must not exceed per‑step caps. Agents in interactive sessions must always use async.
### ⛔ Hard Rule: Commands Must Finish (No Indefinite Runs)

- Every command you invoke MUST have a clear finish condition and return control.
- Long‑running steps must be bounded by time or completion signals:
  - Wrap commands with `scripts/with-timeout.sh --secs <N>`.
  - When using the QA sentinel in `--async` mode, always provide a `--deadline <SECS>`.
  - For log viewing, prefer bounded peeks or finish‑aware follow:
    - One‑shot: `scripts/qa-logpeek.sh --run-id <RUN_ID> --last 200`
    - Bounded follow: `scripts/qa-logpeek.sh --run-id <RUN_ID> --follow 30`
    - Finish‑aware follow: `scripts/qa-logpeek.sh --run-id <RUN_ID> --until-done 60` (stops on `[QA] DONE status=` or after 60s)
- Never run unbounded watchers, tails, or foreground servers during agent work.
- If a step exceeds its cap, abort immediately, surface the last 200 lines, apply the fix in compiler/std/app Haxe (not generated .ex), then rerun under caps.

### 🔭 Optional: Playwright E2E Smoke (when server is up)

Once the sentinel reports readiness, agents may run a lightweight Playwright check to exercise critical paths without blocking the terminal:

- Start the server in the background (recommended for E2E):
  - `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --async --verbose --deadline 300`
  - Or keep it alive for manual browsing: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --keep-alive -v`
  - Inspect logs without blocking (examples):
    - `scripts/qa-logpeek.sh --file /tmp/qa-phx.log --last 200`
    - `scripts/qa-logpeek.sh --file /tmp/qa-phx.log --follow 60`

- Minimal Playwright probe (example):
  1) `npm -C examples/todo-app install --no-audit --no-fund && npx -C examples/todo-app playwright install`
  2) Save a quick test (examples/todo-app/e2e/basic.spec.ts):
     ```ts
     import { test, expect } from '@playwright/test'
     test('home + todos render', async ({ page }) => {
       const base = process.env.BASE_URL || 'http://localhost:4001'
       await page.goto(base + '/')
       await expect(page).toHaveTitle(/Todo/i)
       await page.goto(base + '/todos')
       await expect(page.locator('body')).toContainText(/Todo/i)
     })
     ```
  3) Run: `BASE_URL=http://localhost:4001 npx -C examples/todo-app playwright test e2e/basic.spec.ts`

### ✅ Testing Strategy (ExUnit in Haxe + Playwright in TS)

- ExUnit tests should be authored in Haxe and compile to idiomatic Elixir ExUnit. See docs/02-user-guide/exunit-testing.md.
- Real-browser E2E is covered with Playwright in TypeScript for now (kept small and high-value). We may convert these to Haxe later.
- Trophy over pyramid: emphasize Phoenix integration tests (LiveViewTest/ConnTest) in Haxe→ExUnit, plus a thin Playwright layer for smoke/regression.

Sentinel integration (optional):
- You can have the QA sentinel run Playwright after readiness:
  - `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --playwright --e2e-spec "e2e/*.spec.ts" --deadline 600`
  - Sentinel sets `BASE_URL` from the detected PORT and fails on Playwright errors. Keep deadlines generous for first-run browser installs.
- Current example specs:
  - `examples/todo-app/e2e/basic.spec.ts` — home + todos load
  - `examples/todo-app/e2e/search.spec.ts` — verifies search filters list and updates counter

Best‑practice notes:
- Keep Playwright specs under ~1 minute total; prefer resilient selectors (e.g., `getByPlaceholder`, `data-testid`).
- Use sentinel for lifecycle; never run `mix phx.server` in foreground.

### 🧪 QA Layers and Responsibilities

This repo exercises quality at three distinct layers. Keep them separate and use the right tool at each layer:

1) Compiler layer — Snapshot tests (Haxe → Elixir codegen)
- Location: `test/snapshot/**`
- Runs: `make -C test summary` (positive) and `make -C test summary-negative` (negative)
- Purpose: Validate AST → Elixir printer shapes and transforms deterministically. No app runtime.

2) Integration layer — Todo‑app build + boot (Compiler E2E)
- Entrypoint: `scripts/qa-sentinel.sh`
- Steps: Haxe build → mix deps.get → mix compile → boot Phoenix (background) → readiness probe → `GET /` → log scan
- Runs (examples):
  - Quick: `npm run qa:sentinel`
  - Async: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --async --deadline 300`
  - Keep alive: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --keep-alive -v`
- Purpose: Prove compiler output integrates with Phoenix correctly and runs without runtime errors.

3) Application layer — App tests (Elixir ExUnit + Playwright E2E)
- ExUnit (authored in Haxe, compiles to idiomatic Elixir tests):
  - Recommended for LiveView/ConnTest coverage; see docs/02-user-guide/exunit-testing.md
  - Keep these fast and deterministic; most UI logic belongs here (Testing Trophy).
- Playwright E2E (TypeScript, thin real‑browser layer):
  - Location: `examples/todo-app/e2e/*.spec.ts`
  - Run standalone: `BASE_URL=http://localhost:4001 npx -C examples/todo-app playwright test`
  - Run via sentinel: `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --playwright --e2e-spec "e2e/*.spec.ts" --deadline 600`
  - Purpose: Validate hydration/assets/hooks and critical user journeys cross‑browser; keep under ~1 minute.

Guidelines
- Keep Playwright checks fast and smoke-level (1–2 assertions per path).
- Always rely on the QA sentinel to boot/tear down; do not launch `mix phx.server` directly.
- When running sync sentinel, prefer `--deadline` to guarantee bounded validation.

### 🔁 E2E TDD Loop (Recommended)

Use this loop to implement/verify user-facing features end‑to‑end without coupling compiler code to app internals:

1) Write the Playwright spec first (user perspective)
- Place spec(s) under `examples/todo-app/e2e/`. Start with a minimal flow (1–3 assertions).

2) Boot the app via the QA sentinel (non‑blocking)
- Keep‑alive for manual browsing and MCP inspection:  
  `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --keep-alive -v`

3) Run the spec against the running server
- `BASE_URL=http://localhost:4001 npx -C examples/todo-app playwright test e2e/<your>.spec.ts`

4) Implement the feature/fix generically in the compiler or example app (no app‑specific name heuristics)

5) Re‑run sentinel with `--playwright`
- `scripts/qa-sentinel.sh --app examples/todo-app --port 4001 --playwright --e2e-spec "e2e/<your>.spec.ts" --deadline 600`

6) Add Haxe‑authored ExUnit integration tests (ConnTest/LiveViewTest)
- Keep most coverage here (Testing Trophy). Playwright remains a thin real‑browser layer.

7) Track everything in shrimp
- Each task must include the QA sentinel step in its verification criteria and should link the specific specs being exercised.

### 🧭 JS Client Build Guardrails (Classpath)

- For browser JS builds (e.g., `examples/todo-app/build-client.hxml`), do not add repository-level classpaths like `../../std`, `../../src`, or vendored sources directly.
- Use `-lib` to bring in libraries (e.g., `-lib genes`); their `haxe_libraries/*.hxml` files provide the correct classpaths and macros.
- Rationale: Adding repo `std/` can shadow the official Haxe std macros (e.g., `haxe.macro.Compiler`) and trigger false “missing field” errors.
- Quick check: `haxe -v build-client.hxml` should show client source paths, library paths from `haxe_libraries/`, and the official Haxe std — not the repo’s `std/`.

## 🤖 Developer Identity & Vision

**You are an experienced compiler developer** specializing in Haxe→Elixir transpilation with a mission to transform Reflaxe.Elixir into an **LLM leverager for deterministic cross-platform development**.

### ⚠️ CRITICAL: NO TEMPORARY FIXES OR BAND-AIDS ALLOWED

**FUNDAMENTAL DIRECTIVE: Never use temporary fixes, workarounds, band-aid fixes, or TODOs in production code unless they are part of a debugging process that will lead to the final proper fix.**

- **NO TODOs in production code** - Fix issues completely or don't implement
- **NO workarounds** - Solve the root architectural problem
- **NO "disable for now" comments** - Either it works properly or it doesn't exist
- **NO band-aid fixes** - Always implement the scalable, elegant solution
- **NO placeholder returns** - Don't return dummy values to "fix" infinite loops
- **NO symptom patching** - Fix the root cause, not the visible symptom
- **NO cycle breaking** - If there's an infinite loop, fix WHY it exists
- **EXCEPTION**: Temporary debug code used to understand a problem is acceptable ONLY if immediately followed by the proper fix

**Examples of Band-Aid Fixes to AVOID**:
- Returning `nil` or placeholder values to break infinite recursion
- Adding arbitrary limits to "prevent" infinite loops
- Skipping problematic nodes instead of fixing why they're problematic
- Post-processing to "clean up" bad generated code
- String replacements to "fix" incorrect output

### Core Mission
Enable developers to **write business logic once in Haxe and deploy it anywhere** while generating **idiomatic target code that looks hand-written**, not machine-generated.

### Key Principles
- **Idiomatic Code Generation**: Generated Elixir must pass human review as "natural"
- **Type Safety Without Vendor Lock-in**: Compile-time safety with deployment flexibility  
- **LLM Productivity Multiplier**: Provide deterministic vocabulary that reduces AI hallucinations
- **Framework Integration Excellence**: Deep Phoenix/Ecto/OTP integration, not just language compatibility
- **Framework-Agnostic Architecture**: Support any Elixir application pattern (Phoenix, Nerves, pure OTP) without compiler assumptions
- **⚠️ API Faithfulness**: Follow Elixir and Phoenix APIs exactly - never invent functions that don't exist. Provide Haxe conveniences via proper overloads, not fake APIs
- **Hand-Written Quality**: Generated code should look like it was written by an Elixir expert, not a machine
- **Transparent Bridge Variables**: When compiler-generated variables are needed (like `g` for switch expressions), add comments explaining their purpose
- **🔥 Pragmatic Stdlib Implementation**: Use `__elixir__()` for efficient native stdlib - [see Standard Library Philosophy](#standard-library-philosophy--pragmatic-native-implementation)

### No-Dynamic Policy (Hard Rule)
- Do not introduce `Dynamic` types in new compiler code, stdlib externs, or tests unless absolutely unavoidable at boundary integration points.
- Prefer precise types in Haxe signatures and Elixir outputs. Avoid using `Dynamic` as a workaround for typing mismatches.
- If a type mismatch occurs during a transform, fix the transform to produce correctly typed Elixir (and adjust Haxe signatures) instead of widening to `Dynamic`.
- Snapshot tests must be strictly typed: do not change return types to `Dynamic` to placate compilation; correct the logic or test inputs instead.
- Exceptions (must be documented):
  - External APIs that are inherently dynamic (e.g., Map-like payloads) may use `Dynamic` locally, but public surfaces should remain typed.
  - Transitional refactors require an issue and a TODO linked to the proper fix — not allowed for 1.0 scope.

## Code Style and Conventions

- Prefer clear, descriptive names over abbreviations.
- Keep functions short and focused; extract helpers when a block grows complex.
- Avoid magic numbers and stringly-typed logic; prefer enums/typedefs and small helpers.
- Do not leak target-specific runtime details into the Haxe types unless strictly required by shape.

### Variable Naming (Hard Rules)

- Use descriptive variable names. Avoid cryptic abbreviations (e.g., `fq`, `fn`, `args`) unless they are canonical API terms.
- Never introduce numeric suffixes to disambiguate variables (e.g., `moduleName2`, `qualifiedModule2`, `func2`, `args2`).
  - Pattern-matching cases have their own scopes — reuse the same descriptive names in each case.
  - If distinct names improve clarity, pick different descriptive names (e.g., `callModule`, `captureModule`).
- Prefer small helpers over ad‑hoc inline conditionals when logic repeats.

Examples

- Bad
  - `var qualifiedModule2 = (moduleName2 == "Presence") ? (app + "Web.Presence") : (app + "." + moduleName2);`
  - `case ECall({def: EVar(moduleName2)}, functionName2, argumentList2) …`

- Good
  - `var qualifiedModule = qualifyAppLocalModule(moduleName, appPrefix);`
  - `case ECall({def: EVar(moduleName)}, functionName, argumentList) …`

## 📚 Complete Documentation Index

**All documentation is organized in [`docs/`](docs/) - Always check here first for comprehensive information.**

### 🚀 Quick Navigation by Task Type

#### **New to Reflaxe.Elixir?**
→ **[docs/01-getting-started/](docs/01-getting-started/)** - Installation, quickstart, project setup
- [Installation Guide](docs/01-getting-started/installation.md) - Complete setup with troubleshooting
- [Development Workflow](docs/01-getting-started/development-workflow.md) - Day-to-day practices

#### **Building Applications?**
→ **[docs/02-user-guide/](docs/02-user-guide/)** - Complete application development guide
→ **[docs/07-patterns/](docs/07-patterns/)** - Copy-paste ready code patterns
- [Quick Start Patterns](docs/07-patterns/quick-start-patterns.md) - Essential copy-paste patterns

#### **Working on the Compiler?**
→ **[docs/03-compiler-development/](docs/03-compiler-development/)** - Specialized compiler development context
- [Compiler Development AGENTS.md](docs/03-compiler-development/AGENTS.md) - **AI context for compiler work**
- [Architecture Overview](docs/03-compiler-development/architecture.md) - How the compiler works
- [Testing Infrastructure](docs/03-compiler-development/testing-infrastructure.md) - Snapshot testing system

#### **Need Technical Reference?**
→ **[docs/04-api-reference/](docs/04-api-reference/)** - Technical references and API docs
→ **[docs/05-architecture/](docs/05-architecture/)** - System design documentation
→ **[`__elixir__()` Usage](#standard-library-philosophy--pragmatic-native-implementation)** - Native Elixir code injection for stdlib

#### **Troubleshooting Problems?**
→ **[docs/06-guides/troubleshooting.md](docs/06-guides/troubleshooting.md)** - Comprehensive problem solving

## 🔗 Shared AI Context (Import System)

@docs/claude-includes/compiler-principles.md
@docs/claude-includes/testing-commands.md
@docs/claude-includes/code-style.md
@docs/claude-includes/framework-integration.md

## 🏗️ Compilation Pipeline Architecture (AST-BASED DEFAULT)

**⚠️ CRITICAL REMINDER: AST PIPELINE IS DEFAULT - DO NOT LOOK AT OLD STRING CODE**

**The AST-based pipeline (src/reflaxe/elixir/ast/) is the DEFAULT compilation path.**
- When debugging issues, ALWAYS check ElixirASTBuilder.hx, ElixirASTPrinter.hx, ElixirASTTransformer.hx
- The compiler uses a pure AST pipeline - all compilation goes through AST generation
- ALL compilation methods return ElixirAST nodes that are transformed and printed

### 1. Primary AST-Based Pipeline (DEFAULT ✅)
- Three-phase: TypedExpr → ElixirAST → Transformations → String
- Strongly-typed intermediate representation
- Enables powerful optimizations and idiomatic code generation
- **ALL NEW DEVELOPMENT USES THIS PIPELINE**
- **Files**: ElixirASTBuilder.hx, ElixirASTPrinter.hx, ElixirASTTransformer.hx

## Runtime Artifacts — Source-of-Truth Rule (Hard)

- Do not edit generated runtime files to change behavior. Never patch compiled Elixir files:
  - Repo root/runtime shims and any `*.ex` such as: `reflect.ex`, `std.ex`, `string_buf.ex`, `type.ex`, `int_iterator.ex`
  - Snapshot outputs under `test/snapshot/**/out/**/*.ex`
- Make all behavior changes in the source-of-truth instead:
  - Standard library Haxe sources: `std/_std/*.hx` and `std/*.cross.hx`
  - Compiler pipeline: `src/reflaxe/elixir/ast/**` (Builder → Transformer → Printer)
- Only edit a `.ex` under `std/` directly if it is explicitly documented as the canonical runtime source (no corresponding `.hx` exists). If unsure, assume it is generated and fix upstream.
- Example: Reflect.compare/2 — do not touch `reflect.ex`; change `std/_std/Reflect.hx` (or `std/Reflect.cross.hx`) and re-run snapshots.
- No band-aids: Do not “clean up” outputs or add runtime-only conditionals to mask upstream issues. Fix the transform or std source.
- Pre-merge checks for std/behavior fixes:
  - `rg` should show diffs only in `std/_std/*.hx`, `std/*.cross.hx`, or `src/reflaxe/elixir/**`.
  - No diffs to `reflect.ex`, `std.ex`, `string_buf.ex`, `type.ex`, `int_iterator.ex`, or `test/snapshot/**/out/**` unless accompanied by matching upstream `.hx` changes and a note explaining why the `.ex` is canonical.
- Temporary runtime edits for debugging are allowed only if clearly annotated “DEBUG ONLY” and removed in the same PR after the proper upstream fix lands.

**⚠️ ARCHITECTURAL UPDATE: Complete Migration to AST Pipeline (August 2025)**
- **The compiler now extends GenericCompiler<ElixirAST>** - Pure AST-based architecture
- **The AST pipeline is the ONLY compilation path** - Everything goes through it
- **All functionality is AST-based** - No string concatenation for code generation
- **ADDING NEW FEATURES**: Create a transformation pass in ElixirASTTransformer
- **See**: [`docs/05-architecture/AST_PIPELINE_MIGRATION.md`](docs/05-architecture/AST_PIPELINE_MIGRATION.md) - Complete migration documentation
- Example: Schema compilation → schemaTransformPass in ElixirASTTransformer

**WHY AST-BASED IS CRITICAL**: The AST architecture enables sophisticated transformations impossible with strings:
- **Inheritance → Delegation**: Transform `super.method()` to Elixir module delegation (no inheritance in Elixir!)
- **Self → Struct Parameter**: Convert `this/self` references to proper struct parameters
- **Pattern Optimization**: Detect and optimize complex patterns (loops → comprehensions)
- **Context-Aware Transforms**: Use metadata for intelligent decisions (parent class info, etc.)
- **Multi-Pass Optimization**: Sequential transformation passes that build on each other


### Debug Flags for AST Pipeline
```bash
# Debug AST pipeline transformations
npx haxe build.hxml -D debug_ast_pipeline -D debug_ast_transformer

# Debug specific transformation passes
npx haxe build.hxml -D debug_otp_child_spec -D debug_pattern_matching
```

## ⚠️ CRITICAL: Compiler Optimization Flags - DO NOT USE `-D analyzer-optimize`

**FUNDAMENTAL RULE: NEVER use `-D analyzer-optimize` when compiling Haxe to Elixir.**

### Why This is Critical
The `-D analyzer-optimize` flag triggers Haxe's aggressive optimizations designed for imperative targets like C++ and JavaScript. These optimizations **destroy idiomatic Elixir patterns** and produce verbose, non-functional code.

### What Goes Wrong with `-D analyzer-optimize`
1. **Loop Unrolling**: Converts `for (i in 0...3)` into three sequential statements instead of `Enum.each`
2. **Constant Folding**: Evaluates expressions like `n * 2` at compile-time, losing the original calculation
3. **Pattern Destruction**: Breaks functional patterns that are core to Elixir's philosophy

### Example of the Damage
```haxe
// Haxe source
for (i in 0...3) {
    trace('Item: ' + i);
}

// WITH -D analyzer-optimize (WRONG - verbose, non-idiomatic)
Log.trace("Item: 0", ...)
Log.trace("Item: 1", ...)
Log.trace("Item: 2", ...)

// WITHOUT -D analyzer-optimize (CORRECT - idiomatic Elixir)
Enum.each(0..2, fn i -> 
  Log.trace("Item: #{i}", ...)
end)
```

### Recommended Compiler Configuration
```hxml
# ✅ GOOD optimizations
-dce full                    # Dead code elimination (removes unused code)
-D loop_unroll_max_cost=10   # Reasonable loop unrolling limit

# ❌ NEVER use these
# -D analyzer-optimize       # Destroys functional patterns
# -D analyzer-check          # May trigger unwanted optimizations
```

### Philosophy
**For Elixir, optimize for humans, not machines.** The BEAM VM handles performance optimization at runtime. Our job is to generate **readable, maintainable, idiomatic Elixir code** that looks hand-written by an expert.

**See**: [`docs/01-getting-started/compiler-flags-guide.md`](docs/01-getting-started/compiler-flags-guide.md) - Complete compiler flags documentation

## 📐 Transformer Documentation Directive (hxdoc required)

When you create or modify AST transformers (Builder → Transformer → Printer pipeline):

- Always add hxdoc block comments to the transformer with the following sections:
  - WHAT: Concise description of the transformation and its scope
  - WHY: The problem it solves and the architectural rationale
  - HOW: High-level explanation of the algorithm and where it runs in the pipeline
  - EXAMPLES: Minimal Haxe input → Generated Elixir before/after

Example hxdoc template:

"""
/**
 * MyTransformPass
 *
 * WHAT
 * - Converts while→reduce_while loop patterns to idiomatic Enum.each.
 *
 * WHY
 * - Preserve functional style; avoid mutable loop artifacts in Elixir.
 *
 * HOW
 * - Detect Enum.reduce_while with Stream.iterate(0, fn n -> n + 1 end) and rewrite to
 *   Enum.each(range, fn i -> ... end), preserving side effects and accumulator semantics.
 *
 * EXAMPLES
 * Haxe:
 *   for (i in 0...3) trace(i);
 * Elixir (before):
 *   Enum.reduce_while(Stream.iterate(0, fn n -> n + 1 end), {0}, fn _, {i} -> ... end)
 * Elixir (after):
 *   Enum.each(0..2, fn i -> IO.puts(i) end)
 */
"""

- Keep each transformer file under 2000 LOC. If approaching the limit, extract into domain modules.
- Add focused snapshots where output semantics change; include intended/ regression coverage.
- Follow idiomatic Phoenix/Ecto/OTP patterns; never introduce fake APIs.

### New Entities Documentation Policy (Required)

- Document every new compiler entity thoroughly at creation time. This applies to:
  - Transformers, builder helpers, printer rules, analyzers, macros, passes, and shims
  - Any new public types/externs in std/phoenix/ecto or vendor surfaces we expose
- Each entity must include hxdoc (or module-level doc) with:
  - WHAT: Concise description and exact scope/guards (shape/API-based)
  - WHY: Architectural rationale and the concrete problem it solves
  - HOW: High-level algorithm, where it runs in the pipeline, and ordering assumptions
  - EXAMPLES: Minimal Haxe input → before/after Elixir output (focused on changed shape)
- Cross-reference tests: note the snapshot(s) that cover the change and intended behavior
- Note limitations and non-goals explicitly to prevent scope creep and name heuristics
- Keep docs in-source (hxdoc) and, when cross-cutting, add a short pointer in `docs/03-compiler-development/`

### Hard Rule: No App-Specific Name Heuristics

- Never key transforms on variable names, atoms, tags, or strings tied to examples/domains (e.g., "todo", "updated_todo", "toggle_todo", "cancel_edit", "presenceSocket", "live_socket").
- Never add suffix/prefix name-based rules (e.g., mapping FooSocket→socket). This is application coupling and violates portability.
- Allowed renames must be:
  - Shape-derived (based on AST structure, not names), or
  - Proven equivalence (snake_case of an existing binding), or
  - Usage-driven within a clause and unambiguous (exactly one undefined body var).
- Framework allowances are strictly API- and shape-based (e.g., AppWeb.* → App.Repo via module name parts), never domain terms.

Checklist before merging a transform:
- [ ] No literal checks for example app names or variables
- [ ] No name-suffix/prefix heuristics unless deriving snake_case to an existing binding
- [ ] Pass explains WHAT/WHY/HOW in hxdoc and includes generic examples
- [ ] Grep check: `rg -n "todo_|toggle_todo|cancel_edit|presenceSocket|live_socket|updated_todo" src/` returns zero in logic (docs are allowed)

## ⚠️ CRITICAL: Target-Conditional Classpath Architecture (January 2025 Discovery)

**FUNDAMENTAL ARCHITECTURAL ISSUE**: The current `.cross.hx` staging mechanism is flawed - it makes Elixir-specific code available in ALL compilation contexts (macro, interp, etc.) when it should ONLY be available when compiling to Elixir target.

### The Problem
When .cross.hx files containing `__elixir__()` calls are staged to the classpath:
- They become available during macro evaluation (fails with "Unknown identifier: __elixir__")
- They're available when compiling to other targets (JavaScript, etc.)
- They override standard Haxe implementations in ALL contexts

### The Correct Architecture (How Mature Reflaxe Compilers Work)
**Target-conditional classpath injection** - Standard library overrides should ONLY be added to the classpath when actually compiling to the target platform:

```haxe
// In CompilerInit.hx or bootstrap macro
public static function Start() {
    // ONLY add Elixir-specific paths when target is Elixir
    if (Context.definedValue("target.name") == "elixir") {
        // Add staged .cross.hx files to classpath
        Compiler.addClassPath("std/_std/");
    }
    // Macro context and other targets use regular Haxe stdlib
}
```

### Why This Matters
1. **Macro context uses regular Haxe stdlib** - No __elixir__() failures
2. **Other targets unaffected** - JavaScript compilation doesn't see Elixir-specific code
3. **Clean separation** - Target-specific code only available when needed
4. **Matches hxcpp pattern** - This is how mature Reflaxe compilers handle it

### Current Workaround (Temporary)
The staging mechanism works but requires all contexts to handle Elixir-specific code:
- `std/_std/` contains staged .cross.hx files
- `haxe_libraries/reflaxe.elixir.hxml` includes them unconditionally
- This causes "Unknown identifier: __elixir__" in macro context

### Implementation (Complete)
Classpath gating is implemented in `CompilerInit.Start()`:
- Adds `std/_std/` only when compiling to Elixir target.
- Haxe 5: gated by `CustomTarget("elixir")`.
- Haxe 4: gated by `target.name == "elixir"` or presence of `-D elixir_output`.
- `haxe_libraries/reflaxe.elixir.hxml` no longer unconditionally includes `std/_std/`.

Activation scenarios:
- Elixir builds in tests/examples (`-D elixir_output`) → activated
- Custom target Elixir (Haxe 5) → activated
- JS/genes builds, macro-only tools → not activated

See: `docs/05-architecture/TARGET_CONDITIONAL_STDLIB_GATING.md` for details and verification steps.

**Reference Implementations**:
- hxcpp: Conditionally adds C++ stdlib based on target
- reflaxe.cs: Adds C# paths only during C# compilation

## 🎯 Phoenix Idiomatic Patterns with Type-Safe Augmentation

**FUNDAMENTAL PRINCIPLE: Generate idiomatic Phoenix/Elixir code, augmented with Haxe's type safety.**

### Core Philosophy: "Idiomatic Haxe for Elixir"
- **Phoenix patterns first**: Use standard Phoenix patterns and conventions as the foundation
- **Type safety on top**: Add Haxe's compile-time guarantees without changing the runtime patterns
- **Don't reinvent**: If Phoenix has an established pattern, use it - don't create a "Haxe way"
- **Augment intelligently**: Only deviate from Phoenix patterns when type safety provides clear value
- **Phoenix app in Haxe**: The todo-app should be a standard Phoenix app, just written in Haxe
- **Minimal deviation**: Only differ from Phoenix patterns when it provides type safety or better ergonomics
- **Recognize the patterns**: An Elixir developer should immediately recognize all Phoenix patterns

### Examples of Idiomatic Phoenix with Haxe Benefits

#### ✅ GOOD: Phoenix Presence with Type Safety
```haxe
// Haxe: Type-safe metadata, but standard Phoenix Presence pattern
typedef PresenceMeta = {
    var onlineAt: Float;
    var userName: String;
    var editingTodoId: Null<Int>;  // Phoenix pattern: single presence with state
}

// Generates standard Phoenix Presence usage:
// Presence.track(socket, "users", user_id, %{
//   online_at: System.system_time(),
//   user_name: user.name,
//   editing_todo_id: nil
// })
```

#### ❌ BAD: Over-Engineering with Nested Structures
```haxe
// Don't create complex nested structures that Phoenix doesn't use natively
var editingUsers: Map<Int, Map<String, PresenceEntry>>;  // Too complex!
```

#### ✅ GOOD: LiveView Socket Assigns
```haxe
// Type-safe assigns that compile to standard Phoenix patterns
typedef TodoLiveAssigns = {
    var todos: Array<Todo>;        // Standard Phoenix: socket.assigns.todos
    var currentUser: User;         // Standard Phoenix: socket.assigns.current_user
}
```

#### ✅ GOOD: PubSub with Type Safety
```haxe
// Type-safe topics and messages, but standard Phoenix.PubSub underneath
enum PubSubTopic {
    TodoUpdates;  // Compiles to "todo:updates"
}
// Still uses Phoenix.PubSub.subscribe/broadcast normally
```

### When to Augment vs When to Follow

**Follow Phoenix Exactly**:
- Router DSL structure
- LiveView lifecycle (mount/handle_event/handle_info)
- Presence tracking patterns
- PubSub topic conventions
- Ecto changeset flow
- Controller/action patterns

**Augment with Type Safety**:
- Event parameters (typed instead of maps)
- Socket assigns structure (compile-time validation)
- Message types (enums instead of atoms)
- Form validation (typed changesets)
- API contracts (typed structs)

### The Litmus Test
Ask yourself: "Would an experienced Phoenix developer recognize this pattern?"
- If YES → You're doing it right
- If NO → You might be over-engineering

The goal is that generated Elixir code should be **indistinguishable from hand-written Phoenix code**, just with compile-time type guarantees that Phoenix developers wish they had.

## 🌐 Full-Stack Development with genes (JavaScript Generation)

**REVOLUTIONARY CAPABILITY**: Reflaxe.Elixir now includes **genes** - a modern ES6 JavaScript generator that enables writing entire Phoenix applications (backend AND frontend) in pure Haxe with complete type safety.

### Why genes Integration is Game-Changing

The addition of genes transforms Reflaxe.Elixir from a backend-only compiler into a **full-stack development platform**:

1. **Single Language, Multiple Targets**: Write once in Haxe, compile to both Elixir (backend) and JavaScript (frontend)
2. **Shared Type Definitions**: Define types once, use them on both server and client - no API drift
3. **Modern ES6 Output**: Clean async/await, modules, arrow functions - production-ready JavaScript
4. **Phoenix LiveView Integration**: Type-safe hooks, client-side components, and JavaScript interop
5. **Future Cross-Platform Components**: Components that compile to both LiveView (server) and React-like (client)

### genes Architecture & Integration

**Location**: `vendor/genes/` - Vendored and modified for async/await support

**Key Modifications**:
- **Async Function Detection**: Recognizes `__async_marker__` pattern and generates native `async` keyword
- **Await Expression Handling**: Transforms `js.Syntax.code("await {0}", promise)` to clean `await` expressions
- **Metadata Support**: Full support for `@:async` and `@:await` inline metadata

### Using genes for Client-Side JavaScript

#### Configuration (build-client.hxml)
```hxml
# JavaScript target with modern ES6 via genes
-lib reflaxe
-lib genes
-js assets/js/app.js

# ES6 modules and optimizations
-D js-unflatten
-D analyzer-optimize
--dce=full

# Main entry point
client.TodoApp
```

#### Clean Async/Await Support

**Haxe Source** (using AsyncMacro):
```haxe
@:build(genes.AsyncMacro.build())
class ClientApp {
    static function main() {
        // Clean async function with @:async metadata
        var fetchUser = @:async function(id: Int) {
            var response = @:await fetch('/api/users/$id');
            var data = @:await response.json();
            return data;
        };
        
        // Multiple awaits in sequence
        var processData = @:async function() {
            var user = @:await fetchUser(1);
            var posts = @:await fetchPosts(user.id);
            var comments = @:await fetchComments(posts);
            return {user: user, posts: posts, comments: comments};
        };
    }
}
```

**Generated JavaScript** (clean ES6):
```javascript
class ClientApp {
    static main() {
        let fetchUser = async function(id) {
            let response = await fetch(`/api/users/${id}`);
            let data = await response.json();
            return data;
        };
        
        let processData = async function() {
            let user = await fetchUser(1);
            let posts = await fetchPosts(user.id);
            let comments = await fetchComments(posts);
            return {user: user, posts: posts, comments: comments};
        };
    }
}
```

### Powerful Abstraction Possibilities

#### 1. Shared Business Logic
```haxe
// shared/Validation.hx - Compiles to BOTH Elixir and JavaScript
class Validation {
    public static function validateEmail(email: String): Bool {
        var pattern = ~/^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        return pattern.match(email);
    }
    
    public static function validateAge(age: Int): Bool {
        return age >= 18 && age <= 120;
    }
}

// Used in Elixir (server-side validation)
@:schema class User {
    function changeset(attrs) {
        if (!Validation.validateEmail(attrs.email)) {
            addError("email", "Invalid email format");
        }
    }
}

// Used in JavaScript (client-side validation)  
class SignupForm {
    function validateForm() {
        if (!Validation.validateEmail(emailInput.value)) {
            showError("Invalid email");
            return false;
        }
    }
}
```

#### 2. Type-Safe API Contracts
```haxe
// shared/ApiTypes.hx - Single source of truth
typedef UserRequest = {
    name: String,
    email: String,
    age: Int
}

typedef UserResponse = {
    id: Int,
    name: String,
    email: String,
    createdAt: Date
}

// Elixir controller uses the types
@:controller
class UserController {
    function create(params: UserRequest): UserResponse {
        // Type-safe handling
    }
}

// JavaScript client uses THE SAME types
class UserClient {
    @:async function createUser(data: UserRequest): Promise<UserResponse> {
        var response = @:await fetch('/api/users', {
            method: 'POST',
            body: JSON.stringify(data)
        });
        return @:await response.json();
    }
}
```

#### 3. Universal Components (Future Vision)
```haxe
// Universal component that compiles to both LiveView and React
@:universal
class TodoItem {
    var id: Int;
    var text: String;
    var completed: Bool;
    
    // Compiles to LiveView component (Elixir)
    @:target("elixir")
    function render() {
        return HXX.hxx('
            <div class={if completed "completed" else ""}>
                <input type="checkbox" checked={completed} phx-click="toggle" phx-value-id={id}/>
                <span>{text}</span>
            </div>
        ');
    }
    
    // Compiles to React-like component (JavaScript)
    @:target("javascript")  
    function render() {
        return JSX.jsx('
            <div className={completed ? "completed" : ""}>
                <input type="checkbox" checked={completed} onChange={() => toggle(id)}/>
                <span>{text}</span>
            </div>
        ');
    }
}
```

### Phoenix LiveView Hooks with Type Safety

```haxe
// client/hooks/InfiniteScroll.hx
@:build(genes.AsyncMacro.build())
class InfiniteScrollHook {
    public var el: Element;
    public var pushEvent: (String, Dynamic) -> Promise<Dynamic>;
    
    public function mounted() {
        var observer = new IntersectionObserver(@:async (entries) -> {
            if (entries[0].isIntersecting) {
                var page = parseInt(el.dataset.page) + 1;
                var result = @:await pushEvent("load-more", {page: page});
                // Type-safe handling of server response
            }
        });
        observer.observe(el);
    }
}

// Compiles to clean JavaScript for Phoenix hooks
```

### Integration with Phoenix Assets Pipeline

The generated JavaScript integrates seamlessly with Phoenix's esbuild pipeline:

```javascript
// assets/js/app.js - Generated by genes
import {TodoApp} from "./TodoApp.js"
import {InfiniteScrollHook} from "./hooks/InfiniteScrollHook.js"

// Phoenix LiveView integration
let Hooks = {
    InfiniteScroll: InfiniteScrollHook
}

let liveSocket = new LiveSocket("/live", Socket, {hooks: Hooks})
liveSocket.connect()

// Initialize Haxe app
TodoApp.main()
```

### Development Workflow

1. **Backend Development** (Elixir generation):
   ```bash
   npx haxe build-server.hxml  # Compiles to Elixir
   mix compile                  # Validates Elixir code
   ```

2. **Frontend Development** (JavaScript generation):
   ```bash
   npx haxe build-client.hxml   # Compiles to JavaScript via genes
   npm run deploy               # Bundles with esbuild
   ```

3. **Full-Stack Watch Mode**:
   ```bash
   # Terminal 1: Watch backend
   mix compile.haxe --watch
   
   # Terminal 2: Watch frontend  
   npx haxe build-client.hxml --watch
   
   # Terminal 3: Run Phoenix
   mix phx.server
   ```

### Future Possibilities with genes

1. **Isomorphic Rendering**: Same component renders on server (LiveView) and client (JavaScript)
2. **Shared State Management**: Type-safe state synchronization between server and client
3. **Progressive Enhancement**: Start with server-rendered, progressively add client features
4. **Type-Safe GraphQL**: Generate both schema (Elixir) and client (JavaScript) from Haxe types
5. **Cross-Platform Testing**: Test business logic once, runs on both platforms

### Technical Implementation Details

**The AsyncMacro Pattern**: Instead of complex AST manipulation, genes uses a marker variable approach:
1. AsyncMacro injects `var __async_marker__ = true;` into async functions
2. genes' ExprEmitter detects this marker and generates `async` keyword
3. Clean ES6 output without wrapper functions or runtime overhead

**Why Not Default Haxe→JS?**: 
- Default Haxe JavaScript can generate older ES5 patterns
- genes specifically targets modern ES6+ with modules, async/await, arrow functions
- Better integration with modern bundlers (esbuild, webpack, vite)
- Cleaner output that looks hand-written

### Summary

The genes integration transforms Reflaxe.Elixir into a **complete full-stack development platform**. Developers can now:
- Write entire Phoenix applications in pure Haxe
- Share types and business logic between frontend and backend
- Get compile-time type safety across the entire stack
- Generate clean, modern, production-ready JavaScript and Elixir

This is not just about convenience - it's about **eliminating entire categories of bugs** (API drift, type mismatches, validation inconsistencies) through compile-time guarantees across the full stack.

## 📦 Vendor Modification Policy

**⚠️ CRITICAL DIRECTIVE: Reflaxe source CAN be modified IF NEEDED, but as a LAST RESORT**

You have permission to modify vendored dependencies (Reflaxe, genes) when necessary, but follow these guidelines:

### When to Modify Vendor Source
- ✅ **Bug fixes** that block functionality with no workaround
- ✅ **Critical features** for Elixir idioms that can't be achieved via extension
- ✅ **Integration problems** where vendor architecture doesn't fit Elixir's needs
- ❌ **Avoid** when you can extend via inheritance or AST transformations
- ❌ **Avoid** when you can work around with metadata flags

### Documentation Requirements
**MANDATORY** for every vendor modification:
1. **File header comment** explaining the modification with WHY/WHAT/DATE
2. **Inline comments** marking modification boundaries
3. **Changelog entry** in `vendor/CHANGELOG.md`

### The Decision Flow
```
Issue with vendor code → Can I fix in compiler? → YES → Fix in compiler
                      ↓ NO
                      Can I fix in AST pipeline? → YES → Fix in transformer
                      ↓ NO
                      Is this fundamental? → YES → Modify vendor (document WHY)
```

**See**: [`vendor/AGENTS.md`](vendor/AGENTS.md) - Complete vendor modification policy and guidelines

## 🚀 Essential Commands

### Development Workflow
```bash
# Build and test (with CORRECT flags - no analyzer-optimize!)
npm test                                 # Full test suite (mandatory before commit)
mix assets.build && mix compile --force  # Compile client+server
mix phx.server                           # Run Phoenix application (watchers on)

# Integration testing (example app)
cd examples/todo-app && mix assets.build && mix compile
curl http://localhost:4000               # Test application response

# Dev convenience (example app)
cd examples/todo-app && mix dev          # setup + start with watchers

# ⚠️ IMPORTANT: Never add -D analyzer-optimize to build commands
# It destroys idiomatic Elixir patterns. Use -dce full instead.
```

### Run Servers in Background (Agents)

- Never block the terminal with long‑running servers during agent work. Always start them in the background, capture logs, and ensure teardown.
- Recommended pattern (background + readiness + teardown):
  ```bash
  # Start (background) and capture PID
  MIX_ENV=dev mix phx.server >/tmp/qa-phx.log 2>&1 &
  PHX_PID=$!
  trap 'kill $PHX_PID >/dev/null 2>&1 || true' EXIT

  # Wait until ready
  for i in $(seq 1 60); do
    curl -fsS http://localhost:4000 >/dev/null 2>&1 && break
    sleep 0.5
  done

  # Interact with the app here (tests, Playwright, etc.)
  ```
- Prefer `scripts/qa-sentinel.sh` when possible — it already starts Phoenix in the background, probes readiness, and tears down cleanly.
- If a port is already in use, terminate the listener first (e.g., via `lsof -ti tcp:4000 | xargs -r kill -9`) before starting a new server.

## 🧭 Architecture Lessons From Live QA (Elixir/Phoenix)

- Prefer source-of-truth fixes over late transforms.
  - Builder-level general rules beat app-specific transformer passes.
  - Example: Rewrite local field assignment `params.userId = v` at AST-build time to `params = Map.put(params, "user_id", v)` rather than a narrow, late transform.

- Normalize at stdlib boundaries, not in user code.
  - The Ecto `Changeset.new` bridge should accept mixed input shapes and normalize to schema types (snake_case keys, split comma-separated tags, parse integers) before `cast/3`.
  - Keep this logic generic and framework-faithful; avoid project-specific rewrites.

- Keep the pass registry lean; transformers are not a hammer.
  - Use transformers for semantic/idiomatic Elixir rewrites with broad applicability (e.g., struct immutability, comprehension conversions), not for app business rules.
  - If a pass smells app-specific, move the behavior to:
    - AST Builder (shape-driven, target-agnostic), or
    - std externs (typed, API-faithful boundary adapters).

- Variable naming discipline is non-negotiable.
  - No cryptic abbreviations (`sp`, `fn`, `fq`) and no numeric suffixes (`sp2`, `qualifiedModule2`).
  - Use descriptive names everywhere, including inside injected Elixir snippets: e.g., `snake_params`, `normalized_params`.

- QA loop: gate + browser flows.
  - Always run `scripts/qa-sentinel.sh` to validate build + runtime (WAE) before browser tests.
  - Use Playwright MCP to drive add/toggle/delete/search; capture console logs and server logs.
  - Start servers in background and ensure teardown between runs to avoid port conflicts and stale sessions.

- Phoenix alignment first, then augmentation.
  - Follow Phoenix/Ecto APIs exactly; add type-safety and normalization in typed externs rather than introducing synthetic APIs or app-only passes.


### Mix Integration (Server + Client)

- Server compiler: `Mix.Tasks.Compile.Haxe` integrates Haxe→Elixir into `mix compile`.
- Client build (example app): handled by Phoenix assets tasks and dev watchers.
  - Dev: a watcher runs `haxe build-client.hxml --wait` and esbuild bundles `assets/js/phoenix_app.js`.
  - Build: `mix assets.build` (Haxe client + tailwind + esbuild)
  - Deploy: `mix assets.deploy` (Haxe client + tailwind + esbuild + digest)

Constraints
- Do not add `-D analyzer-optimize` to any HXML. It breaks idiomatic Elixir/JS generation.
- JS client public surfaces must be typed (No‑Dynamic policy). Use `js.Syntax.code` only at the boundary (e.g., within LiveView hook methods) and keep typedefs precise.

### Quick Testing
```bash
# Category-based testing (NEW - much faster iteration!)
npm run test:core                          # Run core language tests only
npm run test:stdlib                        # Run standard library tests
npm run test:regression                    # Run regression tests
npm run test:phoenix                       # Run Phoenix framework tests
npm run test:changed                       # Run only tests affected by git changes
npm run test:failed                        # Re-run only failed tests from last run

# Pattern-based testing
scripts/test-runner.sh --pattern "*array*" # Run all array-related tests
scripts/test-runner.sh --pattern "*date*"  # Run all date-related tests

# Traditional commands (still work)
make -C test test-core__arrays             # Specific test (use __ for path separator)
make -C test update-intended TEST=arrays   # Accept new output
MIX_ENV=test mix test                      # Runtime validation

# Advanced test runner
scripts/test-runner.sh --help              # Show all available options
scripts/test-runner.sh --category core --parallel 8  # Run core tests with 8 jobs
scripts/test-runner.sh --changed --update  # Update tests affected by changes
```

### Advanced Debugging
```bash
# Enable macro stack traces for complex compiler issues
npx haxe build-server.hxml -D eval-stack -D debug_enum_introspection_compiler

# Profile compilation performance
npx haxe build-server.hxml -D eval-times

# Maximum debug visibility for AST issues
npx haxe build-server.hxml -D eval-stack -D debug_pattern_matching -D debug_expression_variants

# Interactive debugging support
npx haxe build-server.hxml -D eval-debugger
```

## AGENTS.md Maintenance Rule ⚠️
This file must stay under 40k characters for optimal performance.
- Keep only essential agent instructions  
- Use imports from `docs/claude-includes/` for shared content
- Move detailed content to appropriate [docs/](docs/) sections
- Reference docs instead of duplicating content
- Review size after major updates: `wc -c AGENTS.md`

## Style Discipline: Eliminate Per-Branch Duplication

- Prefer a single helper + single local variable across symmetric switch branches.
  - Anti‑pattern: `used` and `used2`, `newName` and `newName2` in `PVar` vs `PAlias` arms doing the same logic.
  - Pattern: extract a small inline helper (e.g., `isUsed(name)`, `normalizedBinder(name)`) and use one local (e.g., `nn`) in both branches.
  - Rationale: reduces cognitive load, avoids divergence/bugs when one branch is updated, keeps transforms maintainable and deterministic.
  - Constraint: keep logic shape-/usage-based; never couple to app/domain names. No special cases like `todo`, `id`, etc.
  - Scope: applies to all transformers, analyzers, and builders.


## Naming Rule: Ban Ambiguous Numeric Suffixes

- Never name identifiers with bare numeric suffixes to signal variants or arity (e.g., `parseX2`, `scan2`, `helper3`).
  - Rationale: Numeric suffixes hide intent, confuse maintenance, and accumulate silently across passes.
  - Scope: Functions, methods, classes, modules, fields, and local helper functions in production compiler code.
- Use explicit, intention-revealing names instead:
  - Arity: prefer `ArityTwo`, `ArityThree` as a middle token (e.g., `parseHandleEventArityTwoCaseDispatch`).
  - Variant/role: prefer semantic tokens like `InDo`, `ForKeyword`, `PredicateBody`, `ScanBlock`, `Debug`.
- Exceptions (allowed):
  - External API names where numbers are part of the official API (e.g., `atan2`, `log10`, `to_iso8601`).
  - Test-only, throwaway debug snippets guarded by defines and removed prior to release.
- Hygiene gate: PRs adding identifiers that match `/[A-Za-z_]\w*\d+$/` must refactor to descriptive names or justify under the exceptions.


## Transformer Scope Discipline

- Prefer shape- and usage-based transforms. Do not gate transforms by module/app names (e.g., "Web.", ".Live", ".Presence") unless:
  - The module carries an explicit annotation (e.g., @:liveview, @:schema), or
  - The transform positively detects a framework/API usage pattern (e.g., Phoenix.Presence.list/track/update) and operates only where that usage exists.
- Never couple to application-specific identifiers. Use structural guards and body-usage checks (e.g., promote {:ok, _x} → {:ok, x} only when x is referenced in the clause body).
- Framework-specific passes must be API-scoped, not name-scoped. Avoid brittle heuristics based on module naming.
- All new/modified transformers must include hxdoc (WHAT/WHY/HOW/EXAMPLES) and explicitly state scope/guards.
- QA: add grep gates to flag literal name heuristics in transformers (e.g., `/Web\.|\.Live|\.Presence/`) unless justified by annotations/API shape.

### ❌ NEVER Add Detailed Technical Content to Root AGENTS.md
When documenting new features, fixes, or insights:
1. **Use the nearest AGENTS.md** - Save insights and directives to the nearest AGENTS.md dir-wise (e.g., `src/reflaxe/elixir/ast/AGENTS.md` for AST issues)
2. **Create or update appropriate docs** in `docs/` directory for general documentation
3. **Add only a brief reference** in root AGENTS.md with link to full documentation  
4. **Check character count** before and after: `wc -c AGENTS.md`
5. **If over 40k**, identify and move non-essential content to subdirectory AGENTS.md files

### 📍 AGENTS.md Hierarchy
- **Root AGENTS.md** (`/AGENTS.md`) - Project-wide conventions, navigation, critical rules only
- **Module AGENTS.md** (`src/reflaxe/elixir/AGENTS.md`) - Compiler-specific development guidance
- **Component AGENTS.md** (`src/reflaxe/elixir/ast/AGENTS.md`) - AST-specific patterns and limitations
- **Test AGENTS.md** (`test/AGENTS.md`) - Testing infrastructure and patterns
- **Example AGENTS.md** (`examples/todo-app/AGENTS.md`) - Application-specific patterns

## 🧹 Dead Code and Deprecated Logic Removal

- Prefer deletion over deactivation: remove deprecated/disabled passes and unused helpers instead of keeping them commented or permanently disabled.
- Justification: less code surface reduces maintenance, avoids drift, and prevents accidental re‑enablement; git history preserves removed code if it’s ever needed again.
- Exception: keep short‑lived debug scaffolding only when it immediately leads to a proper fix, and remove it as the fix lands.
- When removing:
  - Eliminate all references (transformer registry entries, docs, comments).
  - Note the decision briefly in the commit message and relevant module AGENTS.md if non‑obvious.

## 📁 Project Directory Structure Map

**CRITICAL FOR NAVIGATION**: This follows standard Reflaxe compiler conventions (like Reflaxe.CPP):

### Directory Purpose & Separation of Concerns

```
haxe.elixir/                          # Project root (Reflaxe convention)
├── src/                              # 🔧 COMPILER SOURCE (macro-time code)
│   └── reflaxe/elixir/               # The actual transpiler implementation
│       ├── ElixirCompiler.hx         # Main compiler extending GenericCompiler<ElixirAST>
│       └── ast/                      # AST builder, transformer, and printer
├── std/                              # 📚 STANDARD LIBRARY (compile-time classpath)
│   ├── elixir/                       # Elixir stdlib externs (IO, File, etc.)
│   ├── phoenix/                      # Phoenix framework externs  
│   └── ecto/                         # Ecto ORM externs
├── lib/                              # 🏃 ELIXIR RUNTIME (Mix integration)
│   ├── haxe_compiler.ex              # Mix task for compilation
│   ├── haxe_watcher.ex               # File watcher for development
│   └── haxe_server.ex                # Haxe compilation server wrapper
├── docs/                             # 📚 ALL DOCUMENTATION
│   ├── 01-getting-started/           # Setup and quickstart
│   ├── 02-user-guide/                # Application development
│   ├── 03-compiler-development/      # Compiler contributor docs (with AGENTS.md)
│   ├── 04-api-reference/             # Technical references
│   ├── 05-architecture/              # System design
│   ├── 06-guides/                    # How-to guides and troubleshooting
│   ├── 07-patterns/                  # Copy-paste code patterns
│   ├── 08-roadmap/                   # Vision and planning
│   ├── 09-history/                   # Historical records
│   └── 10-contributing/              # Contribution guidelines
├── test/                              # 🧪 Compiler snapshot tests
├── examples/                          # 📝 Example applications
│   └── todo-app/                     # Main integration test & showcase
│       └── src_haxe/                  # User application code in Haxe
└── extraParams.hxml                  # Configures -cp src and -cp std
```

### Why This Structure (Reflaxe Convention)

1. **`src/`** - Contains the compiler itself (macro-time code that runs during Haxe compilation)
   - This is where ElixirCompiler.hx lives - the actual transpiler
   - Only exists at macro-time, not in generated output

2. **`std/`** - Standard library included in classpath (`-cp std` in extraParams.hxml)
   - Provides Haxe externs for Elixir/Phoenix/Ecto functionality
   - Available to all user code during compilation
   - Similar to how Reflaxe.CPP has `std/` for C++ standard library

3. **`lib/`** - Elixir runtime support (specific to our Mix integration)
   - Contains .ex files for Mix tasks and compilation support
   - These are actual Elixir files needed to integrate with Mix build system
   - Not part of Haxe compilation, but needed for Elixir project to work

4. **`src_haxe/`** - User application code (in examples)
   - This is where users write their Haxe code
   - Gets compiled to Elixir via the transpiler
   - Separate from compiler source to avoid confusion

**Key Locations for Common Tasks**:
- **Compiler bugs**: `src/reflaxe/elixir/` (macro-time transpiler code)
- **Standard library**: `std/` (externs and framework integration)
- **Mix integration**: `lib/*.ex` (Elixir runtime support)
- **Integration testing**: `examples/todo-app/`
- **Documentation**: `docs/` (ALL documentation)
- **Snapshot tests**: `test/snapshot/`

## IMPORTANT: Agent Execution Instructions
1. **ALWAYS verify docs/ first** - All documentation is in the organized docs/ structure
2. **USE THE DIRECTORY MAP** - Navigate correctly using the structure above
3. **Check recent commits** - Run `git log --oneline -20` to understand recent work patterns
4. **Use specialized AGENTS.md** - Check [docs/03-compiler-development/AGENTS.md](docs/03-compiler-development/AGENTS.md) for compiler work
5. **FOLLOW DOCUMENTATION GUIDE** - See [docs/](docs/) for comprehensive guides
6. **Check Haxe documentation** when needed:
   - https://api.haxe.org/ - Latest API reference
   - https://haxe.org/manual/ - Language documentation

## Critical Architecture Knowledge for Development

**MUST READ BEFORE WRITING CODE**:
- **[docs/03-compiler-development/](docs/03-compiler-development/)** - Complete compiler development guide
- **[docs/03-compiler-development/macro-time-vs-runtime.md](docs/03-compiler-development/macro-time-vs-runtime.md)** - THE MOST CRITICAL CONCEPT
- **[docs/05-architecture/](docs/05-architecture/)** - Complete architectural details

**Key Insight**: Reflaxe.Elixir is a **macro-time transpiler**, not a runtime library. All transpilation happens during Haxe compilation.

## ⚠️ CRITICAL: NEVER EDIT GENERATED FILES

**FUNDAMENTAL RULE: NEVER EDIT GENERATED .ex FILES DIRECTLY. ALL FIXES MUST BE IN THE COMPILER SOURCE.**

**What counts as a generated file violation:**
- ❌ **Editing any .ex file** in `lib/` directories of examples
- ❌ **Manual fixes** to generated Elixir code to "make it work"
- ❌ **Patching output** instead of fixing the generator
- ❌ **Quick fixes** in generated files "just to test"
- ❌ **Any modification** to files created by the transpiler

**The correct approach:**
- ✅ **Fix the compiler source** in `src/reflaxe/elixir/`
- ✅ **Modify Haxe source** in `src_haxe/` if it's user code
- ✅ **Update AST builder/transformer** to generate correct code
- ✅ **Fix root cause** even if it takes longer
- ✅ **Test via regeneration** - delete and regenerate files to verify

**Why this matters:**
- Generated files are **overwritten on every compilation**
- Manual edits are **immediately lost**
- It **violates the entire purpose** of the transpiler
- Fixing symptoms instead of causes **perpetuates bugs**

## ⚠️ CRITICAL: NEVER DELETE FILES MANUALLY - USE NPM SCRIPTS ONLY

**FUNDAMENTAL RULE: NEVER manually delete .ex files with rm, find, or any other command. ALWAYS use the designated npm script.**

### The ONLY Way to Clean Generated Files:
```bash
npm run clean:generated  # ✅ CORRECT - Uses _GeneratedFiles.json manifest to precisely remove only compiler-generated files
```

### NEVER Do This:
```bash
rm -rf lib/*.ex                           # ❌ WRONG - Deletes critical runtime files
find . -name "*.ex" -delete               # ❌ WRONG - Deletes everything
cd examples/todo-app && rm lib/*.ex       # ❌ WRONG - No discrimination
```

### How It Works:
The `clean:generated` script uses the `_GeneratedFiles.json` manifest created by the compiler:
1. **Reads the manifest** - Each compilation creates `_GeneratedFiles.json` listing all generated files
2. **Deletes only listed files** - Only removes files explicitly marked as compiler-generated
3. **Preserves everything else** - All hand-written files are automatically safe

### What Gets Preserved (Automatically):
- `lib/haxe_compiler.ex` - Haxe compilation support (not generated)
- `lib/haxe_server.ex` - Compilation server (not generated)
- `lib/haxe_watcher.ex` - File watcher (not generated)
- `lib/mix/tasks/*.ex` - Mix tasks (not generated)
- `config/*.exs` - Configuration files (not generated)
- `priv/**/*.exs` - Migrations and seeds (not generated)
- Any file NOT in `_GeneratedFiles.json`

### What Gets Deleted:
- Only files listed in `_GeneratedFiles.json` manifests
- Test output files in `test/snapshot/*/out/`
- Nothing else - the script is surgically precise

### Why This Critical Rule Exists:
- **Accidental deletion of lib/*.ex breaks Mix integration** - The :haxe compiler disappears
- **These files were deleted multiple times** - Git history shows repeated restoration
- **Manual rm commands don't discriminate** - They delete hand-written runtime support
- **The clean:generated script uses a whitelist** - It knows exactly what to preserve

## ⚠️ CRITICAL: NO BAND-AID FIXES EVER

**FUNDAMENTAL RULE: NEVER USE POST-PROCESSING OR BAND-AID FIXES. ALWAYS FIX THE ROOT CAUSE.**

**What counts as a band-aid fix:**
- ❌ **Post-processing filters** to clean up bad output after generation
- ❌ **String manipulation** to fix generated code issues  
- ❌ **Workarounds** that patch symptoms instead of fixing the cause
- ❌ **"Quick fixes"** that add complexity without solving the underlying issue
- ❌ **Conditional patches** for specific edge cases without understanding why they occur

**The correct approach:**
- ✅ **Understand WHY the issue happens** - Find the exact compilation step causing problems
- ✅ **Fix at the source** - Modify the compiler logic that generates the problematic code
- ✅ **Test the root fix** - Ensure the underlying problem is completely resolved
- ✅ **Comprehensive solution** - Fix should work for all similar cases, not just the specific instance

**Example of wrong vs right approach:**
```haxe
// ❌ WRONG: Band-aid fix
var result = patternMatchingCompiler.compile(...);
result = cleanupOrphanedVariables(result); // Post-processing patch
return result;

// ✅ RIGHT: Root cause fix  
// Modify the pattern matching compiler itself to not generate orphaned variables
// by detecting empty case bodies and avoiding parameter extraction
```

**Remember**: If you're adding a "cleanup" step, you're probably doing it wrong. Fix the generator, not the output.

## ⚠️ CRITICAL: Predictable Pipeline Architecture - No Logic Bypassing Logic

**FUNDAMENTAL RULE: THE COMPILER MUST HAVE A PREDICTABLE, LINEAR PIPELINE WITH SINGLE RESPONSIBILITY PER PHASE.**

**What counts as unpredictable architecture:**
- ❌ **Multiple detection paths** for the same pattern (builder detecting AND transformer detecting)
- ❌ **Transformations in builder phase** - Builder should ONLY build AST nodes
- ❌ **Building in transformer phase** - Transformer should ONLY transform existing nodes  
- ❌ **Bypass routes** where some code paths skip transformation entirely
- ❌ **Conditional transformation** based on where/when code is compiled
- ❌ **Logic bypassing logic** - Adding more detection layers to fix missed transformations

**The correct pipeline architecture:**
- ✅ **Linear phases**: TypedExpr → Builder → Transformer → Printer (no shortcuts)
- ✅ **Single responsibility**: Each phase does ONE thing well
- ✅ **Metadata-driven**: Builder marks nodes with metadata, transformer reads metadata
- ✅ **No bypasses**: ALL code goes through ALL phases, no exceptions
- ✅ **Predictable behavior**: Same input ALWAYS produces same output regardless of context

**Example of wrong vs right architecture:**
```haxe
// ❌ WRONG: Multiple detection and transformation in wrong phase
// In ElixirASTBuilder.hx:
case TCall(e, el):
    if (isEnumConstructor(e)) {
        var transformed = applyTransformation(...); // Transformation in builder!
        return transformed;
    }

// In ElixirASTTransformer.hx:
if (detectEnumPattern(node)) { // Second detection path!
    return transform(node);
}

// ✅ RIGHT: Single responsibility, metadata-driven
// In ElixirASTBuilder.hx:
case TCall(e, el):
    if (isEnumConstructor(e)) {
        var node = buildEnumNode(e, el);
        node.metadata.isIdiomaticEnum = true; // ONLY mark metadata
        return node;
    }

// In ElixirASTTransformer.hx:
if (node.metadata?.isIdiomaticEnum == true) { // ONLY check metadata
    return applyIdiomaticTransformation(node);
}
```

**Why predictable pipeline matters:**
- **Debugging**: Can trace exactly where transformations happen
- **Maintenance**: Clear separation of concerns makes changes safer
- **Performance**: No redundant detection or missed optimizations
- **Correctness**: No edge cases where transformations are skipped
- **Testing**: Can test each phase independently

**Pipeline Phase Responsibilities:**

1. **Builder Phase (ElixirASTBuilder)**:
   - ONLY builds AST nodes from TypedExpr
   - ONLY sets metadata flags for semantic meaning
   - NEVER transforms or modifies structure
   - NEVER makes decisions about final output format

2. **Transformer Phase (ElixirASTTransformer)**:
   - ONLY transforms existing AST nodes
   - ONLY reads metadata to make decisions
   - NEVER creates new detection logic
   - NEVER builds nodes from scratch

3. **Printer Phase (ElixirASTPrinter)**:
   - ONLY converts AST to strings
   - NEVER transforms structure
   - NEVER makes semantic decisions
   - ONLY handles formatting and syntax

**Remember**: When you find yourself adding another detection layer to catch missed cases, you're creating unpredictable architecture. Step back and fix the pipeline structure instead.

## ⚠️ CRITICAL: Use Reflaxe's Established Architecture Patterns

**FUNDAMENTAL RULE: NEVER INVENT AD-HOC DETECTION SYSTEMS. USE REFLAXE'S ESTABLISHED PATTERNS.**

**What counts as ad-hoc architectural deviation:**
- ❌ **Custom detection systems** when Reflaxe provides standard solutions
- ❌ **Hardcoded pattern matching** instead of using metadata systems
- ❌ **Timing-dependent fixes** that rely on compilation order assumptions
- ❌ **Context-specific workarounds** that don't scale to other use cases

**The Reflaxe way:**
- ✅ **Use Reflaxe's preprocessor system** - MarkUnusedVariablesImpl for unused variable detection
- ✅ **Check established metadata** - Look for `-reflaxe.unused` instead of inventing detection
- ✅ **Follow GenericCompiler patterns** - Extend established base class methods
- ✅ **Study reference implementations** - Check `/haxe.elixir.reference/reflaxe/` for patterns

**LESSON LEARNED: Orphaned Variable Detection**
When we encountered orphaned `g_array` variables:
- ❌ **WRONG**: Invented custom `isParameterTrulyOrphaned()` detection
- ❌ **WRONG**: Made assumptions based on compilation timing
- ✅ **RIGHT**: Use Reflaxe's `MarkUnusedVariablesImpl` + `-reflaxe.unused` metadata
- ✅ **RIGHT**: Check existing VariableCompiler patterns that already handle this metadata

**Example of architectural alignment:**
```haxe
// ❌ WRONG: Ad-hoc detection
private function isParameterTrulyOrphaned(ef: EnumField, index: Int): Bool {
    // Custom logic based on assumptions...
}

// ✅ RIGHT: Use Reflaxe metadata system
if (tvar.meta != null && tvar.meta.has("-reflaxe.unused")) {
    return ""; // Skip generation - Reflaxe preprocessor marked this as unused
}
```

**Remember**: Reflaxe is a mature framework. If you're inventing something from scratch, check if Reflaxe already provides it.

## ⚠️ CRITICAL: Favor Composition Over Inheritance in Reflaxe Compilers

**FUNDAMENTAL RULE: IMPLEMENT ONLY REQUIRED ABSTRACT METHODS. LET REFLAXE ORCHESTRATE THE FLOW.**

**What counts as inheritance overuse:**
- ❌ **Overriding compileExpression** when you only need compileExpressionImpl
- ❌ **Intercepting parent methods** that manage the compilation pipeline
- ❌ **Breaking injection mechanisms** by overriding orchestration methods
- ❌ **Duplicating parent logic** with super calls that add no value
- ❌ **Fighting the framework** instead of working with it

**The composition approach:**
- ✅ **Implement compileExpressionImpl** - The abstract method Reflaxe requires
- ✅ **Trust parent orchestration** - GenericCompiler handles injection, hooks, etc.
- ✅ **Let Reflaxe manage flow** - Don't intercept unless adding specific value
- ✅ **Compose behaviors** - Add functionality through delegation, not overriding
- ✅ **Respect the pipeline** - Each phase has clear responsibilities

**Example of wrong vs right approach:**
```haxe
// ❌ WRONG: Overriding orchestration method
public override function compileExpression(expr: TypedExpr, topLevel: Bool = false): Null<String> {
    // This breaks parent's injection handling!
    return compileExpressionViaAST(expr, topLevel);
}

// ✅ RIGHT: Implement only the required abstract method
public function compileExpressionImpl(expr: TypedExpr, topLevel: Bool): Null<String> {
    // Let parent handle orchestration, we just provide implementation
    return compileExpressionViaAST(expr, topLevel);
}
```

**Why this matters:**
- **Framework integration**: Reflaxe features (like injection) work correctly
- **Maintainability**: Less coupling with parent implementation details
- **Clarity**: Clear separation between orchestration and implementation
- **Future-proofing**: Parent class improvements automatically benefit us

**Remember**: GenericCompiler is a mature orchestrator. Trust it to manage the compilation flow while you focus on Elixir-specific implementation.

## ⚠️ CRITICAL: NO ENUM-SPECIFIC HARDCODING EVER

**FUNDAMENTAL RULE: NEVER HARDCODE SPECIFIC ENUM NAMES OR TYPES IN COMPILER LOGIC. ALWAYS USE GENERAL PATTERNS.**

**What counts as enum-specific hardcoding:**
- ❌ **Hardcoded enum names** like `if (ef.name == "TypeSafeChildSpec")` in compiler logic
- ❌ **Constructor-specific switches** like `switch(ef.name) { case "Repo": ...; case "Telemetry": ...; }`
- ❌ **Parameter index hardcoding** for specific enum constructors
- ❌ **Type-specific workarounds** that only work for particular enum definitions
- ❌ **Field-specific transformations** like `if (key == "strategy")` for supervisor options
- ❌ **Maintenance nightmares** that require updating compiler code when enums change

**The correct approach:**
- ✅ **Detect patterns, not names** - Analyze AST structure and usage patterns
- ✅ **Context-aware detection** - Use compilation context to determine parameter usage
- ✅ **General algorithms** - Write code that works for ANY enum with similar patterns
- ✅ **AST analysis** - Look at actual usage in the AST, not hardcoded type assumptions

**Example of wrong vs right approach:**
```haxe
// ❌ WRONG: Hardcoded enum-specific logic
var orphaned = switch(ef.name) {
    case "Repo": index == 0;      // Hardcoded!
    case "Telemetry": index == 0; // Hardcoded!
    case "Endpoint": index == 1;  // Hardcoded!
    case _: false;
};

// ✅ RIGHT: General pattern detection
var orphaned = isParameterUnusedInCurrentContext(e, ef, index);
// Uses AST analysis to detect unused parameters regardless of enum type
```

**Why this matters:**
- **Maintenance**: Adding new enums shouldn't require compiler changes
- **Generalization**: The compiler should work for user-defined enums, not just stdlib
- **Architectural integrity**: Type-specific logic belongs in type definitions, not the compiler
- **Future-proofing**: Enum definitions will evolve - the compiler should adapt automatically

**Remember**: If you're checking specific enum names in the compiler, you're creating technical debt that will break when enums change.

## ⚠️ CRITICAL: Abstract Types Require `extern inline` for `__elixir__` Injection

**FUNDAMENTAL RULE: Abstract type methods that use `untyped __elixir__()` MUST be declared as `extern inline`.**

### The Problem (Discovered After Extensive Debugging)
When using `untyped __elixir__()` in abstract type methods without `extern inline`:
```haxe
// ❌ FAILS with "Unknown identifier: __elixir__"
abstract LiveSocket<T>(...) {
    public function clearFlash(): LiveSocket<T> {
        return untyped __elixir__('Phoenix.LiveView.clear_flash({0})', this);
    }
}
```

### The Solution
```haxe
// ✅ WORKS: extern inline allows __elixir__ to work
abstract LiveSocket<T>(...) {
    extern inline public function clearFlash(): LiveSocket<T> {
        return untyped __elixir__('Phoenix.LiveView.clear_flash({0})', this);
    }
}
```

### Why This Happens (Critical Understanding)
1. **Abstract methods are typed early**: When an abstract is imported, its methods are typed
2. **`__elixir__` doesn't exist yet**: Reflaxe injects `__elixir__` AFTER Haxe's typing phase
3. **Timing mismatch**: The identifier is checked before it exists
4. **`extern inline` delays typing**: The function body is only typed at call sites, after Reflaxe init

### Why Regular Classes Don't Have This Problem
- Regular class methods aren't forced to be typed immediately
- They can contain `untyped __elixir__()` without `extern inline`
- Exception: Classes with `@:coreApi` get special treatment (like Array.hx)

### The Universal Rule
**For ANY abstract type using `untyped __elixir__()`:**
- ✅ ALWAYS use `extern inline` on methods with `__elixir__`
  - **WHY**: The combination delays typing until the method is actually called, after Reflaxe has injected `__elixir__`
- ✅ This ensures the code is typed AFTER Reflaxe initialization
  - **WHY**: By the time the inlined code is expanded at call sites, `__elixir__` exists
- ❌ NEVER use just `public function` - it will fail
  - **WHY**: Regular functions in abstracts are typed immediately when the abstract is imported, before `__elixir__` exists
- ❌ NEVER use just `inline` - must be `extern inline`
  - **WHY**: `inline` alone still types the function body during abstract processing. `extern` is what prevents early typing

### Lesson Learned
We spent significant time debugging "Unknown identifier: __elixir__" errors in LiveSocket.hx.
The root cause was abstract methods being typed before Reflaxe could inject the `__elixir__` identifier.
This is now documented to prevent future time waste on the same issue.

**See**: [`std/phoenix/LiveSocket.hx`](std/phoenix/LiveSocket.hx) - Working implementation with detailed documentation

## ⚠️ CRITICAL: Comprehensive Documentation Rule for ALL Compiler Code

**FUNDAMENTAL RULE: Every piece of compiler logic MUST include comprehensive documentation and XRay debug traces.**

### The Five Mandatory Elements:
1. **Class-Level HaxeDoc with WHY/WHAT/HOW** - Comprehensive class purpose and architecture documentation
2. **Function-Level WHY/WHAT/HOW Documentation** - Explain reasoning, purpose, and implementation
3. **XRay Debug Traces** - Provide runtime visibility with `#if debug_feature` blocks
4. **Pattern Detection Visibility** - Show what patterns are detected and why
5. **Edge Case Documentation** - Document known limitations and special handling

### 1. Class-Level HaxeDoc Requirements (NEW MANDATE)

**ALL compiler classes MUST have comprehensive class-level documentation following the WHY/WHAT/HOW pattern:**

```haxe
/**
 * CLASS_NAME: Brief class purpose
 * 
 * WHY: Explain the problem this class solves and architectural decisions
 * - What problem in compiler design this addresses
 * - Why this separation/extraction was needed
 * - What happens if this class doesn't exist
 * - How it fits into overall compiler architecture
 * 
 * WHAT: High-level class responsibilities and capabilities
 * - Primary operations and transformations
 * - Key patterns handled or generated
 * - Integration points with other compiler components
 * - Public API surface and usage patterns
 * 
 * HOW: Implementation approach and internal architecture
 * - Key algorithms and data structures used
 * - Major internal methods and their responsibilities
 * - Collaboration patterns with other classes
 * - Extension points and future considerations
 * 
 * ARCHITECTURE BENEFITS:
 * - Single Responsibility: Clear separation of concerns
 * - Open/Closed Principle: Extension without modification
 * - Testability: Independent testing capabilities
 * - Maintainability: Clear boundaries and interfaces
 * - Performance: Optimized for specific use cases
 * 
 * EDGE CASES:
 * - Known limitations and workarounds
 * - Special handling requirements
 * - Integration complexity points
 * - Future improvement areas
 * 
 * @see documentation/RELATED_ARCHITECTURE.md - Related patterns and designs
 */
@:nullSafety(Off)
class CompilerClass {
    // Implementation...
}
```

**Example**: See `VariableCompiler.hx` for a complete implementation of this pattern.

### Example Template:
```haxe
/**
 * FEATURE NAME: Brief description
 * 
 * WHY: Problem being solved and rationale
 * WHAT: High-level operation description  
 * HOW: Step-by-step implementation details
 * EDGE CASES: Special scenarios and limitations
 */
function compilerFunction() {
    #if debug_feature
    trace("[XRay Feature] OPERATION START");
    trace('[XRay Feature] Input: ${input.substring(0, 100)}...');
    #end
    
    // Implementation with visibility
    
    #if debug_feature
    trace("[XRay Feature] ✓ PATTERN DETECTED");
    trace("[XRay Feature] OPERATION END");
    #end
}
```

**See**: [`docs/03-compiler-development/COMPREHENSIVE_DOCUMENTATION_STANDARD.md`](docs/03-compiler-development/COMPREHENSIVE_DOCUMENTATION_STANDARD.md) - Complete documentation standards and XRay patterns

## ⚠️ CRITICAL: File Size and Maintainability Standards

**FUNDAMENTAL RULE: Large files are maintenance debt and MUST be refactored.**

### File Size Guidelines (Based on Reflaxe Reference Implementations)

| File Type | Target Size | Maximum Size | Current State |
|-----------|-------------|--------------|---------------|
| **Utility Classes** | 100-300 lines | 500 lines | ✅ Most helpers good |
| **Helper Compilers** | 300-800 lines | 1,200 lines | ✅ Most helpers good |
| **Main Compiler** | 800-1,500 lines | 2,000 lines | ❌ **ElixirCompiler.hx: 10,661 lines!** |
| **Complex Compilers** | 1,000-2,000 lines | 2,500 lines | Expression compilation |

### ⚠️ MANDATORY REFACTORING TRIGGERS

A file MUST be refactored when:
- [ ] Size exceeds maximum guidelines (ElixirCompiler.hx is 5x too large!)
- [ ] Multiple responsibilities are mixed (loops + expressions + patterns + utilities)
- [ ] Changes frequently break unrelated functionality  
- [ ] Debugging requires scrolling through thousands of lines
- [ ] New developers struggle to understand the file

### ⚠️ CRITICAL: Avoid String Concatenation in Macro Blocks (Compiler Bug)

**CONTEXT**: When compilation output is redirected (`> /dev/null 2>&1`), such as in test runners and CI pipelines

**PROBLEMATIC PATTERNS**: String concatenation (`+` operator) and StringBuf operations in `#if (macro || reflaxe_runtime)` blocks cause Haxe compiler to hang

**SAFE ALTERNATIVES**:
- ✅ **String interpolation** (PREFERRED): Works without issues
- ✅ **Array join pattern**: Also safe
- ✅ **Single string literals**: No concatenation needed

**CHECK BEFORE COMMITTING**:
- If your macro code will run in CI/test contexts with output redirection
- Search for `+` concatenation with strings in `#if macro` blocks
- Search for `new StringBuf()` in `#if macro` blocks  
- Replace with string interpolation or array join

**Symptoms**:
- Compilation hangs indefinitely with redirected output  
- Works fine without output redirection
- Even 5 string concatenations trigger the hang
- Affects Make-based test runner and CI pipelines

**Problematic Patterns** (in contexts with output redirection):
```haxe
// ❌ CAUSES HANG when output is redirected
return 'line1\n' +
       'line2\n' +
       'line3\n';

// ❌ StringBuf ALSO CAUSES HANG  
var sb = new StringBuf();
sb.add("line1\n");
sb.add("line2\n");
```

**Safe Solutions**:
```haxe
// ✅ BEST: String interpolation (clean and safe)
return '
defmodule ${name} do
  use Ecto.Migration
  def change do
    # ${comment}
  end
end';

// ✅ ALSO SAFE: Array join pattern
var lines = [
    'defmodule ${name} do',
    '  use Ecto.Migration',
    'end'
];
return lines.join('\n');
```

### Single Responsibility Principle

Each file should have **one clear reason to change**:

✅ **GOOD Examples**:
- `LoopCompiler.hx` - Only handles loop compilation and optimization
- `PatternDetector.hx` - Only detects AST patterns  
- `CompilerUtilities.hx` - Only provides shared utility functions

❌ **BAD Examples**:
- `ElixirCompiler.hx` (current) - Handles loops, expressions, patterns, utilities, types, etc.

### Refactoring Standards

**Every extraction must include**:
- Complete HaxeDoc for all functions
- **⚠️ MANDATORY WHY/WHAT/HOW documentation** - Every new class, entity, or code must comprehensively justify its existence with WHY (problem being solved), WHAT (responsibilities and capabilities), HOW (implementation approach)
- XRay debug traces for compilation functions
- Single responsibility focus
- Test coverage to prevent regressions

**Validation**: `npm test && cd examples/todo-app && npx haxe build-server.hxml && mix compile`

## Framework-Agnostic Design Pattern ✨ **ARCHITECTURAL PRINCIPLE**

**CRITICAL RULE**: The compiler generates plain Elixir by default. Framework conventions are applied via annotations, not hardcoded assumptions.

### Design Philosophy
```haxe
// ✅ CORRECT: Framework conventions via annotations
@:native("AppNameWeb.TodoLive")  // Explicit Phoenix convention
@:liveview
class TodoLive {}

// ❌ WRONG: Hardcoded framework detection in compiler
if (isPhoenixProject()) {
    moduleName = appName + "Web." + className;  // Compiler assumption
}
```

## 🎯 Elixir Language Semantics - Compiler Must Understand

**CRITICAL KNOWLEDGE**: A robust Haxe→Elixir compiler must deeply understand Elixir's language semantics, reserved words, scoping rules, and idioms.

### Complete List of Elixir Reserved Keywords
The compiler MUST avoid using these as variable/function names:

**Core Reserved Words**:
- `true`, `false`, `nil` - Boolean/null atoms
- `and`, `or`, `not`, `in`, `when` - Operators
- `fn` - Anonymous function definition
- `do`, `end`, `catch`, `rescue`, `after`, `else` - Block delimiters
- `__MODULE__`, `__FILE__`, `__DIR__`, `__ENV__`, `__CALLER__` - Special forms

### Variable Scoping & Rebinding Rules

**Immutability vs Rebinding**:
- **Data is immutable**: Lists, maps, structs never change
- **Variables can rebind**: Variables can point to new data
- **NOT mutation**: `x = x + 1` creates new binding, doesn't mutate

**Scoping Principles**:
```elixir
# Outer scope
x = 1

# Inner scope (anonymous function)
result = Enum.map([1, 2, 3], fn item ->
  x = 2  # Creates NEW local x, doesn't affect outer x
  item * x
end)

# x is still 1 here
```

**Pin Operator (^)**:
```elixir
x = 1
^x = 2  # MatchError - tries to match 2 against existing value 1
x = 2   # Rebinding - x now points to 2
```

### Variable Shadowing Hazards

**The compiler must handle**:
1. **Nested scopes**: Inner variables shadow outer ones
2. **Case/cond clauses**: Each clause has its own scope
3. **Comprehensions**: Variables in generators are local
4. **With expressions**: Each clause can rebind

### Module Naming Conflicts

**Built-in Elixir modules the compiler MUST NOT override**:
- `List`, `Map`, `Enum`, `String`, `Integer`, `Float`
- `Process`, `GenServer`, `Supervisor`, `Agent`
- `File`, `IO`, `Path`, `System`
- `Code`, `Kernel`, `Module`, `Application`

### Elixir Idioms the Compiler Should Generate

**Pattern Matching over Conditionals**:
```elixir
# ✅ Idiomatic
case result do
  {:ok, value} -> process(value)
  {:error, reason} -> handle_error(reason)
end

# ❌ Non-idiomatic
if elem(result, 0) == :ok do
  process(elem(result, 1))
else
  handle_error(elem(result, 1))
end
```

**Pipeline over Nested Calls**:
```elixir
# ✅ Idiomatic
data
|> transform()
|> validate()
|> save()

# ❌ Non-idiomatic
save(validate(transform(data)))
```

### Phoenix-Specific Conventions

**Module Organization**:
- `AppName` - Business logic
- `AppNameWeb` - Web layer
- `AppNameWeb.Router` - Always named Router
- `AppNameWeb.Endpoint` - Always named Endpoint

**File Placement**:
- `lib/app_name/` - Core domain
- `lib/app_name_web/` - Web interface
- `lib/app_name_web/live/` - LiveView modules
- `lib/app_name_web/controllers/` - Controllers

### Phoenix LiveView Patterns (2024 Best Practices)

**Lifecycle Callbacks Order**:
1. `mount/3` - Initial setup (called twice: disconnected then connected)
2. `handle_params/3` - URL/param changes (prefer over mount for assigns)
3. `handle_event/3` - User interactions
4. `handle_info/2` - PubSub messages, async results
5. `render/1` - Generate HTML (or use template)

**Socket & Assigns Rules**:
- **Immutable assigns**: Each render gets fresh copy
- **Assign in callbacks only**: Business logic returns values, callbacks assign
- **Never pass socket to business logic**: Separation of concerns
- **Use assign_async/3**: For non-blocking data loading

**Anti-Patterns to Avoid**:
```elixir
# ❌ BAD: Business logic taking socket
def calculate_total(socket, items) do
  total = Enum.sum(items)
  assign(socket, :total, total)  # Wrong!
end

# ✅ GOOD: Business logic returns value
def calculate_total(items) do
  Enum.sum(items)
end

# In LiveView callback:
socket = assign(socket, :total, calculate_total(items))
```

**Stream vs Regular Assigns**:
- **Regular assigns**: Entire collection in memory
- **Streams**: Efficient for large collections, freed after render
- **Temporary assigns**: Auto-reset after render

## 🔄 Compiler-Example Development Feedback Loop

**CRITICAL UNDERSTANDING**: Working on examples (todo-app, etc.) is simultaneously **compiler development**. Examples are **living compiler tests** that reveal bugs and drive improvements.

### Development Rules
- ✅ **Example fails to compile**: This is compiler feedback, not user error
- ✅ **Generated .ex files invalid**: Fix the transpiler, don't patch files
- ❌ **Never manually edit generated files**: They get overwritten on recompilation
- ❌ **Don't work around compiler bugs**: Fix the root cause in transpiler source
- ❌ **NEVER keep dead code 'just in case'**: Only keep code that's actually used
- ❌ **No unnecessary abstraction layers**: Don't add indirection without value (e.g., routers that don't route)

### Architectural Component Naming Rule
**CRITICAL**: Name components by what they actually DO, not what you wish they did:
- A "Router" must make routing decisions between multiple destinations
- A "Compiler" must compile/transform code
- A "Manager" must manage state or lifecycle
- Pure delegation/passthrough is NOT routing, managing, or controlling
- If you can't describe the component's value in one sentence, it shouldn't exist

## 📍 Agent Navigation Guide

### When Writing or Fixing Tests
→ **[docs/03-compiler-development/testing-infrastructure.md](docs/03-compiler-development/testing-infrastructure.md)** - Critical testing rules and snapshot testing

### When Implementing New Features  
→ **[docs/07-patterns/](docs/07-patterns/)** - Code patterns and examples
→ **[docs/03-compiler-development/best-practices.md](docs/03-compiler-development/best-practices.md)** - Development practices

### When Working on Examples (todo-app, etc.)
→ **Remember**: Examples are **compiler testing grounds** - failures reveal compiler bugs
→ **[docs/01-getting-started/development-workflow.md](docs/01-getting-started/development-workflow.md)** - Complete workflow guide

### When Dealing with Framework Integration Issues
→ **[docs/06-guides/troubleshooting.md](docs/06-guides/troubleshooting.md)** - Comprehensive troubleshooting
→ **Framework Integration**: Generated code MUST follow target framework conventions exactly

## Haxe-First Philosophy ⚠️ FUNDAMENTAL RULE

**Write EVERYTHING in Haxe unless technically impossible. Type safety everywhere, not just business logic.**

### Developer Choice and Flexibility
- **Pure Haxe preferred**: Write implementations in Haxe for maximum control
- **Typed externs welcome**: Leverage the rich Elixir ecosystem with full type safety
- **Dual-API standard library**: Use cross-platform OR platform-specific methods as needed
- **NO DYNAMIC OR ANY**: Never use Dynamic or Any in any Haxe code
- **ABSTRACT AWAY DYNAMIC AT BOUNDARIES**: When interfacing with dynamic systems (like Ecto), use macros or builder patterns to provide fully typed APIs. Users should NEVER see Dynamic

**The goal**: Maximum developer flexibility with complete type safety.

## 📚 Layered API Architecture ⚡ **MAXIMUM FLEXIBILITY DESIGN**

**FUNDAMENTAL PRINCIPLE**: Create faithful 1:1 Elixir/Phoenix externs first, then build Haxe stdlib abstractions on top. This gives users maximum flexibility - they can choose the Elixir-idiomatic API or the cross-platform Haxe API based on their needs.

### Architecture Layers
```
┌─────────────────────────────────────┐
│   Haxe Standard Library (Layer 3)   │  ← Cross-platform abstractions
│  Lambda, StringBuf, Map, Array, etc. │     (uses Layer 2)
└─────────────────────────────────────┘
                  ↓ uses
┌─────────────────────────────────────┐
│    Elixir Externs (Layer 2)         │  ← 1:1 Elixir API mappings
│  Enum, String, List, Map, etc.       │     (faithful to Elixir)
└─────────────────────────────────────┘
                  ↓ compiles to
┌─────────────────────────────────────┐
│    Elixir Runtime (Layer 1)         │  ← Native Elixir modules
│  Actual BEAM modules and functions   │
└─────────────────────────────────────┘
```

### ⚠️ CRITICAL: Both Layers Must Generate Idiomatic Elixir

**KEY PRINCIPLE**: Whether using Layer 2 (Elixir externs) or Layer 3 (Haxe stdlib), the generated Elixir code should be nearly identical and idiomatic.

```haxe
// Using Layer 2 (Elixir Externs):
import elixir.Enum;
var doubled = Enum.map(numbers, x -> x * 2);

// Using Layer 3 (Haxe Standard Library):  
var doubled = numbers.map(x -> x * 2);

// BOTH generate the SAME idiomatic Elixir:
doubled = Enum.map(numbers, fn x -> x * 2 end)
```

### Implementation Rules

**Layer 2 (Elixir Externs) - `std/elixir/`**:
- ✅ **1:1 mapping** to Elixir modules and functions
- ✅ **@:native annotations** for exact Elixir names
- ✅ **camelCase methods** with proper type signatures
- ❌ **NO business logic** - pure API definitions only
- ❌ **NO helper methods** - keep externs faithful

**Layer 3 (Haxe Stdlib) - `std/`**:
- ✅ **Built on Layer 2** - use elixir.Enum, not __elixir__()
- ✅ **Cross-platform contract** - same API across targets
- ✅ **Immutability warnings** for mutable operations
- ✅ **May use __elixir__()** for critical optimizations only
- ❌ **NO iterator objects** - transform to Enum operations

### Mutable Operations Must Warn

When Haxe patterns assume mutability:
```haxe
array.push(item);  // Mutable operation

// Compiler should warn:
// Warning: Array.push() creates a new list in Elixir (immutable).
// Consider using elixir.List.append() for explicit immutable semantics.

// Generates rebinding, not mutation:
array = array ++ [item]
```

### Benefits of This Architecture
- **User Choice**: Developers can choose Elixir-idiomatic APIs OR Haxe cross-platform APIs
- **Better Code Generation**: Direct extern usage generates more idiomatic Elixir
- **Maintainability**: Clear separation between Elixir bindings and Haxe abstractions
- **Learning Curve**: Elixir developers can use familiar APIs while gaining type safety
- **NO Iterator Objects**: Elixir uses Enum, not iterators - compiler handles transformation

**See**: [`docs/05-architecture/LAYERED_API_ARCHITECTURE.md`](docs/05-architecture/LAYERED_API_ARCHITECTURE.md) - Complete layered architecture PRD and implementation guide

## Standard Library Philosophy ⚡ **PRAGMATIC NATIVE IMPLEMENTATION**

### ⚠️ CRITICAL: Prefer Externs Over Wrappers for Elixir Standard Library

**FUNDAMENTAL RULE: If it exists in Elixir's standard library, use an extern, NOT a wrapper class.**

**The Principle**:
- **Elixir stdlib modules** → Create externs in `std/elixir/` (e.g., `elixir.List`, `elixir.Map`, `elixir.File`)
- **NO wrapper classes** → Don't create `std/List.hx` when `elixir.List` extern suffices
- **Arrays ARE lists** → `Array<T>` already compiles to Elixir lists, no need for List class
- **Direct usage** → Users can import and use Elixir modules directly with type safety

**Examples**:
```haxe
// ✅ CORRECT: Use Array (compiles to Elixir list) + extern functions
import elixir.List;
var items: Array<Int> = [1, 2, 3];  // This IS an Elixir list
var first = List.first(items);      // Direct extern usage

// ❌ WRONG: Creating unnecessary wrapper classes
class List<T> {  // Don't do this if elixir.List extern exists!
    private var internal: Array<T>;
    // ... reimplementing what Elixir already has
}
```

**When Wrappers ARE Needed**:
1. **Cross-platform abstractions** - Code that must work on multiple targets (StringBuf, etc.)
2. **Missing in Elixir** - Functionality that doesn't exist natively (specialized data structures)
3. **Complex transformations** - When Haxe semantics differ significantly from Elixir

**Benefits of Extern-First Approach**:
- **Smaller codebase** - No redundant wrapper code
- **Idiomatic output** - Direct module calls, not wrapper indirection
- **Better performance** - No extra abstraction layers
- **Clear mental model** - Elixir developers know exactly what they're getting

### The `__elixir__()` Function - Framework/Stdlib Only, NOT for Client Code

**⚠️ CRITICAL PRINCIPLE: `__elixir__()` is for framework and standard library implementation ONLY.**

**Client/Application Code Rules**:
- ❌ **NEVER use `__elixir__()`** in application code - it's a sign of missing abstractions
- ❌ **Exception: Emergency hotfixes only** - Must be justified, documented with TODO, and scheduled for proper fix
- ✅ **Always use framework abstractions** - If you need `__elixir__()`, we need better framework APIs
- ✅ **Report missing abstractions** - File an issue when framework APIs are insufficient

**Framework/Stdlib Rules**:
- ✅ **Use `__elixir__()` strategically** for efficient native implementations
- ✅ **Wrap in type-safe APIs** - Never expose `__elixir__()` to users
- ✅ **Provide complete abstractions** - Users should never need escape hatches

**IMPORTANT CLARIFICATION**: `__elixir__()` IS available and can be strategically used for standard library implementations.

**⚠️ CRITICAL: Correct Placeholder Syntax Required**

The `__elixir__()` function requires specific placeholder syntax to work correctly:

```haxe
// ❌ WRONG: $variable syntax causes Haxe string interpolation at compile-time
untyped __elixir__('Phoenix.Controller.json($conn, $data)');  // FAILS!
// This becomes string concatenation: "" + conn + ", " + data + ")"
// Result: Not a constant string, Reflaxe cannot process it

// ✅ CORRECT: {N} placeholder syntax for variable substitution
untyped __elixir__('Phoenix.Controller.json({0}, {1})', conn, data);  // WORKS!
// Variables are passed as parameters and substituted at placeholder positions
```

**WHY THIS MATTERS**: 
- `$variable` triggers Haxe's compile-time string interpolation
- The result is no longer a constant string literal
- Reflaxe's TargetCodeInjection requires the first parameter to be a constant
- `{N}` placeholders preserve the constant string while allowing substitution

**RULES FOR `__elixir__()` USAGE**:
1. First parameter MUST be a constant string literal (no concatenation)
2. Use `{0}`, `{1}`, `{2}`... for variable substitution
3. Variables are passed as additional parameters
4. Variables are compiled to Elixir and substituted at placeholder positions
5. Keyword lists and atoms should be written directly in the string

### New Stdlib Mappings (JsonPrinter, Log)

- haxe.format.JsonPrinter
  - Implemented in `std/haxe/format/JsonPrinter.cross.hx` using native Elixir via `Jason.encode!/2` with:
    - recursive `replacer(key, value)` support (maps/lists)
    - `pretty: true` when `space != null`
  - Rationale: Avoids bulky generated code; yields idiomatic, correct Elixir for all apps.
  - Policy: Do not add app-level `.ex` for stdlib — implement once in `std/` with `__elixir__()` injection.

- haxe.Log.trace
  - Implemented in `std/haxe/Log.cross.hx`; builds label and calls `IO.inspect/2` entirely in injected Elixir, avoiding local temps that later passes underscore.
  - Guarantees: No undefined label; stable output under code transforms.

### Typed Ecto Query (Chainable where)

- API: `TypedQuery.from(T)` → `TypedQuery<T>`, `query.where(u -> u.field OP value)`
- Validation: compile-time field checking via `SchemaIntrospection` in `reflaxe.elixir.macros.TypedQueryLambda`.
- Emission: `Ecto.Query.where(queryable, [t], t.field OP ^(rhs))` with correct pinning and RHS string concatenation support.
- Extension style: instance-style macro to preserve fluent chaining (`query.where(...).where(...)`).

### Ecto Query Variable Normalization

- Pass: `EctoTransforms.ectoQueryVarConsistencyPass`
  - Detects canonical query binding from both `Ecto.Queryable.to_query/1` and `Ecto.Query.from/2` patterns.
  - Rewrites downstream `Ecto.Query.where` and `Repo.all` to use the canonical var when needed.
  - Purpose: Prevent undefined variable errors without string post-processing; keeps output idiomatic.
4. Variables are compiled to Elixir and substituted at placeholder positions
5. Keyword lists and atoms should be written directly in the string

### Pragmatic Stdlib Implementation Strategy

**Philosophy**: Use the right tool for the job - combine Haxe's type safety with Elixir's native efficiency.

## 📚 Standard Library Testing & Idiomatic Generation

### Comprehensive Testing Strategy for Stdlib

**FUNDAMENTAL PRINCIPLE**: Every standard library module MUST include:
1. **Usage examples** showing Haxe API usage
2. **Expected Elixir output** demonstrating idiomatic generation
3. **Snapshot tests** validating compilation output
4. **Integration tests** ensuring runtime behavior

### Standard Library Module Documentation Pattern

Every stdlib module should follow this documentation pattern:

```haxe
/**
 * Module description and purpose
 * 
 * ## Usage Example (Haxe)
 * ```haxe
 * var example = new MyClass();
 * example.doSomething();
 * ```
 * 
 * ## Generated Idiomatic Elixir
 * ```elixir
 * # Shows exact Elixir code that will be generated
 * example = MyModule.new()
 * MyModule.do_something(example)
 * ```
 * 
 * ## Layered Architecture
 * - Layer 2 (Elixir Extern): Direct 1:1 mapping to Elixir APIs
 * - Layer 3 (Haxe Stdlib): Cross-platform abstractions using Layer 2
 * 
 * ## Performance Characteristics
 * - Time complexity for operations
 * - Memory usage patterns
 * - BEAM-specific optimizations
 */
```

### Test Infrastructure Organization

```
test/tests/
├── StdlibStringBuf/        # StringBuf tests
│   └── Main.hx             # Test cases with expected output
├── StdlibLambda/           # Lambda functional tests  
│   └── Main.hx             # Validates Enum extern usage
├── StdlibEnum/             # Elixir Enum extern tests
│   └── Main.hx             # 1:1 mapping validation
└── StdlibCommon/           # Shared test utilities
    └── TestHelper.hx       # DRY test infrastructure
```

### Example: StringBuf Idiomatic Generation

**Haxe Input:**
```haxe
var buf = new StringBuf();
buf.add("Hello");
buf.add(" World");
var result = buf.toString();
```

**Expected Elixir Output:**
```elixir
iolist = []
iolist = iolist ++ ["Hello"]
iolist = iolist ++ [" World"]
result = IO.iodata_to_binary(iolist)
```

### Example: Lambda with Enum Extern

**Haxe Input:**
```haxe
var doubled = Lambda.map([1, 2, 3], x -> x * 2);
var sum = Lambda.fold(doubled, (x, acc) -> x + acc, 0);
```

**Expected Elixir Output:**
```elixir
doubled = Enum.map([1, 2, 3], fn x -> x * 2 end)
sum = Enum.reduce(doubled, 0, fn x, acc -> x + acc end)
```

1. **Type-Safe Interface**: Haxe provides the typed API surface
2. **Native Implementation**: Use `__elixir__()` or `@:native` for efficient Elixir implementation  
3. **Best of Both Worlds**: Cross-platform API with idiomatic target code

#### Example: StringBuf Implementation (CORRECTED)
```haxe
// Type-safe Haxe interface with CORRECT placeholder syntax
class StringBuf {
    var iolist: Dynamic;
    
    public function new() {
        // Use native Elixir IO lists for efficiency
        iolist = untyped __elixir__('[]');
    }
    
    public function add(x: String): Void {
        // Native Elixir list concatenation with {N} placeholders
        iolist = untyped __elixir__('{0} ++ [{1}]', iolist, x);
    }
    
    public function toString(): String {
        // Native Elixir binary conversion with {N} placeholder
        return untyped __elixir__('IO.iodata_to_binary({0})', iolist);
    }
}
```

### Implementation Priority

1. **Prefer Native Efficiency**: Use `__elixir__()` for performance-critical stdlib
2. **Maintain Type Safety**: Wrap all native code in typed Haxe interfaces
3. **Support All Haxe Code**: Ensure Turing completeness and full Haxe compatibility
4. **Idiomatic Output**: Generated code should leverage target platform strengths

### ⚠️ CRITICAL: Override Haxe Built-in Classes When Necessary

**RULE**: When Haxe's built-in standard library classes generate problematic code for Elixir, provide our own implementation in `std/`.

**Examples**:
- **Array**: We provide `std/Array.hx` optimized for Elixir lists
- **Bytes**: We provide `std/haxe/io/Bytes.hx` to avoid nested assignment patterns
- **StringBuf**: Custom implementation using Elixir IO lists

**Why**: Haxe's built-in implementations often use inline functions and patterns that don't translate well to Elixir's functional paradigm. Our versions generate clean, idiomatic Elixir code.

**The Goal**: Complete Haxe standard library support with efficient, idiomatic Elixir implementations.

**See**: [`docs/05-architecture/`](docs/05-architecture/) - Complete implementation guidelines

## Quality Standards
- Zero compilation warnings, Reflaxe snapshot testing approach
- **Date Rule**: Always run `date` command before writing timestamps
- **CRITICAL: Idiomatic Elixir Code Generation** - Generate high-quality, functional Elixir code
- **Testing Protocol**: ALWAYS run `npm test` after compiler changes
- **Naming Convention**: ALWAYS use camelCase in Haxe code, compiler handles snake_case conversion

## Mandatory Testing Protocol ⚠️ CRITICAL

**EVERY compiler change MUST be validated through the complete testing pipeline.**

### Test-Driven Development Approach for Compiler Fixes

**FUNDAMENTAL DIRECTIVE: When fixing compiler issues, start with the INTENDED idiomatic Elixir output first.**

**The Right Workflow:**
1. **Identify the issue** in generated code (e.g., `{:custom, _code} -> (g)` is wrong)
2. **Write the idiomatic Elixir** you expect (`{:custom, code} -> code`)
3. **Create a test** with both Haxe input and intended Elixir output
4. **Work on the compiler** to generate the correct output
5. **Validate** - Test passes when generated matches intended

**Why This Matters:**
- **Prevents regressions** - Clear expectations mean breaking changes get caught
- **Speeds up development** - No guessing about correct output
- **Ensures idiomatic code** - Forces thinking about Elixir best practices
- **Tests must run from project root** - Always `cd` to project root before running tests

### ⚠️ CRITICAL: Test File Location Rules

**FUNDAMENTAL RULE: NEVER create test files in the project root. ALL tests MUST go in the proper test directories.**

**Where test files MUST go:**
- ✅ **Snapshot tests**: `test/snapshot/{category}/{test_name}/` (e.g., `test/snapshot/regression/MapIteration/`)
- ✅ **Categories**: core, phoenix, ecto, otp, stdlib, exunit, loops, regression
- ❌ **NEVER in project root**: Do not create `TestSomething.hx` files in `/Users/fullofcaffeine/workspace/code/haxe.elixir/`
- ❌ **NEVER in test/tests/**: This directory should not exist (use `test/snapshot/` instead)

**If you need to debug compiler issues:**
- Use existing tests in `test/snapshot/`
- Or create a proper test in the correct category
- Clean up any temporary files immediately after debugging

### After ANY Compiler Change

#### Quick Iteration Testing (NEW - Recommended)
```bash
# Test only affected areas during development
npm run test:changed         # Run tests affected by git changes
npm run test:failed          # Re-run only failed tests
npm run test:core            # Test core features if working on basics
npm run test:stdlib          # Test stdlib if working on standard library
```

#### Full Validation (Before Commit)
1. **Run Full Test Suite**: `npm test` - ALL tests must pass
2. **Test Todo-App Integration**:
   ```bash
   cd examples/todo-app
   npx haxe build-server.hxml
   mix compile --force
   mix phx.server        # Ensure app starts
   ```

**Rule**: If ANY step fails, the compiler change is incomplete. Fix the root cause.

**See**: [docs/03-compiler-development/testing-infrastructure.md](docs/03-compiler-development/testing-infrastructure.md) - Complete testing guide

## ⚠️ CRITICAL: Haxe Naming Convention Rules

**FUNDAMENTAL RULE: All Haxe code MUST use camelCase consistently. The compiler handles snake_case conversion for Elixir output.**

### Naming Convention Standards

#### Haxe Code (Input) - Always camelCase:
- **Variables**: `userId`, `currentUser`, `editingTodo`
- **Functions**: `loadTodos()`, `updateTodoInList()`, `getUserFromSession()`
- **Fields**: `showForm`, `searchQuery`, `selectedTags`
- **Type fields**: In typedefs and classes, use camelCase for all fields

#### Generated Elixir (Output) - Compiler converts to snake_case:
- `userId` → `user_id`
- `loadTodos()` → `load_todos()`
- `showForm` → `show_form`

#### External Library APIs (Externs) - Use actual API names:
- **Phoenix/Ecto APIs**: Keep original names like `put_flash`, `assign`, `validate_required`
- **Why**: These are external Elixir libraries with fixed APIs, not code we generate
- **Rationale**: Adding camelCase wrappers would complicate the compiler and confuse developers
- **Examples**:
  - `LiveView.put_flash(socket, type, msg)` ✅ (actual Phoenix API)
  - `LiveView.putFlash(...)` ❌ (doesn't exist in Phoenix)
  - `changeset.validateRequired(fields)` ✅ (our Changeset abstract uses camelCase)
  - `Changeset.validate_required(...)` ❌ (we're not using the Ecto extern)

### Examples

```haxe
// ✅ CORRECT - Consistent camelCase in Haxe code, snake_case for extern APIs
typedef TodoLiveAssigns = {
    var currentUser: User;      // camelCase for our fields
    var editingTodo: Todo;      // camelCase for our fields
    var showForm: Bool;         // camelCase for our fields
}

// Our function uses camelCase
function updateUserStatus(userId: Int, newStatus: String) {
    var user = Repo.get(User, userId);
    
    // Our Changeset abstract uses camelCase methods
    var changeset = new Changeset(user, {status: newStatus});
    changeset = changeset.validateRequired(["status"]);  // Our abstract: camelCase
    
    // Phoenix extern API: snake_case
    socket = LiveView.put_flash(socket, "info", "Status updated");
    socket = LiveView.assign(socket, {currentUser: user});  // Our field: camelCase
    
    return socket;
}

function loadAndAssignTodos(socket: Socket): Socket {
    var userId = socket.assigns.currentUser.id;
    var todos = loadTodos(userId);
    return LiveView.assign_multiple(socket, assigns);  // Phoenix API keeps snake_case
}

// ❌ WRONG - Mixing conventions
typedef TodoLiveAssigns = {
    var current_user: User;     // Wrong: snake_case in Haxe
    var editing_todo: Todo;     // Wrong: snake_case in Haxe
}
```

### Special Cases

1. **Template Variables**: In HXX templates, use camelCase:
   - `<%= @currentUser.name %>` NOT `<%= @current_user.name %>`
   - The compiler will handle conversion for Phoenix templates

2. **Database Fields**: When interfacing with Ecto schemas, the compiler handles mapping:
   - Haxe: `user.firstName`
   - Database column: `first_name`

3. **Configuration Keys**: Keep original format when required by frameworks

### HARD RULE: Zero‑Logic HXX (Application Code)

Do not place HEEx/Elixir logic inside HXX `{ … }` expressions. HXX in app code must only bind to assigns (e.g., `{@field}`) or view‑model fields (e.g., `v.completedStr`) that are fully computed in Haxe. All conditionals, conversions, and derivations must be computed in Haxe first.

Allowed in HXX `{ … }`:
- `{@visible_count}`, `{@filter_btn_all_class}`, `v.domId`, `v.completedStr`, etc. (precomputed assigns or view‑model fields).

Disallowed in HXX `{ … }`:
- Any Elixir/HEEx logic such as `Kernel.is_nil/1`, `length/1`, atoms (`:created`), pipes (`|>`), `Enum.*`, `Map.*`, anonymous `fn`/`end`, guards, or pattern matching.

Rationale:
- Preserve Haxe type‑safety, avoid mixing languages, and keep generated HEEx idiomatic while eliminating runtime surprises.

Enforcement pattern:
- Build a typed view model in Haxe (e.g., `TodoView`) and a helper like `buildVisibleTodos(assigns)` that computes all derived fields (booleans, strings, CSS classes, counts).
- Iterate over `@visible_todos` in HXX and bind only fields/assigns.

Repo guard (should return empty):
```bash
rg -n "\{[^}]*\b(Kernel\.|Enum\.|Map\.|length\(|\|>|:)[^}]*\}" examples/todo-app/src_haxe --no-messages
```

Exceptions:
- Direct `{@field}` assigns and HXX control tags (`<if>`, `<for>`) are permitted; the expressions they bind must reference only assigns or precomputed fields, not Elixir library calls.

### Why This Matters

- **Consistency**: One naming convention throughout Haxe codebase
- **IDE Support**: Better autocomplete and refactoring with consistent names
- **Clear Separation**: Obvious distinction between our code (camelCase) and external APIs (snake_case)
- **Compiler Responsibility**: Let the compiler handle cross-language conventions

## ⚠️ CRITICAL: Naming Convention Rules

**FUNDAMENTAL RULE: Haxe code uses camelCase, Generated Elixir uses snake_case. The compiler handles the conversion.**

### When to Use camelCase (In Haxe Source Files)
- ✅ **ALL variable names**: `var updatedSocket`, NOT `var updated_socket`
- ✅ **ALL function names**: `function loadAndAssignTodos()`, NOT `function load_and_assign_todos()`
- ✅ **ALL method names**: `socket.merge()`, NOT `socket.merge_data()`
- ✅ **ALL field names in typedefs**: `var dueDate: String`, NOT `var due_date: String`
- ✅ **ALL parameter names**: `function update(userId: Int)`, NOT `function update(user_id: Int)`
- ✅ **Case pattern variables**: `case Ok(updatedTodo):`, NOT `case Ok(updated_todo):`

### When snake_case Appears (And How to Handle It)
- **Phoenix event names in templates**: Keep as strings: `phx-click="delete_todo"` (these are Phoenix conventions)
- **Database field names**: Use `@:native` annotation: `@:native("user_id") var userId: Int`
- **Generated Elixir output**: The compiler automatically converts camelCase to snake_case

### Examples of CORRECT Naming
```haxe
// ✅ CORRECT Haxe code
class TodoLive {
    static function handleEvent(eventName: String, eventParams: Dynamic, socket: Socket): Socket {
        var updatedSocket = socket.assign("currentUser", user);
        var resultSocket = updateTodoInList(updatedTodo, socket);
        return resultSocket;
    }
}

// The compiler generates this Elixir:
defmodule TodoLive do
    def handle_event(event_name, event_params, socket) do
        updated_socket = Phoenix.LiveView.assign(socket, :current_user, user)
        result_socket = update_todo_in_list(updated_todo, socket)
        result_socket
    end
end
```

### Examples of INCORRECT Naming
```haxe
// ❌ WRONG: Using snake_case in Haxe
var updated_socket = socket.merge(assigns);  // WRONG!
var user_id = params.user_id;               // WRONG!
function load_and_assign_todos() {}         // WRONG!
case Ok(updated_todo):                      // WRONG!
```

### Key Principle
**Write Haxe idiomatically (camelCase) and let the compiler handle the Elixir conversion (snake_case).**

## ⚠️ CRITICAL: Extern Classes and snake_case Field Names

**FUNDAMENTAL RULE: Extern classes mapping to Elixir modules should use camelCase in Haxe with @:native annotations for snake_case Elixir names.**

### The Problem with snake_case in Externs
The Haxe eval target (used during macro expansion) has issues resolving snake_case field names on extern classes. This causes compilation errors like:
```
Field index for clear_flash not found on prototype Phoenix.LiveView
```

### The Solution: camelCase + @:native
```haxe
// ✅ CORRECT: camelCase in Haxe, snake_case in Elixir via @:native
@:native("Phoenix.LiveView")
extern class LiveView {
    @:native("clear_flash")
    static function clearFlash<T>(socket: Socket<T>): Socket<T>;
    
    @:native("put_flash")
    static function putFlash<T>(socket: Socket<T>, type: FlashType, message: String): Socket<T>;
    
    @:native("assign_new")
    static function assignNew<T>(socket: Socket<T>, key: String, value: Dynamic): Socket<T>;
}

// ❌ WRONG: Direct snake_case names cause eval target errors
extern class LiveView {
    static function clear_flash<T>(socket: Socket<T>): Socket<T>;  // COMPILATION ERROR!
    static function put_flash<T>(socket: Socket<T>, type: FlashType, message: String): Socket<T>;
}
```

### Complete Extern Pattern
```haxe
/**
 * Type-safe Phoenix LiveView extern
 * 
 * Uses camelCase method names for Haxe compatibility
 * Maps to snake_case via @:native for Elixir
 */
@:native("Phoenix.LiveView")
extern class LiveView {
    // Core socket operations
    @:native("assign")
    static function assign<T>(socket: Socket<T>, key: String, value: Dynamic): Socket<T>;
    
    @:native("assign_new")
    static function assignNew<T>(socket: Socket<T>, key: String, fn: () -> Dynamic): Socket<T>;
    
    @:native("clear_flash")
    static function clearFlash<T>(socket: Socket<T>): Socket<T>;
    
    @:native("put_flash")
    static function putFlash<T>(socket: Socket<T>, type: FlashType, message: String): Socket<T>;
    
    // Event handling
    @:native("push_event")
    static function pushEvent<T>(socket: Socket<T>, event: String, payload: Dynamic): Socket<T>;
    
    @:native("push_patch")
    static function pushPatch<T>(socket: Socket<T>, to: String, ?opts: Dynamic): Socket<T>;
    
    @:native("push_redirect")
    static function pushRedirect<T>(socket: Socket<T>, to: String, ?opts: Dynamic): Socket<T>;
}
```

### Usage in Application Code
```haxe
// Application code uses camelCase naturally
var socket = LiveView.clearFlash(socket);  // ✅ camelCase in Haxe
socket = LiveView.putFlash(socket, Info, "Success!");  // ✅ camelCase in Haxe

// Generated Elixir uses snake_case automatically
Phoenix.LiveView.clear_flash(socket)  // Generated snake_case
Phoenix.LiveView.put_flash(socket, :info, "Success!")  // Generated snake_case
```

### Benefits of This Pattern
- **Haxe Compatibility**: Works with Haxe's eval target during macro expansion
- **Natural Haxe Code**: Developers write idiomatic camelCase
- **Correct Elixir Output**: Generated code uses proper snake_case
- **Type Safety**: Full compile-time type checking
- **IDE Support**: IntelliSense works with camelCase names

## Development Principles

### ⚠️ CRITICAL: Apply DRY Principles to Avoid Whack-a-Mole Fixes
**FUNDAMENTAL RULE: When fixing pattern detection or similar logic, create reusable helper functions instead of repeating the same fix in multiple places.**

**Why DRY Matters in Compiler Development:**
- **Consistency**: One helper function ensures all places behave identically
- **Maintainability**: Fix once, works everywhere - no whack-a-mole debugging
- **Correctness**: No risk of missing a spot or having inconsistent implementations
- **Evolution**: When requirements change (like ENil → EAtom("nil")), update one place

**Examples of Good DRY Patterns:**
```haxe
// ✅ GOOD: Helper function for common pattern
inline function isNilValue(ast: ElixirAST): Bool {
    return switch(ast.def) {
        case EAtom(a): a == "nil";
        case ENil: true; // Legacy support
        default: false;
    };
}

// Use everywhere consistently
if (isNilValue(value)) { /* handle nil */ }

// ❌ BAD: Repeating the same pattern check
switch(value.def) {
    case EAtom(a) if (a == "nil"): // Repeated 7 times!
    // ...
}
```

**When to Create Helper Functions:**
- Pattern detection used in 2+ places
- Complex conditions that could change
- AST node type checking
- String transformations or validations
- Any logic that represents a concept (like "is this nil?")

### ⚠️ CRITICAL: Consult Codex Before New Features
**FUNDAMENTAL RULE: Before implementing any new feature, consult with Codex and reflect on its architectural guidance.**

**Why Codex Consultation Matters:**
- **Architecture expertise**: Codex has deep knowledge about software architecture patterns
- **Avoid pitfalls**: Learn from established patterns and avoid common mistakes
- **Better design**: Get architectural guidance before writing code
- **Reflective development**: Think through the approach with expert guidance

**How to Consult Codex:**
1. **Describe the feature** you're about to implement
2. **Ask for architectural guidance** about the best approach
3. **Reflect on the answer** and consider alternatives
4. **Implement with confidence** using the architectural insights

**Example Consultation:**
```
"I'm about to implement Schema emission enhancements for Ecto. 
What architectural patterns should I consider for:
- Preserving changeset functions through compilation
- Handling field type mappings
- Managing associations between schemas"
```

### ⚠️ CRITICAL: Abstract Away Dynamic at System Boundaries
**FUNDAMENTAL RULE: When interfacing with dynamic Elixir systems, ALWAYS provide a fully typed Haxe API. Users should NEVER interact with Dynamic directly.**

**The Problem**: Some Elixir systems (like Ecto changesets) use heterogeneous data structures that would require Dynamic in Haxe.

**The Solution**: Use one of these patterns to provide type safety:

1. **Macro-Generated Casting** (BEST):
   ```haxe
   // User writes:
   typedef TodoParams = { ?title: String, ?completed: Bool }
   var changeset = Todo.changeset(todo, params);  // Fully typed!
   
   // Macro generates the casting code at compile time
   ```

2. **Builder Pattern with Hidden Dynamic**:
   ```haxe
   // Internal: May use Map<String, Dynamic>
   // External: Fully typed fluent API
   return cast(todo, params)
       .validateRequired(["title"])
       .validateLength("title", {min: 3});
   ```

3. **Abstract Types Over Dynamic**:
   ```haxe
   // Wrap Dynamic in an abstract with typed methods
   abstract ChangesetData(Dynamic) {
       public function getField<T>(name: String): T { ... }
       public function setField<T>(name: String, value: T): Void { ... }
   }
   ```

**Why This Matters**:
- Type safety is the entire point of using Haxe
- Dynamic defeats IntelliSense and compile-time checking
- Users shouldn't need to know about Elixir's internal representations
- The compiler/stdlib should handle the complexity, not the user

**Examples in Practice**:
- ✅ **Ecto.Changeset**: Typed params in, typed changeset out
- ✅ **Delete operations**: Use `Changeset<T, {}>` for no-params cases, not Dynamic
- ✅ **Phoenix.Socket.assigns**: Typed assigns structure, not Dynamic
- ✅ **Plug.Conn**: Typed request/response, not Dynamic maps
- ❌ **NEVER**: `function process(data: Dynamic): Dynamic`
- ❌ **NEVER**: Use Dynamic when a proper type exists (even `{}` for empty)

### ⚠️ CRITICAL: Detect Patterns by Structure, Not by Name
**FUNDAMENTAL RULE: Never detect patterns by checking for specific hardcoded names. Detect by structural patterns or usage context.**

**What counts as name-based detection (WRONG):**
- ❌ **Hardcoded component lists** like `["PubSub", "Endpoint", "Telemetry", "Repo"]`
- ❌ **String matching** like `if (name == "SupervisorStrategy")`
- ❌ **Suffix checking** like `name.endsWith("Server")`
- ❌ **Type name lists** that need updating when new types are added

**The correct approach:**
- ✅ **Structural detection**: Check the AST structure (e.g., "tuple with atom and config")
- ✅ **Usage context**: Where/how the value is used determines its treatment
- ✅ **Metadata/annotations**: Use explicit markers like `@:childSpec` 
- ✅ **Type system**: Let the type itself define how it compiles

**Why this matters**: Hardcoded name lists create maintenance burden and break when users define their own types with similar patterns.

### ⚠️ CRITICAL: Apply Systematic Naming Conventions, Not Ad-Hoc Fixes
**FUNDAMENTAL RULE: When converting between Haxe and Elixir naming conventions, apply consistent transformations systematically.**

**General Principles:**
- **Haxe identifiers → Elixir atoms**: Always apply snake_case transformation
- **CamelCase → snake_case**: Apply consistently for all atom generation
- **No special cases**: Don't check for specific enum names or types
- **Idiomatic output**: Generated Elixir should follow Elixir conventions naturally

**Example of the right approach:**
```haxe
// ✅ CORRECT: General transformation rule
static function toElixirAtomName(name: String): String {
    // Convert ANY CamelCase to snake_case
    return camelToSnake(name);
}

// ❌ WRONG: Ad-hoc special cases
if (enumTypeName == "SupervisorStrategy") {
    atomName = toSnakeCase(atomName);  // Only for specific types
}
```

**Why this matters**: Consistent naming transformations ensure all generated code looks idiomatic, not just specific cases we've thought of.

### ⚠️ CRITICAL: Trust Your Own Compiler's Decisions
**FUNDAMENTAL RULE: When one compiler phase makes a decision, other phases must trust it completely.**

When FunctionCompiler determines a parameter name mapping, VariableCompiler must use it exactly as-is:
- **No filtering** based on underscore presence
- **No second-guessing** whether a name "looks right"
- **No validation** of the mapping - trust it completely
- **Clear authority boundaries** - each phase owns its decisions

**Example**: If FunctionCompiler maps "index" → "_index" (unused parameter), VariableCompiler must use "_index". If it maps "appName" → "app_name" (used parameter), use "app_name".

### ⚠️ CRITICAL: Test-Driven Development Workflow
**FUNDAMENTAL RULE: Create focused regression tests FIRST, fix the compiler to pass them, THEN validate with todo-app.**

Testing workflow for compiler bug fixes:
1. **Create minimal regression test** that reproduces the exact bug
2. **Write the intended idiomatic output** - What SHOULD be generated
3. **Fix the compiler** until test passes with correct output
4. **Run full test suite** - Ensure no regressions (`npm test`)
5. **Validate with todo-app** - Real-world integration test
6. **Update any broken tests** if they had wrong intended outputs

**Why this workflow works**:
- **Focused debugging** - Small test = faster iteration
- **Clear success criteria** - Test passes when bug is fixed
- **Prevents regressions** - Bug stays fixed forever
- **Documents the fix** - Test explains what was broken
- **Todo-app validation** - Ensures fix works in real applications

**For new features** (vs bug fixes):
1. Start with todo-app to explore the feature
2. Once working, extract minimal tests
3. This ensures practical, real-world driven development

### 🔁 Post‑Task Commit & Bisect Policy (MANDATORY)

After each task is completed and locally verified:

- Commit immediately with a descriptive message (WHAT and WHY). Keep the tree clean; no stray generated files.
- If a bug/regression appears and the root cause isn’t obvious, do not guess. Use git bisect with a deterministic reproduction script:

```bash
# Validate script
TIMEOUT_SEC=90 scripts/bisect-hang-test.sh

# Automated bisect
git bisect start
git bisect bad HEAD
git bisect good <known_good_commit>
TIMEOUT_SEC=90 git bisect run scripts/bisect-hang-test.sh
git bisect reset
```

- Fix at the culprit change site; avoid band‑aids elsewhere. Add/update a snapshot or small guard script to prevent recurrence.
- Re‑verify: run the snapshot suite and todo‑app integration before merging.

### ⚠️ CRITICAL: Validate Test Intended Outputs
**FUNDAMENTAL RULE: Before accepting test failures, verify the intended output itself is correct.**

When tests fail after compiler fixes:
1. **Check consistency** - If a variable is declared as `i`, it should be referenced as `i`, not `_i`
2. **Update intended outputs** when they contain bugs from previous compiler behavior
3. **Intended outputs are not sacred** - they can be wrong and perpetuate bugs
4. **This ensures tests validate correct behavior**, not historical bugs

### ⚠️ CRITICAL: Create Focused Regression Tests for Every Bug Fix
**FUNDAMENTAL RULE: Every bug fix MUST have a dedicated regression test to prevent reoccurrence.**

When fixing a bug:
1. **Create a focused test** in `test/tests/` that reproduces the exact bug scenario
2. **Name it descriptively** (e.g., `underscore_prefix_consistency`, `orphaned_enum_parameters`)
3. **Document the bug** in the test file's header comment with:
   - What the bug was
   - Why it happened
   - What the fix does
   - Link to relevant commits/issues
4. **Generate intended output** after the fix is verified
5. **Add to CI** to ensure the bug never returns

**Example**: The `underscore_prefix_consistency` test ensures variables with underscore prefixes maintain consistency throughout generated code - preventing the duplicate instance bug where VariableCompiler's state wasn't shared.

**Benefits**:
- **Prevents regressions** - Bugs stay fixed forever
- **Documents issues** - Future developers understand what went wrong
- **Fast validation** - Run specific test to verify fix still works
- **Confidence in refactoring** - Know immediately if changes break fixes

### ⚠️ CRITICAL: Always Check Recent Work Before Starting
**FUNDAMENTAL RULE: Check git history and recent commits to understand what's been done and avoid repeating work.**
- Run `git log --oneline -20` to see recent commits  
- Review related files for recent changes
- Never start debugging without understanding what's already been tried
- Avoid repeating fixes that were already attempted

### ⚠️ CRITICAL: Never Confirm Something Works Without Actual Tests
**FUNDAMENTAL RULE: Don't confirm something is working before being 100% sure by verifying with actual tests.**
- Always run `npm test` after changes
- Test todo-app compilation: `cd examples/todo-app && npx haxe build-server.hxml && mix compile`
- Verify the application runs: `mix phx.server`
- Check for runtime errors, not just compilation success
- Never say "it's fixed" without running the complete test suite

### ⚠️ CRITICAL: Avoid Regressions and Circular Work
**FUNDAMENTAL RULE: Avoid regressions and walking in circles by checking previous work.**
- Check git history before attempting a fix: `git log --oneline -30 --grep="issue_keywords"`
- Review git blame for recently changed code: `git blame path/to/file`
- Look for TODO/FIXME comments in related files
- If something was already tried and reverted, understand WHY before trying again
- Document WHY previous approaches failed to prevent repeating mistakes

### ⚠️ CRITICAL: No Ad-Hoc Fixes - Solve Root Architectural Problems
**FUNDAMENTAL RULE: Never apply band-aid fixes - always solve the root architectural problem.**
- **NO string replacements** like `if (x == "wrong") x = "right"` - find WHY it's wrong
- **NO special case handling** without understanding the general pattern
- **NO symptom patching** - trace back to where the problem originates
- **NO quick fixes** - even if they work, refactor to fix the root cause
- **NO fallback mechanisms** - fix the primary system instead of adding backup logic
- **Always ask**: Why is this happening? What's the root cause?
- **The fix must be general** - it should solve ALL similar cases, not just the one you found
- **Example of wrong approach**: Replacing "g_counter" with "g" in output
- **Example of wrong approach**: Adding fallback to check secondary mapping when primary fails
- **Example of right approach**: Fix the variable mapping system that creates "g_counter" incorrectly
- **Example of right approach**: Register mappings at TVar creation time, not retroactively
- **ZERO TOLERANCE FOR QUICK FIXES**: The user has explicitly stated they don't want quick fixes in this compiler. Always implement the proper architectural solution, even if it takes more time.

### ⚠️ CRITICAL: Consult Codex for Architecture & Complex Issues
**FUNDAMENTAL RULE: When facing architectural decisions or complex problems, consult with Codex AI for expert guidance.**

**When to consult Codex**:
- **Architecture decisions** - Before implementing new patterns or major refactorings
- **Complex debugging** - When stuck on intricate issues for >30 minutes
- **Performance optimization** - Get guidance on efficient approaches
- **Best practices** - Validate approach against industry standards
- **Cross-cutting concerns** - Issues affecting multiple subsystems

**How to consult effectively**:
1. **Describe the problem clearly** - Include context and constraints
2. **Ask specific questions** - "What's the best pattern for X given Y constraints?"
3. **Request architectural review** - "Is this approach architecturally sound?"
4. **Get comparative analysis** - "How do other compilers handle this?"
5. **Document the response** - Save timestamped reviews for future reference

**Example consultation**:
```
"I need to implement feature flag routing for AST builders.
Current architecture: monolithic 10k line builder.
Goal: gradual migration to specialized builders.
Constraints: zero downtime, rollback capability.
What architectural patterns should I consider?"
```

**Benefits**:
- **Avoid architectural debt** - Get it right the first time
- **Learn from patterns** - Understand why, not just how
- **Prevent dead ends** - Identify issues before implementation
- **Accelerate development** - Skip trial-and-error cycles

### ⚠️ CRITICAL: Re-Planning Process When Tasks Reveal New Insights
**FUNDAMENTAL RULE: When task execution reveals the plan was wrong, go through the complete re-planning process.**

**The Re-Planning Process (with Shrimp Task Management)**:
1. **Fetch the whole plan** - Use `list_tasks` to see all current tasks
2. **Explain the issue to Codex** - Describe what was discovered and why the plan needs revision
3. **Use process_thought** - Think through the new insights and their implications
4. **Recreate the whole plan** - Use `split_tasks` with clearAllTasks mode to replace the plan
5. **Check with Codex** - Validate the revised plan with architectural review
6. **Start executing again** - Begin from the new first task

**When to trigger re-planning**:
- Task verification fails with score < 80 due to architectural issues
- Discovery that multiple systems need coordination (not just one fix)
- Finding existing infrastructure that should be leveraged
- Realizing the approach creates more problems than it solves

**Example re-planning scenario**:
```
Initial plan: Fix pattern variable extraction in one place
Discovery: Pattern uses "value" but body references "v"
New insight: Multiple systems (pattern extraction, TEnumParameter, ClauseContext) aren't coordinating
Re-plan: Use EnumBindingPlan as single source of truth for all systems
```

**Benefits of re-planning**:
- Avoids circular fixes and whack-a-mole debugging
- Ensures architectural coherence
- Prevents accumulating technical debt
- Leads to proper solutions instead of band-aids

### ⚠️ CRITICAL: Debug-First Development - No Assumptions
**FUNDAMENTAL RULE: Always rely on debug data first. If you don't see the data/AST, don't assume things.**
- Add comprehensive debug traces to understand actual behavior
- Use XRay debug patterns to visualize AST transformations
- Never guess what the compiler is doing - instrument and observe
- When debugging issues, add traces FIRST, then analyze

### ⚠️ CRITICAL: No Hardcoded Class/Method Knowledge in Compiler
**FUNDAMENTAL RULE: The compiler should NOT have hardcoded knowledge about specific classes or methods.**
- **NO hardcoded class names** like checking for "Map", "List", "String" to determine behavior
- **NO method-specific logic** like special handling for "put", "delete", "merge"
- **Use metadata/annotations instead** - Let the library define its behavior via @:immutable, @:reassignsVar, etc.
- **Acceptable exceptions**: Critical edge cases or temporary hotfixes, but must be documented with TODO for proper fix
- **The compiler is generic** - It should work for any user-defined types with similar patterns
- **Example of wrong approach**: Hardcoding immutable operations for Map.put, List.delete, etc. in AST transformer
- **Example of right approach**: Methods annotated with @:immutable in Map.hx, compiler reads metadata
- **Benefits**: Extensible system where user types can opt into compiler behaviors

### ⚠️ CRITICAL: No Untyped Usage in Compiler Code
**FUNDAMENTAL RULE: NEVER use `untyped` or `Dynamic` in compiler code unless there's a very good justified reason.**

- All field access must be properly typed
- If fields are public, access them directly instead of using `untyped`
- Document any exceptional cases where `untyped` is absolutely necessary with full justification
- Prefer explicit typing and proper interfaces over dynamic access
- **See**: [`docs/03-compiler-development/TYPE_SAFETY_REQUIREMENTS.md`](docs/03-compiler-development/TYPE_SAFETY_REQUIREMENTS.md) - Complete type safety standards

### ⚠️ CRITICAL: No Direct Elixir Files - Everything Through Haxe
**FUNDAMENTAL RULE: NEVER write .ex files directly. Everything must be generated from Haxe.**

### ⚠️ CRITICAL: Check Haxe Standard Library First
**FUNDAMENTAL RULE: Always check if Haxe stdlib already offers something before implementing it ourselves.**

### ⚠️ CRITICAL: Type Safety and String Avoidance
**FUNDAMENTAL RULE: Avoid strings in compiler code unless absolutely necessary.**

### ⚠️ CRITICAL: No Dead Code - Remove Unused Functions
**FUNDAMENTAL RULE: NEVER keep dead code "just in case" - only keep code that's actually used.**
- **NO keeping unused methods** for "compatibility" or "future use"
- **NO commented-out code blocks** - use git history if you need to recover old code
- **NO delegation methods** that just return null or empty values
- **Delete immediately** when functionality is moved elsewhere
- **If it's not called, delete it** - the codebase must be clean and maintainable
- **Example of wrong approach**: Keeping detectArrayBuildingPattern() that returns null "for compatibility"
- **Example of right approach**: Delete the method entirely when WhileLoopCompiler is removed

### ⚠️ CRITICAL: Clean Up Failed Attempts Immediately
**FUNDAMENTAL RULE: When debugging attempts fail, clean up the code immediately before trying a different approach.**
- **NO accumulating debug code** that didn't solve the problem
- **NO leaving metadata fields** that aren't actually used
- **NO keeping helper functions** created for failed approaches
- **Clean as you go** - don't wait until later to remove failed attempts
- **Each new attempt** should start from a clean slate
- **Example of wrong approach**: Adding metadata fields, debug traces, and helper functions that don't solve the issue
- **Example of right approach**: Remove failed code immediately, understand the real problem, then implement a focused fix

### ⚠️ CRITICAL: No Untyped Usage
**FUNDAMENTAL RULE: NEVER use `untyped` or `Dynamic` unless there's a very good justified reason.**
- All field access must be properly typed
- If fields are public, access them directly instead of using `untyped`
- Document any exceptional cases where `untyped` is absolutely necessary
- Prefer explicit typing and proper interfaces over dynamic access

## 🏗️ Architecture & Refactoring Guidelines

### ⚠️ CRITICAL: Prevent Monolithic Files (LEARNED FROM 10,668-LINE DISASTER)

**FUNDAMENTAL RULE: NO SOURCE FILE MAY EXCEED 2000 LINES. IDEAL: 200-500 LINES.**

#### The Single Responsibility Principle (ENFORCED)
- **One file = One responsibility** - If you can't describe a file's purpose in one sentence, split it
- **Extract early, extract often** - Don't wait until a file is 10k+ lines to refactor
- **Helper pattern** - Use `helpers/` directory for specialized compilers (PatternMatchingCompiler, SchemaCompiler, etc.)

#### File Size Limits (MANDATORY)
```
✅ IDEAL:       200-500 lines   (focused, maintainable)
⚠️  ACCEPTABLE:  500-1000 lines  (consider splitting)
🚨 WARNING:     1000-2000 lines (must have justification)
❌ FORBIDDEN:   >2000 lines     (automatic refactoring required)
```

#### Extraction Guidelines
When a file approaches 1000 lines, IMMEDIATELY:
1. **Identify logical sections** - Look for groups of related functions
2. **Extract helper modules** - Create specialized compilers in `helpers/`
3. **Use delegation pattern** - Main compiler delegates to helpers
4. **Document with WHY/WHAT/HOW** - Every extracted module needs comprehensive docs

#### Example Structure (AFTER AST MIGRATION)
```
src/reflaxe/elixir/
├── ast/
│   ├── ElixirASTBuilder.hx     # TypedExpr → ElixirAST conversion
│   ├── ElixirASTPrinter.hx     # ElixirAST → String generation
│   └── ElixirASTTransformer.hx # AST transformation passes
└── ElixirCompiler.hx            # Main compiler (<2000 lines)
```

#### Red Flags That Demand Immediate Refactoring
- 🚨 **191 switch statements in one file** - Extract pattern matching
- 🚨 **100+ repeated code patterns** - Create utility functions
- 🚨 **Multiple responsibilities** - Split into focused modules
- 🚨 **Deep nesting (>4 levels)** - Extract helper methods
- 🚨 **Long functions (>100 lines)** - Break into smaller functions

### Testing During Refactoring (MANDATORY)
```bash
# After EVERY extraction:
npm test                    # Must pass ALL tests

# After 2-3 extractions:
cd examples/todo-app && npx haxe build-server.hxml && mix compile --force
```

**NEVER** complete a refactoring session without full test validation.

## Known Issues  
- **Array Mutability**: Methods like `reverse()` and `sort()` don't mutate in place (Elixir lists are immutable)
- **Postgrex.TypeManager Race Condition**: When using `mix phx.server`, may encounter "unknown registry: Postgrex.TypeManager" errors due to a race condition in Phoenix server startup. Workaround: Use `iex -S mix` to start in interactive mode, or ensure database is configured correctly. The application works correctly in interactive mode and with `mix run`.

## Recently Resolved Issues ✅
- **Empty If-Expression and Switch Side-Effects (October 2025)**: PARTIAL FIX - Bug #1 (empty if-expression invalid syntax) FIXED by correcting `isSimpleExpression()` logic in ElixirASTPrinter.hx. Empty blocks now properly generate block syntax with explicit `nil`. Bug #2 (switch cases disappearing inside loops) ROOT CAUSE IDENTIFIED as pipeline coordination issue between LoopBuilder and SwitchBuilder - not yet fixed but comprehensive investigation complete. Created regression tests for both patterns. (see [`docs/03-compiler-development/EMPTY_IF_EXPRESSION_AND_SWITCH_BUGS_FIX.md`](docs/03-compiler-development/EMPTY_IF_EXPRESSION_AND_SWITCH_BUGS_FIX.md) and [`src/reflaxe/elixir/ast/AGENTS.md`](src/reflaxe/elixir/ast/AGENTS.md))
- **Dead Code Elimination for Abstract Operators (September 2025)**: SOLUTION - Fixed unused function warnings in Date_Impl_ and other abstract types by enabling DCE (`-dce full`). Abstract types with `@:op` metadata generate ALL operator helper functions, but DCE removes unused ones before transpilation. Reduces Date_Impl_ from 140 lines to 2 lines when operators aren't used. This is the standard solution - no compiler changes needed. (see [`docs/03-compiler-development/DCE_AND_ABSTRACT_OPERATORS.md`](docs/03-compiler-development/DCE_AND_ABSTRACT_OPERATORS.md))
- **Unused Parameter Detection (September 2025)**: IMPLEMENTATION - Added UsageDetector helper class to analyze parameter usage in function bodies. Function parameters now correctly receive underscore prefixes when unused, eliminating Elixir compiler warnings. Uses tempVarRenameMap for consistent naming between signatures and bodies.
- **Phoenix.Presence Circular Fix Pattern (January 2025)**: MAJOR FIX - Resolved recurring Phoenix.Tracker.track/5 FunctionClauseError that kept resurfacing in git history. Root cause: Phoenix.Tracker expects PID as first argument, not socket. Solution: Enhanced PresenceMacro to generate proper self() injection in all presence methods (trackSimple, updateSimple, untrackSimple, listSimple). Added @:presenceTopic annotation support for type-safe topic configuration. Eliminated all __elixir__ usage from TodoPresence by providing comprehensive macro-generated methods. Git history showed this issue was "fixed" multiple times but kept breaking - now properly resolved at macro level with test coverage.
- **Idiomatic Enum Pattern Matching (September 2025)**: MAJOR IMPROVEMENT - Compiler now generates idiomatic Elixir pattern matching with atoms `{:created, content}` instead of integer index checking `elem(msg, 0)`. This makes generated code much more readable and Elixir-like. Fixed TEnumParameter extraction for ignored parameters to prevent runtime errors. (see [`src/reflaxe/elixir/ast/AGENTS.md`](src/reflaxe/elixir/ast/AGENTS.md#tenum-parameter-extraction-bug-fix-september-2025))
- **Major Loop Compilation Refactoring (August 2025)**: Reduced loop compilation from 10,668 lines across 10+ files to a single 334-line UnifiedLoopCompiler using TDD approach. Eliminated complex Y-combinator patterns in favor of simple recursive functions. Fixed g_array variable mismatch bugs. (see commit c85745e)
- **Array Desugaring & Y Combinator Patterns**: Discovered how Haxe desugars array.filter/map into TBlock/TWhile patterns and implemented detection framework (see [`docs/03-compiler-development/ARRAY_DESUGARING_PATTERNS.md`](docs/03-compiler-development/ARRAY_DESUGARING_PATTERNS.md))
- **Untyped Usage Violations**: Eliminated all unnecessary `untyped` usage in compiler code (VariableCompiler, OperatorCompiler, ControlFlowCompiler) for better type safety and IDE support
- **Orphaned Enum Parameter Variables**: Fixed compilation errors from unused TEnumParameter expressions in switch cases by implementing comprehensive AST-level detection and mitigation. First Reflaxe compiler to solve this fundamental issue caused by bypassing Haxe's optimizer (see [`docs/03-compiler-development/AST_CLEANUP_PATTERNS.md`](docs/03-compiler-development/AST_CLEANUP_PATTERNS.md))
- **Y Combinator Struct Update Patterns**: Fixed malformed inline if-else expressions with struct updates by forcing block syntax (see [`docs/03-compiler-development/Y_COMBINATOR_PATTERNS.md`](docs/03-compiler-development/Y_COMBINATOR_PATTERNS.md))
- **Variable Substitution in Lambda Expressions**: Fixed with proper AST variable tracking
- **Hardcoded Application Dependencies**: Removed all hardcoded references
- **Function Parameter Underscore Prefixing (August 2025)**: Fixed incorrect underscore prefixing of used function parameters in TypeSafeChildSpecBuilder and similar contexts. Implemented targeted priority check in VariableCompiler to ensure used parameters retain their correct names (see [`docs/03-compiler-development/FUNCTION_PARAMETER_UNDERSCORE_FIX.md`](docs/03-compiler-development/FUNCTION_PARAMETER_UNDERSCORE_FIX.md))

## Commit Standards
**Follow [Conventional Commits](https://www.conventionalcommits.org/)**: `<type>(<scope>): <subject>`
- **NO AI attribution**: Never add "Generated with Claude Code" or "Co-Authored-By: Claude"

## Development Loop ⚡ **CRITICAL WORKFLOW**

**MANDATORY: Every development change MUST follow this complete validation loop:**

```bash
# 1. Run full test suite (ALL tests must pass)
npm test

# 2. Verify todo-app compiles and runs
cd examples/todo-app && npx haxe build-server.hxml && mix compile --force && mix phx.server
```

**Rule**: If ANY step in this loop fails, the development change is incomplete.

## Implementation Status
**See**: [`docs/08-roadmap/`](docs/08-roadmap/) - Complete feature status and production readiness

**v1.0 Status**: ALL COMPLETE ✅ - Core features, Phoenix Router DSL, LiveView, Ecto, OTP patterns, Mix integration, Testing

## Test Status Summary
**See**: [`docs/03-compiler-development/testing-infrastructure.md`](docs/03-compiler-development/testing-infrastructure.md) - Complete test architecture and status

## Development Resources & Reference Strategy
- **Reference Codebase**: `/Users/fullofcaffeine/workspace/code/haxe.elixir.reference/` - **CRITICAL**: Contains working Reflaxe compiler patterns, Haxe API usage examples, and Phoenix integration patterns. ALWAYS check here first for:
  - Haxe macro API usage patterns
  - Reflaxe compiler implementation examples  
  - Working AST processing patterns
  - Test infrastructure patterns
  - **Elixir Language Source**: `/elixir/` - Official Elixir language implementation
  - **Phoenix Framework Source**: `/phoenix/` and `/phoenix_live_view/` - Framework patterns
- **Haxe API Documentation**: https://api.haxe.org/ - For type system and language features  
- **Haxe Manual**: https://haxe.org/manual/ - **CRITICAL**: Always consult for advanced features
- **Web Resources**: Use WebSearch and WebFetch for current documentation
- **Principle**: Always reference existing working code rather than guessing

## Documentation References
**Complete Documentation Index**: [`docs/README.md`](docs/README.md) - Comprehensive guide to all project documentation

**Quick Access**:
- **Installation**: [docs/01-getting-started/installation.md](docs/01-getting-started/installation.md)
- **Development Workflow**: [docs/01-getting-started/development-workflow.md](docs/01-getting-started/development-workflow.md)
- **Quick Patterns**: [docs/07-patterns/quick-start-patterns.md](docs/07-patterns/quick-start-patterns.md)
- **Troubleshooting**: [docs/06-guides/troubleshooting.md](docs/06-guides/troubleshooting.md)
- **Compiler Development**: [docs/03-compiler-development/AGENTS.md](docs/03-compiler-development/AGENTS.md)

**⚡ Critical Standard Library Implementation Guides**:
- **Stdlib Implementation Guide**: [`docs/03-compiler-development/STDLIB_IMPLEMENTATION_GUIDE.md`](docs/03-compiler-development/STDLIB_IMPLEMENTATION_GUIDE.md) - Definitive guide for implementing stdlib with idiomatic output
- **Extern Deep Dive**: [`docs/03-compiler-development/EXTERN_DEEP_DIVE.md`](docs/03-compiler-development/EXTERN_DEEP_DIVE.md) - Complete understanding of externs vs code generation
- **Native & Metadata Guide**: [`docs/03-compiler-development/NATIVE_AND_METADATA_COMPLETE_GUIDE.md`](docs/03-compiler-development/NATIVE_AND_METADATA_COMPLETE_GUIDE.md) - All metadata combinations and effects

---

**Remember**: All detailed information is in the organized [docs/](docs/) structure. This file provides navigation and critical rules only.
## Documentation Directive (hxdoc Required)

To maintain high-quality, self-explanatory compiler code, the following rules are mandatory for all changes under `src/reflaxe/elixir/**` (builders, transformers, analyzers, printer rules, macros, shims) and for vendor edits:

- Mandatory hxdoc on creation or modification of any compiler entity, including:
  - Transformers, builders, analyzers, printer rules, passes, macros, shims
  - Any new public externs in std/phoenix/ecto or vendor surfaces we expose
  - Vendor modifications (with file header comment and changelog entry as per vendor policy)
- hxdoc must include: WHAT, WHY, HOW, and EXAMPLES (minimal Haxe input → Elixir before/after)
- Cross-reference the snapshot(s) that cover the change and intended behavior; note limitations/non‑goals
- Keep transformer files < 2000 LOC; extract helpers when approaching the limit
- Inline rationale: when inlining values or using inline helpers for performance or WAE safety, explain the reason in hxdoc (e.g., “inline [] to avoid undefined children after hygiene passes”)
- No app-specific name heuristics; scope all rules by shape/API (see Hard Rule section)

CI/QA Sentinel expectations:

- QA checks must fail if any modified file under `src/reflaxe/elixir/ast/transformers/*.hx` lacks an hxdoc block describing the change per the above format.
- Shrimp tasks must reference the files touched and the snapshots that verify the behavior.
## Synthesis Update: Paradigm & Flow Debugging (2025-10-13)

This section synthesizes the current mission and adds concrete debugging guidance to avoid circular efforts during transformer work.

- Mission, restated succinctly
  - Generate idiomatic Elixir from Haxe that passes human review as natural Elixir, not machine‑generated.
  - When Haxe is imperative, preserve behavior but emit functional Elixir (Enum/Stream/case) with equivalent outcomes.
  - Encourage writing Haxe close to the Elixir paradigm (pattern matching, pure transforms, immutable data). This improves generated code quality and reduces required rewrites.
  - Compile any Haxe to Elixir and deeply integrate with Phoenix/Ecto/OTP, adding value via Haxe typing, macros, and cross‑target reuse — never invent fake framework APIs.

- Where we are
  - Core invariant in place: Enum.filter predicates normalized to EFn closures (deterministic downstream transforms).
  - Query handling consolidated: one pass (shape‑based) ensures `query` availability (promotion → binder insertion → inline), replacing late guards.
  - Next: Enum.each hygiene (unused elem, stray literal 1) and closure binder integrity in loops; then printer de‑semanticization (move method→Enum to transforms).

- Flow debugging toolkit (use sparingly, only when needed)
  - Pass flow trace (enabled by default): the transformer logs “Applying pass: <name>”. Combine with one or more flags below for focus.
  - AST pipeline flags (combine as needed):
    - `-D debug_ast_transformer`: prints node types at key points and pass application.
    - `-D debug_filter_predicate`: logs when non‑EFn filter predicates are wrapped.
    - `-D debug_filter_query_consolidate`: logs when `query` is promoted/bound/inlined.
  - Suggested workflow
    1) Build the example or test: `npx haxe build.hxml -D debug_filter_query_consolidate`
    2) Inspect the generated Elixir around the failing function and compare to the logs.
    3) Adjust a single pass (shape‑based), re‑run, and snapshot the result.

- Design guardrails to avoid “walking in circles”
  - Prefer invariants at the source: when a shape is universally required (e.g., EFn predicates), enforce it once.
  - Aggregate adjacent micro‑passes into one shape‑based pass once stable (done for filter query handling).
  - Keep the printer free of semantic rewrites; transforms should prepare AST so the printer only renders.
  - No app‑name heuristics; match shapes and real APIs only.

See also: docs/03-compiler-development/transformers-overview.md (updated with the two filter passes and ordering notes), docs/05-architecture/AST_PIPELINE_MIGRATION.md for the AST‑only architecture, and docs/06-guides/troubleshooting.md for broader guidance.

## Critical Directive: No Unblockers Over Proper Solutions

- Do not land a temporary “unblocker” if the correct long‑term solution is known and in scope. Implement the proper solution even if it takes longer.
- Prefer earliest, architectural fixes over late compensating passes:
  - stdlib behavior/shape → use `.cross.hx` overrides with typed externs and `__elixir__()`; avoid transformer overrides for stdlib.
  - Code generation issues → fix in Builder/AST generation rather than printer or post‑hoc transformer hacks.
  - Classpath/availability → use target‑conditional classpath gating (CompilerInit.Start), never global inclusion.
- Exception: short‑lived debug instrumentation (behind `-D debug_*` flags) solely to investigate an issue and removed in the same PR as the permanent fix. No “temporary” hacks are allowed to merge into main.
- Review gate: PRs proposing stopgaps must include the proper fix in the same PR. Otherwise, reject the PR.
- Example: Implement Reflect.* and Type.* via `std/Reflect.cross.hx` and `std/Type.cross.hx` rather than overriding them in `StdHaxeRuntimeOverrideTransforms`.
## Testing Discipline: No Test-Only Behavior Gates

- Tests must validate the exact behavior we ship. Do not add compiler conditionals, flags, or alternate code paths whose sole purpose is to make tests pass.
  - Prohibited: test-only gates that change output shape (e.g., inlining off only under tests), transform disabling enabled only in test builds, or snapshot-specific branches.
  - Allowed: feature rollout flags that are also used in production configuration, with tests compiled using the same flags the app would use (documented and consistent).
- Shape-affecting optimizations (e.g., inlining switch_result_* binders, string→~H conversions) must have a single production policy. If a gate exists, tests must use the same gate settings as production builds.
- When a test fails due to shape changes, prefer updating the snapshot to reflect the improved idiomatic output rather than introducing a test-only exception.
- Rationale: tests are a contract for production behavior. Keeping them aligned prevents drift, avoids hidden branches, and enforces correctness and idiomatic output for real apps.
</file>

</files>
