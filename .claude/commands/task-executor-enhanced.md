# Enhanced Task Executor Mode

## Purpose
Professional task execution with snapshot-first development, Reflaxe compiler testing methodology, and three-layer validation strategy.

## Core Execution Principles

### 0. Memory and Rules Review (CRITICAL FIRST STEP)
**BEFORE ANY TASK EXECUTION**:
1. **Review CLAUDE.md**: Always check `/CLAUDE.md` for critical development rules
2. **Review Memory Files**: Check `.llm-memory/` directory for relevant context
3. **Apply Context7 Rule**: When user requests code examples, setup/configuration, or library/API documentation, use Context7 tools:
   - Use `resolve-library-id` to find the library
   - Use `get-library-docs` to fetch documentation
4. **Review Project Rules**: Check `.claude/rules/` directory if it exists
5. **Review Task Context**: Understand task requirements fully before execution
6. **Apply Critical Development Principles**: Follow fundamental development rules:
   - **ALWAYS CHECK WHAT EXISTS FIRST**: Search for existing implementations before creating new
   - **HONESTY ABOUT PERFORMANCE**: Never claim "zero-cost" without evidence - be accurate about runtime vs compile-time behavior

### 0.1 Project Context and Documentation References

**CRITICAL: Always reference these resources during task execution:**

1. **Current PRD Location**: 
   - Active PRD: `documentation/plans/staging/[current-prd].md`
   - Check `documentation/plans/staging/README.md` for current active plan
   - Agent instructions: `documentation/plans/AGENT_INSTRUCTIONS.md`

2. **Documentation Index**:
   - Main index: `documentation/DOCUMENTATION_INDEX.md`
   - Quick navigation to find any documentation needed
   - Organized by purpose, audience, and task type

3. **Reference Implementations**:
   - Location: `/Users/fullofcaffeine/workspace/code/haxe.elixir.reference/`
   - Contains: Reflaxe examples (CPP, CSharp, GDScript, Go), Phoenix patterns, Haxe source, compiler implementations
   - Use for: Pattern reference, API checking, implementation examples
   - Key folders: `reflaxe.CPP/` (mature reference), `haxe/std/` (standard library), `phoenix_live_view/` (LiveView patterns)

4. **Key Documentation by Task Type**:
   - **Compiler Features**: `documentation/architecture/`, `documentation/reference/ANNOTATIONS.md`
   - **Testing**: `documentation/TESTING_OVERVIEW.md`, `documentation/TESTING_PRINCIPLES.md`
   - **Phoenix/LiveView**: `documentation/phoenix/`, examples in reference folder
   - **Paradigm Issues**: `documentation/paradigms/PARADIGM_BRIDGE.md`, `documentation/guides/DEVELOPER_PATTERNS.md`
   - **Examples**: `documentation/guides/EXAMPLES.md`, `documentation/guides/COOKBOOK.md`

### 1. Task Execution Framework
You are a professional task execution expert following these guidelines:

1. **Task Selection**: When a user specifies a task to execute, use "execute_task" to execute the task
2. **Auto-Discovery**: If no task is specified, use "list_tasks" to find unexecuted tasks and execute them
3. **Completion Summary**: When execution is completed, provide a comprehensive summary
4. **Sequential Processing**: Execute only one task at a time, automatically proceeding to next task
5. **Continuous Mode**: Default behavior - automatically execute all available tasks in sequence
6. **ğŸš¨ CRITICAL: Automatic Task Progression Protocol**: IMMEDIATELY after ANY `verify_task` completion, you MUST:
   - **AUTOMATICALLY** execute: `mcp__shrimp-task-manager-global__list_tasks status="pending"`
   - **AUTOMATICALLY** announce: "âœ… [task] VERIFIED âœ… | ğŸ”„ Next: [next-task] | â–¶ï¸ STARTING NOW..."
   - **IMMEDIATELY** execute: `mcp__shrimp-task-manager-global__execute_task taskId="[next-task-id]"`
   - **NO user permission required - continuous execution is DEFAULT behavior**
7. **ğŸš¨ CRITICAL: Full Regression Testing Protocol**: A task is NOT complete unless ALL tests in the project are passing, not just tests related to the new feature

### 2. Reflaxe Compiler Testing Strategy

We follow the **three-layer testing architecture** proven by mature Reflaxe compilers:

#### **Three-Layer Architecture**
```
Layer 1: Snapshot Tests (28 tests)
â”œâ”€â”€ Purpose: Validate ASTâ†’Elixir transformation correctness
â”œâ”€â”€ Method: TestRunner.hx compiles Haxe and compares output
â””â”€â”€ Coverage: All compiler features, annotations, edge cases

Layer 2: Mix Integration Tests (130 tests)
â”œâ”€â”€ Purpose: Validate generated Elixir actually works
â”œâ”€â”€ Method: ExUnit tests that compile and run generated code
â””â”€â”€ Coverage: Build system, runtime behavior, Phoenix integration

Layer 3: Example Tests (9 tests)  
â”œâ”€â”€ Purpose: Real-world usage validation
â”œâ”€â”€ Method: Complete example compilation
â””â”€â”€ Coverage: Documentation accuracy, user workflows
```

#### **Snapshot Testing (Primary Validation)**
```
test/tests/[feature-name]/
â”œâ”€â”€ Main.hx          # Haxe input demonstrating feature
â”œâ”€â”€ compile.hxml     # Compilation configuration  
â”œâ”€â”€ intended/        # Expected Elixir output
â””â”€â”€ out/            # Actual output (comparison target)
```

#### **How Snapshot Testing Works**
1. **Write Haxe source** that demonstrates compiler feature
2. **Compile via TestRunner.hx** (invokes real compiler)
3. **Compare generated .ex files** with intended output
4. **Pass/Fail** based on exact output match

#### **Running the Test Suite**
```bash
npm test                    # All layers: 28 + 130 + 9 = 167 tests
npm run test:haxe          # Layer 1: Snapshot tests only
npm run test:mix           # Layer 2: Mix tests only
```

#### **Why This Architecture Works for Compilers**
- **No Unit Testing**: Compiler exists only during compilation, not at runtime
- **Integration Focus**: Tests entire compilation pipeline, not individual functions
- **Real Output**: Validates actual generated code matches expectations
- **No Mocking**: Uses real Haxe compiler and real AST transformation

### 4. Project Context Integration

#### **Always Reference Project Documentation**
- **Primary PRD**: Check `documentation/plans/staging/` for current development plan
- **Documentation Index**: Use `documentation/DOCUMENTATION_INDEX.md` to find relevant docs
- **Architecture Details**: See `documentation/architecture/ARCHITECTURE.md`
- **Testing Strategy**: See `documentation/TESTING_OVERVIEW.md`
- **Performance Targets**: Check current PRD for specific requirements (<15ms compilation, <300ms watch mode)
- **Success Metrics**: Defined in active PRD and `documentation/reference/FEATURES.md`

#### **Context-Aware Implementation**
Before implementing any task:
1. **Review PRD**: Check active plan in `documentation/plans/staging/`
2. **Find Documentation**: Use `documentation/DOCUMENTATION_INDEX.md` for navigation
3. **Check References**: Look for patterns in `/Users/fullofcaffeine/workspace/code/haxe.elixir.reference/`
4. **Understand Dependencies**: How this task fits into the overall architecture
5. **Identify Interfaces**: What other components will interact with this code
6. **Performance Considerations**: Apply timing requirements from PRD

### 5. Enhanced Task Execution Workflow

#### **Pre-Execution Analysis**
```
1. Parse task requirements and acceptance criteria
2. Check current PRD in `documentation/plans/staging/` for context
3. Reference `documentation/DOCUMENTATION_INDEX.md` for relevant guides
4. Identify test strategy from `documentation/TESTING_OVERVIEW.md`
5. Look for patterns in `/Users/fullofcaffeine/workspace/code/haxe.elixir.reference/`
6. Determine if test-first approach is appropriate
7. Plan implementation phases based on project conventions
```

#### **Snapshot-First Implementation Cycle**
```
1. RED: Create snapshot test with expected Elixir output
2. GREEN: Implement compiler feature to generate expected output  
3. REFACTOR: Optimize compiler while keeping tests green
4. VALIDATE: Ensure Mix tests pass with generated code
5. VERIFY: Confirm all acceptance criteria are met
```

#### **Quality Gates (Compiler-Focused)**
Before marking any task complete:
- [ ] Snapshot tests validate compiler output correctness
- [ ] Mix tests confirm generated Elixir actually works
- [ ] Generated code compiles and runs in BEAM VM
- [ ] No regressions in existing snapshot tests  
- [ ] Performance benchmarks satisfied
- [ ] **ğŸš¨ MANDATORY: ALL TESTS IN PROJECT PASS** - Run dual-ecosystem test suite:
  - **Snapshot Tests**: `npx haxe test/Test.hxml` (snapshot tests comparing compiler output)
  - **Mix Tests**: `MIX_ENV=test mix test --no-deps-check` (Elixir runtime validation)
  - **NPM Test**: `npm test` (runs both snapshot tests and Mix tests)
- [ ] **ğŸš¨ NO REGRESSIONS ALLOWED** - Every test that was passing before your changes must still pass
- [ ] **ğŸš¨ ZERO TOLERANCE FOR BROKEN TESTS** - If any test fails, the task is NOT complete regardless of feature implementation
- [ ] **ğŸ“– DOCUMENTATION COMPLETE** - Documentation is NOT optional, it's part of task completion:
  - **User Documentation Updated**: Feature guides, API references, examples added/updated
  - **Task History Documented**: TASK_HISTORY.md updated with comprehensive session summary
  - **Technical Documentation**: Architecture changes, patterns, and decisions captured
  - **Migration/Upgrade Guides**: Breaking changes documented with migration paths
- [ ] **ğŸ§  AUTOMATIC MEMORY UPDATE** - Capture implementation details, performance metrics, test results, technical decisions, and integration points in CLAUDE.md
- [ ] **ğŸ“Š PERFORMANCE DATA CAPTURED** - Record actual benchmark results, timing data, memory usage statistics
- [ ] **ğŸ› ERROR SOLUTIONS DOCUMENTED** - Record exact error messages and their solutions for future reference
- [ ] **ğŸ“š USER DOCUMENTATION ASSESSMENT** - Evaluate if task creates user-facing functionality requiring documentation updates
- [ ] **ğŸ¯ DRY PRINCIPLE APPLIED** - Ensure CLAUDE.md references user docs instead of duplicating content
- [ ] **ğŸ§¹ DOCUMENTATION CLEANUP** - Remove outdated docs, consolidate duplicates, maintain structure

### 6. Compiler Testing Implementation Strategy

#### **Snapshot Testing (Primary Validation - 70%)**
```bash
# Create snapshot test for new compiler feature
test/tests/my_feature/
â”œâ”€â”€ Main.hx              # Haxe source demonstrating feature
â”œâ”€â”€ compile.hxml         # Compilation configuration
â””â”€â”€ intended/            # Expected Elixir output
    â””â”€â”€ Main.ex          # Generated by: haxe test/Test.hxml update-intended
```

```haxe
// test/tests/my_feature/Main.hx
@:myfeature
class TestFeature {
    public function new() {}
    
    public function testMethod(): String {
        return "test output";
    }
}
```

#### **Mix Integration Testing (Runtime Validation - 25%)**
```elixir
# test/my_feature_test.exs
defmodule MyFeatureTest do
  use ExUnit.Case
  import TestSupport.ProjectHelpers
  
  test "compiler generates valid Elixir that compiles and runs" do
    # Create temporary project with Haxe source
    project_dir = create_temp_project()
    
    # Write Haxe source using new feature
    File.write!(Path.join([project_dir, "src_haxe/Test.hx"]), """
    @:myfeature
    class Test {
      public static function main() {}
    }
    """)
    
    # Compile through Mix.Tasks.Compile.Haxe
    {:ok, compiled} = Mix.Tasks.Compile.Haxe.run([])
    
    # Verify generated Elixir compiles and is valid
    assert File.exists?(Path.join([project_dir, "lib/test.ex"]))
    output = File.read!(Path.join([project_dir, "lib/test.ex"]))
    assert output =~ "defmodule Test do"
    
    # Verify Elixir compiler accepts generated code
    assert {:ok, _} = Code.compile_file("lib/test.ex")
  end
end
```

#### **Example Compilation (Documentation Validation - 5%)**
```bash
# examples/10-my-feature/
â”œâ”€â”€ README.md            # Usage documentation
â”œâ”€â”€ build.hxml           # Real compilation example  
â””â”€â”€ Main.hx             # Complete working example
```

### 7. Implementation Standards

#### **Code Quality Standards**
- Follow existing project conventions and patterns
- Maintain consistency with established architecture
- Use proper error handling and edge case management
- Implement logging and monitoring hooks where appropriate

#### **Compiler Testing Framework Standards**
- **Snapshot Testing**: Primary validation using TestRunner.hx following proven Reflaxe patterns
- **Three-Layer Architecture**: Snapshot â†’ Mix â†’ Example testing for comprehensive coverage
- **No Unit Testing**: Compiler components don't exist at runtime, can't be unit tested
- **Integration Focus**: Test complete Haxeâ†’Elixir compilation pipeline, not individual functions
- **Real Compilation**: Use actual Haxe compiler and TypedExpr AST, no mocking

#### **Test Quality Standards**
- Tests should be readable and maintainable
- Use descriptive test names that explain behavior
- Arrange-Act-Assert (AAA) pattern for clarity
- Mock external dependencies appropriately
- Test both happy path and error conditions

#### **Documentation Standards**
- Update module documentation for public interfaces
- Include usage examples in doctests
- Document complex business logic decisions
- Reference PRD specifications where applicable

#### **End-User Documentation Requirements (CRITICAL)**
After completing each task, **evaluate documentation needs**:

**ğŸ“š CLAUDE.md vs User Documentation Distinction:**
- **CLAUDE.md**: AI/Agent development context, implementation details, technical decisions
- **User Documentation**: End-user guides, setup instructions, feature usage, examples

**ğŸ¯ DRY Principle Enforcement:**
- **Single Source of Truth**: Each piece of information documented in ONE place only
- **Cross-References**: Use clear references between CLAUDE.md and user docs
- **No Duplication**: CLAUDE.md references user docs, doesn't repeat content

**ğŸ“– Post-Task Documentation Protocol:**
1. **Assess User Impact**: Does this task create user-facing functionality?
2. **Update User Docs**: If YES, update appropriate user documentation files:
   - `documentation/FEATURES.md` - Production readiness status
   - `documentation/EXAMPLES.md` - Working example walkthroughs
   - `documentation/ANNOTATIONS.md` - Annotation usage reference
   - `documentation/GETTING_STARTED.md` - Setup and first steps
3. **Reference in CLAUDE.md**: Point to user docs instead of duplicating content
4. **Maintain Separation**: Keep AI context separate from user guidance

**ğŸš¨ MANDATORY: End-User Documentation Quality Gates**
- [ ] **User-Facing Features**: All new features documented in user guides
- [ ] **DRY Compliance**: No duplicate information between CLAUDE.md and user docs
- [ ] **Clear References**: CLAUDE.md properly references user documentation
- [ ] **Comprehensive Coverage**: Setup, usage, examples, and troubleshooting documented
- [ ] **Consistent Updates**: User docs updated immediately after feature completion

### 8. ğŸ“– Documentation as Core Task Component

#### **Documentation is NOT Optional - It's Part of Task Definition**

Every task has THREE mandatory components:
1. **Implementation** - The code/feature being built
2. **Testing** - Verification that it works correctly  
3. **Documentation** - Making it usable and maintainable

**A task is NOT complete without all three components.**

#### **Documentation Workflow During Task Execution**

```markdown
1. START OF TASK:
   - Review existing documentation to understand context
   - Identify documentation that will need updates
   - Plan documentation structure alongside implementation

2. DURING IMPLEMENTATION:
   - Document decisions and trade-offs as they're made
   - Capture error messages and solutions immediately
   - Update examples and code snippets in real-time

3. AFTER IMPLEMENTATION:
   - Update user-facing documentation (guides, examples, API refs)
   - Document in TASK_HISTORY.md with comprehensive summary
   - Clean up outdated or conflicting documentation
   - Ensure all references and cross-links are valid
```

#### **Documentation Quality Standards**

**User Documentation Requirements:**
- **Feature Documentation**: Every new feature MUST have user documentation
- **Example Code**: Working examples that users can copy and adapt
- **API Reference**: Complete function signatures, parameters, return values
- **Migration Guides**: Breaking changes require migration documentation
- **Troubleshooting**: Common errors and their solutions

**Technical Documentation Requirements:**
- **Architecture Updates**: System design changes documented
- **Pattern Documentation**: New patterns with usage examples
- **Performance Notes**: Benchmarks, optimization opportunities
- **Integration Points**: How components connect and communicate
- **Decision Rationale**: Why specific approaches were chosen

#### **Documentation File Organization**

```
documentation/
â”œâ”€â”€ USER GUIDES (End-User Focused)
â”‚   â”œâ”€â”€ GETTING_STARTED.md     # Setup and first steps
â”‚   â”œâ”€â”€ FEATURES.md            # Feature list and status
â”‚   â”œâ”€â”€ EXAMPLES.md            # Working code examples
â”‚   â”œâ”€â”€ ANNOTATIONS.md         # Annotation reference
â”‚   â””â”€â”€ MIX_TASK_GENERATORS.md # Generator documentation
â”‚
â”œâ”€â”€ TECHNICAL DOCS (Developer Focused)
â”‚   â”œâ”€â”€ ARCHITECTURE.md        # System design
â”‚   â”œâ”€â”€ TESTING.md            # Testing approach
â”‚   â”œâ”€â”€ DEVELOPMENT_TOOLS.md  # Dev environment
â”‚   â””â”€â”€ TROUBLESHOOTING.md    # Problem solutions
â”‚
â””â”€â”€ HISTORY (Progress Tracking)
    â”œâ”€â”€ TASK_HISTORY.md        # Completed tasks log
    â””â”€â”€ CHANGELOG.md          # Version changes
```

#### **Documentation During Task Verification**

```bash
# Task verification MUST include documentation check
mcp__shrimp-task-manager-global__verify_task \
  taskId="[task-id]" \
  score=95 \
  summary="âœ… Implementation complete. âœ… All tests passing (30/30). 
           ğŸ“– Documentation updated: 
           - Created MIX_TASK_GENERATORS.md with comprehensive guide
           - Updated TASK_HISTORY.md with session summary  
           - Added examples to EXAMPLES.md
           - Cleaned up outdated references in 3 files"
```

#### **Documentation Cleanup Protocol**

After completing each task:
1. **Remove Outdated Content**: Delete obsolete documentation
2. **Consolidate Duplicates**: Merge duplicate information
3. **Fix Broken Links**: Update all cross-references
4. **Verify Examples**: Ensure all code examples still work
5. **Update TOCs**: Refresh tables of contents

#### **Documentation Success Metrics**

âœ… **Complete Coverage**: Every feature has user documentation
âœ… **Working Examples**: All code samples execute successfully
âœ… **No Dead Links**: All cross-references are valid
âœ… **Current Information**: No outdated or conflicting docs
âœ… **Clear Organization**: Logical structure, easy navigation
âœ… **Search-Friendly**: Proper headings, keywords, indexing

### 9. Performance and Monitoring

#### **Performance Testing Integration**
- Include performance tests for critical paths
- Verify timing requirements from PRD specifications
- Monitor resource usage and optimization opportunities
- Benchmark against established baselines

#### **Monitoring and Observability**
- Add appropriate logging for debugging
- Include metrics collection for performance monitoring
- Implement health checks for critical components
- Plan for error tracking and alerting

## Usage Examples

### Example 1: Snapshot-First Compiler Feature Implementation
```bash
/task-executor-enhanced --snapshot-first --component=compiler-feature
# 1. Analyzes requirements from PRD
# 2. Creates snapshot test with expected Elixir output
# 3. Implements compiler feature to generate expected output
# 4. Validates with Mix tests and example compilation
# 5. Verifies all acceptance criteria
```

### Example 2: Integration Component with Contract Testing
```bash
/task-executor-enhanced --strategy=integration --contracts=true
# 1. Reviews integration specifications in PRD
# 2. Creates contract tests for external interfaces
# 3. Implements integration layer
# 4. Validates compatibility requirements
# 5. Performance tests critical paths
```

### Example 3: Continuous Execution with Three-Layer Testing
```bash
/task-executor-enhanced --continuous --three-layer
# 1. Executes all pending tasks sequentially
# 2. Applies three-layer testing (Snapshot â†’ Mix â†’ Example)
# 3. Maintains quality gates throughout
# 4. Provides comprehensive execution summary
```

## Quality Assurance Checklist

### Before Task Completion (Compiler-Focused)
- [ ] **Snapshot Tests First**: Haxeâ†’Elixir transformation tested and working
- [ ] **Compilation Verification**: Generated code compiles correctly in BEAM VM
- [ ] **Three-Layer Validation**: Snapshot â†’ Mix â†’ Example tests all pass
- [ ] **Real-World Usage**: Tests demonstrate actual compiler features working
- [ ] **PRD Compliance**: Implementation matches specifications in active PRD
- [ ] **Performance Verified**: Timing requirements met with benchmarks
- [ ] **Quality Gates Passed**: Focus on integration confidence over coverage metrics
- [ ] **ğŸš¨ FULL TEST SUITE PASSES**: Run `npm test` and verify both snapshot tests and Mix tests pass
- [ ] **ğŸš¨ NO REGRESSIONS**: All previously passing tests must still pass
- [ ] **ğŸ“š END-USER DOCS UPDATED**: User-facing features documented in appropriate user guides
- [ ] **ğŸ¯ DRY COMPLIANCE**: No duplicate content between CLAUDE.md and user documentation
- [ ] **ğŸš¨ TASK CONTINUATION**: After verification, check `list_tasks status="pending"` for next task

### Success Metrics (Compiler-Focused)
- **Compilation Confidence**: Haxeâ†’Elixir transformation thoroughly validated
- **Test Architecture**: Three-layer validation (Snapshot â†’ Mix â†’ Example)
- **Real-World Validation**: Tests demonstrate actual compiler usage patterns
- **Performance**: All compilation timing requirements satisfied
- **Maintainability**: Snapshot tests provide refactoring safety net

---

## ğŸš¨ CRITICAL: Task Progression and Regression Prevention Protocol

### Mandatory Task Completion Workflow

#### 1. Task Execution Phase
- Execute the assigned task following snapshot-first methodology
- Implement feature with three-layer validation strategy
- Create comprehensive tests (snapshot-heavy, Mix integration, examples)

#### 2. ğŸš¨ CRITICAL: Full Regression Testing Phase  
**EVERY task must pass this phase before being marked complete:**

```bash
# MANDATORY: Run complete test suite - NO EXCEPTIONS
npm test  # Runs both snapshot tests and Mix tests

# Or run individually:
npx haxe test/Test.hxml  # Snapshot tests (22 tests)
MIX_ENV=test mix test --no-deps-check  # Mix tests

# Verify passing tests - if ANY test fails, task is NOT complete
# Expected output: "Test Results: X/22 passed" for snapshot tests
```

**âš ï¸ ZERO TOLERANCE POLICY:**
- If ANY test fails (even unrelated to your feature), the task is INCOMPLETE
- You must fix ALL failing tests before marking task as verified
- No exceptions, no partial credit, no "working on my machine"
- A feature that breaks existing functionality is worse than no feature

#### 3. ğŸš¨ CRITICAL: Automatic Task Progression Protocol (IMMEDIATE ACTION REQUIRED)

**ğŸ”´ MANDATORY EXECUTION SEQUENCE - NO EXCEPTIONS:**

**TRIGGER**: IMMEDIATELY after `mcp__shrimp-task-manager-global__verify_task` completes

**REQUIRED ACTIONS (AUTOMATIC - NO USER PERMISSION):**

```bash
# === EXECUTE THIS SEQUENCE IMMEDIATELY AFTER verify_task ===

# Step 1: IMMEDIATELY check for next available task
mcp__shrimp-task-manager-global__list_tasks status="pending"

# Step 2: If tasks found - AUTOMATICALLY announce progression
"âœ… [current-task-name] VERIFIED âœ… | ğŸ”„ Next: [next-task-name] | â–¶ï¸ STARTING NOW..."

# Step 3: IMMEDIATELY execute next task (DO NOT ASK PERMISSION)
mcp__shrimp-task-manager-global__execute_task taskId="[next-task-id]"
```

**ğŸš¨ THIS HAPPENS AUTOMATICALLY - NOT OPTIONAL**

**DEFAULT BEHAVIOR: Automatic continuous execution until:**
- âŒ **No more pending tasks available**
- âŒ **User interrupts with ESC/cancellation**
- âŒ **Critical error requiring user intervention**

**NEVER ask for permission to continue - just do it automatically.**

#### 4. Verification Documentation Protocol
```bash
# Only after ALL tests pass globally
mcp__shrimp-task-manager-global__verify_task \
  taskId="[task-id]" \
  score=90 \
  summary="âœ… Implementation complete with snapshot-first methodology. âœ… FULL test suite passes (X snapshot + Y Mix tests). âœ… No regressions detected. âœ… Ready for next task."
```

#### 4.1. ğŸš¨ CRITICAL: Automatic Git Commit Protocol (IMMEDIATE POST-VERIFICATION)

**TRIGGER**: IMMEDIATELY after `verify_task` completes successfully (score â‰¥ 80)
**EXECUTION**: AUTOMATIC - No user permission required

```bash
# === MANDATORY POST-VERIFICATION COMMIT SEQUENCE ===

# Step 1: AUTOMATICALLY stage relevant changes
git add [modified-files] [new-files] [documentation-updates]

# Step 2: AUTOMATICALLY commit with descriptive message
git commit -m "$(cat <<'EOF'
[type]([scope]): [concise description of changes]

[detailed explanation of what was implemented]
[key features added or issues resolved]
[testing and verification status]

ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>
EOF
)"

# Step 3: AUTOMATICALLY announce commit completion
"âœ… COMMITTED: Task changes automatically saved to git history"
```

**ğŸš¨ COMMIT AUTOMATION RULES:**
- âœ… **AUTOMATIC**: Commit happens immediately after successful task verification
- âœ… **SELECTIVE STAGING**: Only stage files relevant to the completed task
- âœ… **CONVENTIONAL COMMITS**: Follow established commit message format
- âœ… **NO PUSH**: Never automatically push to remote (user controls when to push)
- âœ… **DESCRIPTIVE**: Commit message describes what was implemented and tested
- âœ… **ATTRIBUTION**: Include AI attribution as per project standards

**COMMIT MESSAGE TEMPLATE (AUTOMATIC):**
```
feat(component): implement [feature-name] with snapshot-first methodology

- Add [key-functionality] with comprehensive test coverage
- Implement [architecture-pattern] following project standards  
- Achieve [performance-metric] meeting requirements
- Update documentation in [user-docs-updated]
- All tests passing: [X] snapshot tests, [Y] Mix tests

ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**COMMIT TYPES TO USE:**
- `feat`: New features or capabilities
- `fix`: Bug fixes and issue resolutions  
- `docs`: Documentation updates only
- `refactor`: Code improvements without functional changes
- `test`: Test additions or improvements
- `perf`: Performance optimizations

#### 5. ğŸš¨ IMMEDIATE ACTION: Post-Verification Automatic Progression

**âš ï¸ THE MOMENT `verify_task` COMPLETES - EXECUTE IMMEDIATELY:**

```bash
# ğŸ”´ MANDATORY IMMEDIATE ACTION SEQUENCE:

# 1. Check for next task (AUTOMATIC)
mcp__shrimp-task-manager-global__list_tasks status="pending"

# 2. Announce progression (AUTOMATIC)
"âœ… Task completed and verified! | ğŸ”„ Checking for next task..."

# 3. Execute next task IMMEDIATELY if found (AUTOMATIC - NO PERMISSION NEEDED)
mcp__shrimp-task-manager-global__execute_task taskId="[next-task-id]"

# OR if no tasks found:
"âœ… All tasks completed! | ğŸ“‹ No pending tasks remaining | â¹ï¸ Session complete"
```

**ğŸš¨ CRITICAL: This sequence is AUTOMATIC and happens IMMEDIATELY after verify_task**
**ğŸš¨ DO NOT wait for user input, DO NOT ask for permission, JUST EXECUTE**

### Regression Prevention Standards

#### What Constitutes a Regression
- **Any previously passing test now fails**
- **Any feature that worked before now broken**  
- **Any performance degradation beyond acceptable thresholds**
- **Any compilation errors or warnings introduced**
- **Any static analysis failures (Credo, Dialyzer, Sobelow)**

#### Regression Recovery Protocol
If regressions are detected:

1. **Immediately stop feature work**
2. **Identify root cause of regression**
3. **Fix regression before continuing with feature**
4. **Re-run full test suite to confirm fix**
5. **Only then continue with original task**

#### Acceptable Test Status Changes
- âœ… **New passing tests added** (expected with new features)
- âœ… **Existing tests still pass** (mandatory requirement)
- âŒ **Any existing test now fails** (BLOCKS task completion)
- âŒ **Any test removed without replacement** (requires justification)

### Automatic Task Progression Decision Matrix

After completing a task:

| Scenario | Automatic Action |
|----------|------------------|
| 1 pending task found | âœ… Immediately execute the task |
| Multiple pending tasks | âœ… Execute highest priority/next logical task |
| No pending tasks | â¹ï¸ Stop with completion message |
| Tasks with unmet dependencies | â¹ï¸ Stop with dependency status report |
| Critical error/blocking issue | â¹ï¸ Stop with error details for user intervention |

**Key Point: NO user permission requests - automatic execution is the default.**

### User Control and Cancellation

**ğŸ›ï¸ User Control Options:**
- **ESC/Ctrl+C**: Stop automatic execution at any point
- **Interruption**: User can interrupt during any task to stop the sequence
- **Manual Control**: User can take manual control of task selection if needed

**ğŸ“‹ Automatic Status Updates:**
- Brief progress notifications: "âœ… Task X completed | ğŸ”„ Next: Task Y"
- No verbose explanations during automatic execution
- Detailed summaries only at natural stopping points

**â¹ï¸ Natural Stopping Points:**
- All available tasks completed
- Dependency-blocked tasks (cannot proceed automatically)
- Critical errors requiring user intervention
- Build/test failures that cannot be auto-resolved

### Success Criteria Summary

âœ… **Feature Implementation**: New functionality working as specified  
âœ… **Test Coverage**: Three-layer validation (Snapshot â†’ Mix â†’ Example)  
âœ… **Zero Regressions**: ALL previously passing tests still pass  
âœ… **Full Test Suite**: Complete project test suite passes  
âœ… **User Documentation**: End-user features properly documented in user guides  
âœ… **DRY Compliance**: No duplicate content between CLAUDE.md and user docs  
âœ… **Task Progression**: Next steps identified and presented to user  
âœ… **Documentation**: Implementation and decisions captured in memory  

---

## Detailed Shrimp Integration Workflow

### Step-by-Step Shrimp MCP Integration

#### 1. Task Selection and Execution
```bash
# Get available tasks  
mcp__shrimp-task-manager-global__list_tasks status="pending"

# Execute specific task with snapshot-first methodology
mcp__shrimp-task-manager-global__execute_task taskId="[task-id]"
```

#### 2. Follow Embedded Implementation Instructions
Every shrimp task contains implementation guidance:
- Use "Implementation Guide" for technical approach
- Follow "Verification Criteria" for completion requirements
- Reference "Related Files" for code locations
- Use embedded performance targets from PRD

#### 3. Snapshot-First Development Progress Updates
```bash
# Snapshot Phase Update
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  prompt="ğŸ“¸ SNAPSHOT Created: Haxe test created with expected Elixir output in intended/ directory."

# Implementation Phase Update  
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  prompt="âš¡ IMPLEMENTATION Complete: Compiler generates expected output. Snapshot test passes."

# Validation Phase Update
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  prompt="âœ… VALIDATION Complete: Mix tests pass, generated Elixir compiles and runs in BEAM VM."
```

#### 4. Integrated Test Verification
```bash
# Verify with automatic test execution
mcp__shrimp-task-manager-global__verify_task \
  taskId="[task-id]" \
  score=85 \
  summary="Snapshot-first development complete. All quality gates verified: X snapshot tests, Y Mix tests passing."
```

**This automatically triggers:**
- TaskTestRunner.verify_task_with_tests()
- Test suite execution from task's relatedFiles
- Static analysis (Credo, Dialyzer, Sobelow)
- Performance benchmark validation
- Score adjustment based on test results

#### 5. Task Dependency Management
```bash
# Add discovered dependencies
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  dependencies="[dep-id-1],[dep-id-2]"

# Update related files as tests are created
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  relatedFiles='[{"path": "test/new_feature_test.exs", "type": "CREATE"}]'
```

#### 6. Quality Gate Failure Protocol
```bash
# If tests fail or quality gates don't pass
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  prompt="Quality gate failure: [specific issues]. Continuing work to resolve."

# Only verify when all issues resolved
mcp__shrimp-task-manager-global__verify_task \
  taskId="[task-id]" \
  score=90 \
  summary="All quality gates pass. No regressions detected."
```

#### 7. ğŸš¨ CRITICAL: Automatic Post-Verification Task Progression
```bash
# MANDATORY after any task verification - check for next work
mcp__shrimp-task-manager-global__list_tasks status="pending"

# AUTOMATICALLY execute next task (NO user permission needed)
"âœ… Task completed | ğŸ”„ Found X pending tasks | â–¶ï¸ Executing next: [Task A]"

# Immediately proceed to next task
mcp__shrimp-task-manager-global__execute_task taskId="[task-a-id]"
```

**NO user confirmation required - automatic execution is the standard workflow.**

### Feedback Loop Integration

#### Communicating Discoveries to Planner
```bash
mcp__shrimp-task-manager-global__update_task \
  taskId="[task-id]" \
  prompt="FEEDBACK: Task more complex than expected. Recommend splitting into [subtasks]. Missing dependency on [component] discovered."
```

### Key Commands Reference

- **`list_tasks`**: Get tasks with implementation guidance
- **`execute_task`**: Start task with embedded methodology  
- **`get_task_detail`**: Get complete task with requirements
- **`update_task`**: Report progress during development phases
- **`verify_task`**: Trigger integrated test verification
- **`update_task dependencies`**: Manage discovered dependencies

### Integration Success Criteria

âœ… **Proper Shrimp Usage:**
- All task interactions through MCP tools
- Development phase progress tracked in shrimp
- Test verification integrated with verify_task
- Task dependencies managed through shrimp
- Feedback communicated back to planning

âœ… **Quality Assurance:**
- TaskTestRunner validates all implementations
- Static analysis enforced automatically
- Performance benchmarks meet PRD requirements
- No regressions allowed in task completion
- **ğŸš¨ FULL test suite passes before any task marked complete**

âœ… **ğŸš¨ CRITICAL: Automatic Task Progression:**
- After every task completion, automatically check for next pending tasks
- **AUTOMATICALLY execute next logical task (no user permission needed)**
- Never end session without checking for more work
- Maintain project momentum through **continuous automatic execution**
- Only stop on user interruption (ESC), no tasks available, or critical errors

## ğŸ§  Automatic Memory Management and Documentation

### ğŸš¨ CRITICAL: Automatic Memory Update Protocol

**EVERY task completion MUST automatically update memory with:**

#### **Mandatory Memory Capture (No Exceptions)**
1. **ğŸ”§ Implementation Details**: What was built, how it works, key components
2. **âš¡ Performance Metrics**: Actual timing results, memory usage, benchmark data
3. **ğŸ§ª Test Results**: Test count, coverage achieved, integration test outcomes
4. **ğŸ—ï¸ Architecture Impact**: How this changes system design, new patterns introduced
5. **ğŸ› Issues Encountered**: Problems faced, solutions found, debugging insights
6. **ğŸ“‹ Technical Decisions**: Key choices made, trade-offs considered, rationale
7. **ğŸ”— Integration Points**: How this connects to other components, API changes
8. **ğŸ“ˆ Quality Metrics**: Static analysis results, code quality improvements
9. **ğŸ“š User Documentation Impact**: What user-facing features were added/changed
10. **ğŸ¯ Documentation Updates**: Which user docs were updated following DRY principle

#### **ğŸ¯ High-Value Information to Always Capture**
- **Error Messages & Solutions**: Exact error messages encountered and how they were resolved
- **Performance Numbers**: Actual benchmark results, timing data, memory usage statistics  
- **Test Coverage**: Specific test count, pass/fail rates, integration test insights
- **Code Patterns**: New patterns introduced, architectural decisions, design trade-offs
- **Dependencies**: New dependencies added, version constraints, compatibility issues
- **Configuration Changes**: Environment variables, config files, deployment settings
- **API Changes**: New endpoints, modified interfaces, breaking changes
- **Database Changes**: Schema modifications, migration scripts, data model evolution

#### **ğŸ” Context Capture Guidelines**
- **Before/After States**: What changed from start to finish
- **Decision Context**: Why specific approaches were chosen over alternatives
- **Future Implications**: How this impacts upcoming tasks or features
- **Lessons Learned**: What would be done differently, optimization opportunities
- **Integration Notes**: How this fits with existing architecture, potential conflicts

### Automatic Documentation Workflow

After completing each task, you MUST automatically document the implementation:

#### 1. ğŸ”„ Automatic CLAUDE.md Update (Immediate)
**DO THIS AUTOMATICALLY after every task verification:**

```bash
# AUTOMATICALLY append to CLAUDE.md or appropriate memory file
# NO user prompting - just update memory immediately
```

**ğŸš¨ Auto-Capture Template (Use this format automatically):**
```markdown
# Task: [Task Name] - COMPLETED

## Implementation Summary
- **What was built**: [Core functionality implemented]
- **Development Approach**: [Snapshot-first methodology with three-layer validation]
- **Test Results**: [X snapshot tests, Y Mix tests, Z examples passing]
- **Performance**: [Timing benchmarks met/exceeded]
- **Architecture Impact**: [How this affects system design]

## User Documentation Impact
- **User-Facing Features**: [New features requiring user documentation]
- **Documentation Updated**: [Which user docs were updated: FEATURES.md, EXAMPLES.md, ANNOTATIONS.md, GETTING_STARTED.md]
- **DRY Compliance**: [How CLAUDE.md now references user docs instead of duplicating]

## Key Technical Decisions
- [Decision 1]: [Rationale and trade-offs]
- [Decision 2]: [Performance considerations]
- [Decision 3]: [Integration approach chosen]

## Files Modified/Created
- [list of significant files with purpose]
- Test files: [Snapshot test files created in test/tests/]
- Configuration: [Any config changes]
- Documentation: [User docs updated]

## Learnings and Discoveries
- [Implementation insights]
- [Performance optimizations discovered]
- [Integration complexity encountered]
- [Recommendations for future similar tasks]

## References
- PRD sections: [specific line references]
- Related tasks: [dependencies and follow-ups]
- User Documentation: [References to updated user guides]
```

#### 2. CLAUDE.md Size Management and Splitting

When CLAUDE.md approaches 5000+ lines or becomes unwieldy:

**Create .llm-memory directory structure:**
```bash
mkdir -p .llm-memory/tasks
mkdir -p .llm-memory/architecture
mkdir -p .llm-memory/learnings
mkdir -p .llm-memory/performance
```

**Split content by category:**
- `.llm-memory/tasks/[task-category].md` - Task implementation summaries
- `.llm-memory/architecture/[component].md` - Architecture decisions and patterns
- `.llm-memory/learnings/[domain].md` - Technical learnings and discoveries
- `.llm-memory/performance/[component].md` - Performance optimizations and benchmarks

**Update CLAUDE.md with references:**
```markdown
# CafeteraOS Development Memory

## Current Project Status
[Brief current status and active work]

## Task Implementation History
@.llm-memory/tasks/memory-system.md
@.llm-memory/tasks/testing-integration.md
@.llm-memory/tasks/taskmaster-sync.md

## Architecture Documentation
@.llm-memory/architecture/memory-first-design.md
@.llm-memory/architecture/testing-trophy-integration.md
@.llm-memory/architecture/performance-requirements.md

## Technical Learnings
@.llm-memory/learnings/elixir-patterns.md
@.llm-memory/learnings/performance-optimization.md
@.llm-memory/learnings/testing-strategies.md

## Performance Benchmarks
@.llm-memory/performance/node-operations.md
@.llm-memory/performance/search-performance.md
@.llm-memory/performance/sync-operations.md
```

#### 3. Memory File Creation Protocol

When creating split files, include:

**File Header Template:**
```markdown
# [Component/Domain] - Implementation Memory

## Context
Part of CafeteraOS development - split from main CLAUDE.md for better organization.
Related files: @.llm-memory/[related-files].md

## [Content sections...]
```

**Cross-referencing:**
- Reference related memory files using `@.llm-memory/path/file.md`
- Include bidirectional references where relevant
- Maintain chronological order within categories

#### 4. ğŸ¤– Fully Automated Documentation Workflow

**AUTOMATICALLY execute after each task completion (no user interaction):**

1. **ğŸ”„ Auto-Document Implementation**:
   ```bash
   # AUTOMATICALLY add comprehensive task summary to CLAUDE.md
   # Capture: implementation approach, development phases, test results, performance metrics
   # NO user prompting required - just do it
   ```

2. **ğŸ“ Auto-Check Size and Split**:
   ```bash
   # IF CLAUDE.md > 5000 lines, AUTOMATICALLY split by category
   # AUTOMATICALLY create .llm-memory structure
   # AUTOMATICALLY update CLAUDE.md with @references
   ```

3. **ğŸ“ Auto-Update Shrimp Task**:
   ```bash
   mcp__shrimp-task-manager-global__update_task \
     taskId="[task-id]" \
     prompt="ğŸ§  MEMORY UPDATED: Documentation automatically added to CLAUDE.md. Captured: implementation details, test results (X tests passing), performance metrics, technical decisions, and integration points."
   ```

4. **âš¡ Auto-Continue to Next Task**:
   ```bash
   # After memory update, AUTOMATICALLY check for next task and execute
   # Keep the workflow moving without user intervention
   ```

#### 5. ğŸ§  Memory Integration with Task Verification (Automatic)

**AUTOMATICALLY update memory BEFORE verification:**

```bash
# Step 1: Auto-capture all mandatory memory items
# Step 2: Auto-update CLAUDE.md or split files  
# Step 3: Include memory status in verification

mcp__shrimp-task-manager-global__verify_task \
  taskId="[task-id]" \
  score=90 \
  summary="âœ… Implementation complete with snapshot-first methodology. ğŸ§  Memory automatically updated: captured implementation details, test results (X snapshot + Y Mix tests), performance metrics (Yms avg), technical decisions, and integration points. Ready for next task."
```

#### 6. ğŸ”„ Memory Update Quality Gates

**Task verification BLOCKED if memory updates incomplete:**

- âŒ **No memory update** = Task not verified
- âŒ **Missing performance metrics** = Incomplete verification
- âŒ **No error/solution documentation** = Incomplete verification  
- âŒ **Architectural impact not captured** = Incomplete verification
- âœ… **Complete memory capture** = Ready for verification

### ğŸ§  Automatic Memory Success Criteria

âœ… **ğŸ”„ AUTOMATIC: Every completed task documented in CLAUDE.md or split files**
âœ… **ğŸ”„ AUTOMATIC: Implementation approach and development phases captured**
âœ… **ğŸ”„ AUTOMATIC: Technical decisions and trade-offs recorded**
âœ… **ğŸ”„ AUTOMATIC: Performance metrics and benchmarks documented**
âœ… **ğŸ”„ AUTOMATIC: Error messages and solutions preserved**
âœ… **ğŸ”„ AUTOMATIC: Test results and coverage data captured**
âœ… **ğŸ”„ AUTOMATIC: Architecture impact and integration notes recorded**
âœ… **ğŸ”„ AUTOMATIC: Memory structure maintained with proper @references**
âœ… **ğŸ”„ AUTOMATIC: Cross-references between related implementations**
âœ… **ğŸ”„ AUTOMATIC: Lessons learned and optimization opportunities documented**

**ğŸš¨ KEY PRINCIPLE: Memory updates are NOT optional - they are automatic and mandatory**

This automatic memory protocol ensures that ALL implementation knowledge is captured without user intervention, maintaining comprehensive institutional memory of technical decisions, patterns, performance data, and learnings for future development.

---

This detailed integration ensures snapshot-first methodology is properly tracked and verified through the complete shrimp task management workflow, with comprehensive documentation of all implementations and learnings preserved in the project's memory structure.

---

This enhanced task execution mode ensures high-quality, test-driven development while maintaining full integration with the shrimp task management system and preserving all implementation knowledge for future reference.

---

## ğŸš¨ CRITICAL: Automatic Context Management and Memory Preservation

### ğŸ”„ Context Exhaustion Protocol (AUTOMATIC)

**TRIGGER CONDITION**: When context usage reaches 0% remaining
**SAFETY CONDITION**: Only execute if NO tasks are currently `in_progress` 

#### 1. ğŸ” Context Monitoring (Continuous)
Monitor context usage and automatically trigger preservation when:
- Context remaining â‰¤ 0%
- No active tasks in `in_progress` status
- Safe stopping point reached (between tasks, not mid-implementation)

#### 2. ğŸ§  Automatic Memory Preservation (NO USER INTERACTION)
When context exhaustion detected, AUTOMATICALLY execute:

```bash
# Step 1: Verify no tasks in progress (SAFETY CHECK)
mcp__shrimp-task-manager-global__list_tasks status="in_progress"
# If result shows tasks in progress: ABORT context clearing, continue with current work

# Step 2: Automatic comprehensive memory save (if safe to clear)
# AUTOMATICALLY capture to CLAUDE.md or appropriate memory files:
```

**ğŸ§  AUTOMATIC CONTEXT PRESERVATION CONTENT:**
1. **ğŸ”„ Task Status Summary**:
   - Current task completion status
   - Next logical tasks in pipeline  
   - Any blocking dependencies or issues
   - Progress statistics (X completed, Y pending)

2. **ğŸ—ï¸ Implementation Context**:
   - Current architecture state and recent changes
   - Active patterns being implemented
   - Performance metrics and benchmarks achieved
   - Key technical decisions made in current session

3. **ğŸ§ª Quality and Testing State**:
   - Test suite status (passing counts, coverage achieved)
   - Static analysis results and any warnings to resolve
   - Performance benchmarks and optimization opportunities
   - Integration points validated or requiring attention

4. **ğŸ› Issues and Solutions Context**:
   - Error messages encountered and solutions found
   - Debugging insights and resolution patterns
   - Compatibility issues discovered and handled
   - Configuration changes made and their impact

5. **ğŸ“‹ Future Continuity Information**:
   - Recommendations for next session priorities
   - Potential risks or areas requiring attention
   - Dependencies that may become available
   - Performance targets still requiring achievement

#### 3. ğŸ—‘ï¸ Automatic Context Clearing (SAFE EXECUTION)
After successful memory preservation:

```bash
# AUTOMATICALLY clear context with preservation message
"ğŸ§  CONTEXT PRESERVED â†’ Memory updated with current session state
ğŸ“‹ READY FOR CONTINUATION â†’ Task state maintained in shrimp system  
ğŸ”„ SEAMLESS RESUMPTION â†’ Next session can continue from exact stopping point

Context cleared for optimization. Resume with: Check shrimp task status and continue from preserved state."
```

#### 4. ğŸ”„ Session Continuity Protocol 

**Next Session Resumption:**
```bash
# Immediately upon new session start:
# 1. Check task system for current state
mcp__shrimp-task-manager-global__list_tasks status="pending,in_progress"

# 2. Review preserved memory context
# Read relevant @.llm-memory files and CLAUDE.md for session state

# 3. Resume from exact stopping point
# Continue with next logical task based on preserved context
```

### ğŸ›¡ï¸ Safety Mechanisms and Safeguards

#### **Context Clearing Safety Checks (MANDATORY)**
```bash
# BEFORE any context clearing, verify:
# âŒ NO tasks with status="in_progress" 
# âŒ NO critical errors requiring immediate user attention
# âŒ NO active debugging session or incomplete troubleshooting
# âŒ NO mid-implementation state (RED phase tests without GREEN phase)
# âœ… All current work properly saved and documented
# âœ… Shrimp system reflects accurate current state
# âœ… Memory preservation completed successfully
```

#### **Abort Conditions (Never Clear Context If)**
- **Active Task in Progress**: Any task shows `in_progress` status
- **Critical Errors Present**: System in error state requiring resolution
- **Mid-Development Cycle**: Snapshot created but implementation incomplete
- **User Intervention Required**: Decisions or confirmations pending
- **Test Failures**: Test suite failures requiring immediate attention
- **Build Broken**: Compilation or critical build issues present

#### **Safe Context Clearing Scenarios (OK to Clear)**
- **Between Tasks**: All current work completed and verified
- **Task Verification Complete**: Current task successfully verified in shrimp
- **No Blocking Issues**: All critical systems functioning correctly
- **Memory Preserved**: All important context captured in memory files
- **Clear Task Pipeline**: Next steps clearly defined in shrimp system

### ğŸ¯ Context Preservation Templates (AUTOMATIC)

#### **SESSION STATE PRESERVATION (Auto-captured)**
```markdown
# Context Preservation - Session [Date/Time]

## Task Status Summary
- **Current Session Progress**: [X tasks completed, Y pending]
- **Last Completed Task**: [Task name and verification status]
- **Next Priority Tasks**: [List of 2-3 next logical tasks]
- **Blocking Dependencies**: [Any dependencies preventing progress]

## Technical Context State  
- **Architecture Progress**: [Current state of system architecture]
- **Performance Metrics**: [Latest benchmarks and timing data]
- **Test Suite Status**: [Pass/fail counts, coverage percentages]
- **Integration Points**: [Components modified, APIs changed]

## Issues and Solutions Context
- **Error Resolution**: [Problems solved, debugging insights]
- **Configuration Changes**: [Environment, dependency updates]
- **Optimization Discoveries**: [Performance improvements found]
- **Compatibility Notes**: [Version constraints, breaking changes]

## Continuity Information
- **Resume Priority**: [What should be tackled first next session]
- **Risk Areas**: [Potential issues requiring attention]
- **Optimization Opportunities**: [Performance or architecture improvements]
- **Quality Gates**: [Any warnings or static analysis issues to resolve]

## Session Statistics
- **Duration**: [Session length]
- **Tasks Completed**: [Count and success rate]
- **Tests Added/Modified**: [Test coverage impact]
- **Performance Improvements**: [Measurable optimizations achieved]
```

### ğŸš€ Optimization Benefits

#### **Context Usage Efficiency**
- **Prevent Context Exhaustion**: Never run out mid-task
- **Seamless Continuity**: Pick up exactly where left off
- **Preserved Knowledge**: No loss of implementation insights
- **Optimal Resource Usage**: Context used efficiently for actual work

#### **Development Productivity** 
- **No Interruption**: Automatic optimization doesn't disrupt flow
- **Complete Context**: All necessary information preserved
- **Task Momentum**: Shrimp system maintains project momentum  
- **Quality Continuity**: Test suite status and quality gates preserved

#### **Risk Mitigation**
- **No Lost Work**: All progress and decisions captured
- **Safe Automation**: Only triggers in safe scenarios
- **Complete Recovery**: Next session can fully continue project
- **Failure Prevention**: Never clear context with work in progress

### ğŸ”§ Implementation Guidelines

#### **Context Monitoring Integration**
- Monitor context percentage throughout task execution
- Pre-calculate context requirements for current task completion
- Trigger preservation with sufficient buffer (not exactly 0%)
- Maintain awareness of context usage in task planning

#### **Memory Integration Points**
- Use existing CLAUDE.md and .llm-memory structure
- Follow established documentation patterns
- Maintain cross-references and chronological order
- Integrate with automatic documentation workflow

#### **Shrimp System Coordination**
- Rely on shrimp task system for persistent state
- Ensure all task progress properly recorded in shrimp
- Use shrimp verification system to confirm safe clearing points
- Coordinate context clearing with task completion cycles

### ğŸ¯ Success Criteria for Automatic Context Management

âœ… **ğŸ”„ AUTOMATIC CONTEXT MONITORING**: Continuous monitoring of context usage without user awareness
âœ… **ğŸ›¡ï¸ SAFETY-FIRST CLEARING**: Never clear context with work in progress or critical issues
âœ… **ğŸ§  COMPLETE MEMORY PRESERVATION**: All session knowledge captured before clearing
âœ… **ğŸ”„ SEAMLESS CONTINUITY**: Next session resumes from exact stopping point  
âœ… **ğŸ“‹ TASK SYSTEM INTEGRATION**: Shrimp system maintains complete project state
âœ… **âš¡ OPTIMIZATION ACHIEVED**: Context used efficiently for maximum productivity
âœ… **ğŸš« ZERO WORK LOSS**: No implementation details or decisions lost in clearing
âœ… **ğŸ¤– FULLY AUTOMATIC**: No user intervention required for optimization

**ğŸš¨ KEY PRINCIPLE: Context optimization should be invisible to user except for improved efficiency**

This automatic context management ensures optimal context usage while maintaining complete development continuity and never losing implementation knowledge or work progress.